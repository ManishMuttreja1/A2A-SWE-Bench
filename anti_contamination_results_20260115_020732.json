{
  "verified": [
    {
      "instance_id": "sympy__sympy-22914",
      "generated_patch": "--- a/sympy/printing/pycode.py\n+++ b/sympy/printing/pycode.py\n@@ -1,6 +1,6 @@\n \"\"\"\n Python code printer\n \n See sympy.printing.codeprinter for more information.\n \"\"\"\n@@ -1,200 +1,212 @@\n from __future__ import annotations\n \n from sympy.core import S\n from sympy.core.function import Function\n from sympy.core.numbers import Integer\n from sympy.core.relational import Relational\n from sympy.core.symbol import Symbol\n from sympy.logic.boolalg import BooleanFunction\n from sympy.printing.codeprinter import CodePrinter\n from sympy.printing.precedence import precedence\n from sympy.printing.str import StrPrinter\n \n \n class PythonCodePrinter(CodePrinter):\n@@ -120,6 +132,18 @@\n     def _print_Pow(self, expr):\n         PREC = precedence(expr)\n         return self._print_Pow(expr, PREC)\n \n+    def _print_Min(self, expr):\n+        return \"min({})\".format(\", \".join(self._print(arg) for arg in expr.args))\n+\n+    def _print_Max(self, expr):\n+        return \"max({})\".format(\", \".join(self._print(arg) for arg in expr.args))\n+\n     def _print_And(self, expr):\n         return \" and \".join(self._print(arg) for arg in expr.args)\n \n     def _print_Or(self, expr):\n         return \" or \".join(self._print(arg) for arg in expr.args)",
      "expected_patch": "diff --git a/sympy/printing/pycode.py b/sympy/printing/pycode.py\n--- a/sympy/printing/pycode.py\n+++ b/sympy/printing/pycode.py\n@@ -18,6 +18,8 @@\n \n _known_functions = {\n     'Abs': 'abs',\n+    'Min': 'min',\n+    'Max': 'max',\n }\n _known_functions_math = {\n     'acos': 'acos',\n",
      "tokens": 586,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-23950",
      "generated_patch": "--- a/sympy/sets/contains.py\n+++ b/sympy/sets/contains.py\n@@ -1,6 +1,7 @@\n from sympy.core.basic import Basic\n from sympy.core.relational import Relational\n from sympy.core.sympify import _sympify\n+from sympy.sets.sets import Set\n \n \n class Contains(Relational):\n@@ -52,8 +53,11 @@ class Contains(Relational):\n         return self.args[1]\n \n     def as_set(self):\n-        return self\n+        # Contains is a Boolean/Relational, not a Set. Only return a Set when\n+        # the membership is trivially True/False.\n+        if isinstance(self.args[1], Set):\n+            return self.args[1].contains(self.args[0]).as_set()\n+        return super().as_set()",
      "expected_patch": "diff --git a/sympy/sets/contains.py b/sympy/sets/contains.py\n--- a/sympy/sets/contains.py\n+++ b/sympy/sets/contains.py\n@@ -45,4 +45,4 @@ def binary_symbols(self):\n             isinstance(i, (Eq, Ne))])\n \n     def as_set(self):\n-        raise NotImplementedError()\n+        return self.args[1]\n",
      "tokens": 492,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-14141",
      "generated_patch": "--- a/sklearn/utils/_show_versions.py\n+++ b/sklearn/utils/_show_versions.py\n@@ -1,6 +1,7 @@\n \"\"\"Utility methods to display system info for debugging.\n \n Adapted from pandas.\n \"\"\"\n \n # Authors: The scikit-learn developers\n # SPDX-License-Identifier: BSD-3-Clause\n \n import platform\n import sys\n \n import numpy\n import scipy\n \n from .. import __version__\n \n+import joblib\n+\n \n def _get_sys_info():\n     \"\"\"System information.\n \n     Returns\n     -------\n@@ -33,6 +34,7 @@\n def _get_deps_info():\n     \"\"\"Overview of the installed version of main dependencies.\n \n     Returns\n     -------\n@@ -44,6 +46,7 @@\n     deps = {\n         \"numpy\": numpy.__version__,\n         \"scipy\": scipy.__version__,\n+        \"joblib\": joblib.__version__,\n     }\n     return deps",
      "expected_patch": "diff --git a/sklearn/utils/_show_versions.py b/sklearn/utils/_show_versions.py\n--- a/sklearn/utils/_show_versions.py\n+++ b/sklearn/utils/_show_versions.py\n@@ -48,6 +48,7 @@ def _get_deps_info():\n         \"Cython\",\n         \"pandas\",\n         \"matplotlib\",\n+        \"joblib\",\n     ]\n \n     def get_version(module):\n",
      "tokens": 329,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-16082",
      "generated_patch": "--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -722,7 +722,7 @@ class CombinedExpression(SQLiteNumericMixin, Expression):\n     connector = None\n     output_field = None\n \n-    _resolve_output_field = staticmethod(_resolve_combined_type)\n+    _resolve_output_field = staticmethod(_resolve_combined_type)\n \n     def __init__(self, lhs, connector, rhs, output_field=None):\n         super().__init__(output_field=output_field)\n@@ -737,7 +737,7 @@ class CombinedExpression(SQLiteNumericMixin, Expression):\n     def _combine(self, other, connector, reversed):\n         if not isinstance(other, Expression):\n             other = Value(other)\n-        return CombinedExpression(self, connector, other) if not reversed else CombinedExpression(other, connector, self)\n+        return CombinedExpression(self, connector, other) if not reversed else CombinedExpression(other, connector, self)\n \n     def __repr__(self):\n         return \"<%s: %s %s %s>\" % (\n@@ -771,7 +771,7 @@ class CombinedExpression(SQLiteNumericMixin, Expression):\n         return self.output_field\n \n     def _resolve_output_field(self):\n-        return self._resolve_output_field(self.connector, self.lhs.output_field, self.rhs.output_field)\n+        return _resolve_combined_type(self.connector, self.lhs.output_field, self.rhs.output_field)\n \n     def as_sql(self, compiler, connection):\n         expressions = []\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -50,6 +50,7 @@ from django.core import checks, exceptions, validators\n from django.db import connection\n from django.db.models.constants import LOOKUP_SEP\n from django.db.models.query_utils import DeferredAttribute, RegisterLookupMixin\n+from django.db.models.expressions import Combinable\n from django.utils.datastructures import DictWrapper\n from django.utils.functional import cached_property\n from django.utils.hashable import make_hashable\n@@ -2461,6 +2462,10 @@ class DecimalField(Field):\n     def get_internal_type(self):\n         return \"DecimalField\"\n \n+    def _resolve_output_field(self):\n+        return self\n+\n     def to_python(self, value):\n         if value is None:\n             return value\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -570,6 +570,7 @@ _connector_combinations = {\n     Combinable.SUB: [\n         (IntegerField, IntegerField, IntegerField),\n         (FloatField, FloatField, FloatField),\n         (DecimalField, DecimalField, DecimalField),\n+        (DecimalField, IntegerField, DecimalField),\n         (IntegerField, DecimalField, DecimalField),\n         (DecimalField, FloatField, FloatField),\n         (FloatField, DecimalField, FloatField),\n@@ -584,6 +585,7 @@ _connector_combinations = {\n     Combinable.MUL: [\n         (IntegerField, IntegerField, IntegerField),\n         (FloatField, FloatField, FloatField),\n         (DecimalField, DecimalField, DecimalField),\n+        (DecimalField, IntegerField, DecimalField),\n         (IntegerField, DecimalField, DecimalField),\n         (DecimalField, FloatField, FloatField),\n         (FloatField, DecimalField, FloatField),\n@@ -598,6 +600,7 @@ _connector_combinations = {\n     Combinable.DIV: [\n         (IntegerField, IntegerField, FloatField),\n         (FloatField, FloatField, FloatField),\n         (DecimalField, DecimalField, DecimalField),\n+        (DecimalField, IntegerField, DecimalField),\n         (IntegerField, DecimalField, DecimalField),\n         (DecimalField, FloatField, FloatField),\n         (FloatField, DecimalField, FloatField),\n@@ -612,6 +615,7 @@ _connector_combinations = {\n     Combinable.MOD: [\n         (IntegerField, IntegerField, IntegerField),\n         (FloatField, FloatField, FloatField),\n         (DecimalField, DecimalField, DecimalField),\n+        (DecimalField, IntegerField, DecimalField),\n         (IntegerField, DecimalField, DecimalField),\n         (DecimalField, FloatField, FloatField),\n         (FloatField, DecimalField, FloatField),\n     ],\n }",
      "expected_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -533,6 +533,7 @@ def __hash__(self):\n             Combinable.SUB,\n             Combinable.MUL,\n             Combinable.DIV,\n+            Combinable.MOD,\n         )\n     },\n     # Bitwise operators.\n",
      "tokens": 1081,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-13406",
      "generated_patch": "--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1,6 +1,7 @@\n import copy\n import difflib\n import functools\n+import pickle\n import itertools\n import operator\n import warnings\n@@ -339,6 +340,7 @@ class Query(BaseExpression):\n         self.extra_select_mask = None\n         self._extra_select_cache = None\n         self._filtered_relations = {}\n+        self.values_select = ()\n \n     @property\n     def has_select_fields(self):\n@@ -1230,6 +1232,7 @@ class Query(BaseExpression):\n         self.select = ()\n         self.values_select = ()\n         self.selected = None\n+        self.default_cols = True\n \n     def set_values(self, fields):\n         \"\"\"\n@@ -1240,6 +1243,7 @@ class Query(BaseExpression):\n         self.select_related = False\n         self.clear_deferred_loading()\n         self.clear_select_fields()\n+        self.default_cols = False\n         if fields:\n             field_names = []\n             extra_names = []\n@@ -1258,6 +1262,7 @@ class Query(BaseExpression):\n             self.values_select = tuple(field_names)\n             self.add_fields(field_names, True)\n             self.selected = selected\n+        else:\n+            self.values_select = ()\n \n     def add_fields(self, field_names, allow_m2m=True):\n         \"\"\"\n@@ -2148,6 +2153,18 @@ class Query(BaseExpression):\n     def __getstate__(self):\n         obj_dict = self.__dict__.copy()\n         obj_dict.pop('_annotation_select_cache', None)\n+        # Ensure values()/values_list() queries remain values queries after\n+        # pickling/unpickling and reassignment to another QuerySet.\n+        if obj_dict.get('values_select'):\n+            obj_dict['default_cols'] = False\n         return obj_dict\n \n     def __setstate__(self, state):\n         self.__dict__.update(state)\n+        # Backwards compatibility for pickles created before values_select was\n+        # part of the serialized state.\n+        if getattr(self, 'values_select', None) is None:\n+            self.values_select = ()\n+        if self.values_select:\n+            self.default_cols = False",
      "expected_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -210,6 +210,8 @@ def query(self):\n \n     @query.setter\n     def query(self, value):\n+        if value.values_select:\n+            self._iterable_class = ValuesIterable\n         self._query = value\n \n     def as_manager(cls):\n",
      "tokens": 1360,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-16429",
      "generated_patch": "--- a/django/utils/timesince.py\n+++ b/django/utils/timesince.py\n@@ -90,11 +90,11 @@\n     if isinstance(d, datetime.date) and not isinstance(d, datetime.datetime):\n         d = datetime.datetime(d.year, d.month, d.day)\n     if isinstance(now, datetime.date) and not isinstance(now, datetime.datetime):\n         now = datetime.datetime(now.year, now.month, now.day)\n \n     if d > now:\n         d, now = now, d\n     delta = now - d\n \n-    pivot = datetime.datetime(d.year, d.month, 1)\n+    pivot = datetime.datetime(d.year, d.month, 1, tzinfo=d.tzinfo)\n     while pivot + datetime.timedelta(days=31) <= d:\n         pivot += datetime.timedelta(days=31)\n     months = (now.year - pivot.year) * 12 + (now.month - pivot.month)\n     if months:\n         delta = now - pivot",
      "expected_patch": "diff --git a/django/utils/timesince.py b/django/utils/timesince.py\n--- a/django/utils/timesince.py\n+++ b/django/utils/timesince.py\n@@ -97,6 +97,7 @@ def timesince(d, now=None, reversed=False, time_strings=None, depth=2):\n             d.hour,\n             d.minute,\n             d.second,\n+            tzinfo=d.tzinfo,\n         )\n     else:\n         pivot = d\n",
      "tokens": 560,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-13757",
      "generated_patch": "--- a/sympy/polys/polytools.py\n+++ b/sympy/polys/polytools.py\n@@ -1,6 +1,7 @@\n from __future__ import print_function, division\n \n from sympy.core import S, sympify\n+from sympy.core.expr import Expr\n from sympy.core.basic import Basic\n from sympy.core.compatibility import iterable\n from sympy.core.decorators import _sympifyit\n@@ -2350,6 +2351,14 @@ class Poly(Basic):\n     def __mul__(f, g):\n         return f.mul(g)\n \n+    def __rmul__(f, g):\n+        g = sympify(g)\n+        if isinstance(g, Expr):\n+            try:\n+                return f.mul(g)\n+            except Exception:\n+                return g*f.as_expr()\n+        return f.mul(g)\n+\n     def __pow__(f, n):\n         return f.pow(n)\n \n@@ -2390,6 +2399,9 @@ class Poly(Basic):\n     def mul(f, g):\n         \"\"\"Multiply ``f`` and ``g``. \"\"\"\n         g = sympify(g)\n+        if isinstance(g, Expr) and not g.is_commutative:\n+            return f.as_expr()*g\n         if isinstance(g, Poly):\n             return f._mul_poly(g)\n         else:",
      "expected_patch": "diff --git a/sympy/polys/polytools.py b/sympy/polys/polytools.py\n--- a/sympy/polys/polytools.py\n+++ b/sympy/polys/polytools.py\n@@ -106,6 +106,7 @@ class Poly(Expr):\n \n     is_commutative = True\n     is_Poly = True\n+    _op_priority = 10.001\n \n     def __new__(cls, rep, *gens, **args):\n         \"\"\"Create a new polynomial instance out of something useful. \"\"\"\n",
      "tokens": 534,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-23534",
      "generated_patch": "--- a/sympy/core/symbol.py\n+++ b/sympy/core/symbol.py\n@@ -1,6 +1,7 @@\n from __future__ import annotations\n \n from collections import defaultdict\n+from collections.abc import Sequence\n from itertools import product\n from typing import Any\n \n@@ -650,6 +651,10 @@ def symbols(names, **args):\n     \"\"\"\n     cls = args.pop('cls', Symbol)\n     seq = args.pop('seq', False)\n+    # If a single iterable of names is passed (e.g. ('q:2', 'u:2')),\n+    # treat it as multiple names rather than a single name.\n+    if isinstance(names, Sequence) and not isinstance(names, (str, bytes)):\n+        return tuple(symbols(n, cls=cls, seq=seq, **args) for n in names)\n \n     if isinstance(names, str):\n         return _symbols(names, cls=cls, seq=seq, **args)",
      "expected_patch": "diff --git a/sympy/core/symbol.py b/sympy/core/symbol.py\n--- a/sympy/core/symbol.py\n+++ b/sympy/core/symbol.py\n@@ -791,7 +791,7 @@ def literal(s):\n         return tuple(result)\n     else:\n         for name in names:\n-            result.append(symbols(name, **args))\n+            result.append(symbols(name, cls=cls, **args))\n \n         return type(names)(result)\n \n",
      "tokens": 473,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-19040",
      "generated_patch": "--- a/sympy/polys/polytools.py\n+++ b/sympy/polys/polytools.py\n@@ -1,6 +1,7 @@\n \"\"\"User-friendly public interface to polynomial functions. \"\"\"\n \n from __future__ import annotations\n+from sympy.core.symbol import Symbol\n \n from sympy.core import (Add, Basic, Expr, Mul, S, Symbol as _Symbol,\n     Tuple, sympify)\n@@ -6645,6 +6646,14 @@ def factor(f, *gens, **args):\n     if not isinstance(f, Basic):\n         return sympify(f)\n \n+    # If extension is requested but no generators are given, ensure that all\n+    # free symbols are treated as polynomial generators. Otherwise factorization\n+    # may incorrectly treat some symbols as coefficients and drop factors.\n+    if gens == () and args.get('extension', None) is not None:\n+        fs = tuple(sorted([s for s in f.free_symbols if isinstance(s, Symbol)],\n+                          key=lambda s: s.sort_key()))\n+        gens = fs\n+\n     try:\n         return _generic_factor(f, gens, args, method='factor')\n     except PolynomialError:\n         return f.factor(*gens, **args)\n--- a/sympy/polys/tests/test_polytools.py\n+++ b/sympy/polys/tests/test_polytools.py\n@@ -1,6 +1,7 @@\n from sympy.core.add import Add\n from sympy.core.expr import Expr\n from sympy.core.function import Function\n+from sympy.core.numbers import I\n from sympy.core.numbers import Rational\n from sympy.core.singleton import S\n from sympy.core.symbol import Symbol\n@@ -3778,6 +3779,12 @@ def test_factor_list():\n     assert factor_list(x**2 + 2*x + 1) == (1, [(x + 1, 2)])\n \n \n+def test_factor_extension_preserves_factors():\n+    z = expand((x - 1)*(y - 1))\n+    assert factor(z, extension=[I]) == (x - 1)*(y - 1)\n+\n+\n def test_factor_terms():\n     assert factor_terms(x + x*y) == x*(y + 1)\n     assert factor_terms(x + x*y, radical=True) == x*(y + 1)",
      "expected_patch": "diff --git a/sympy/polys/factortools.py b/sympy/polys/factortools.py\n--- a/sympy/polys/factortools.py\n+++ b/sympy/polys/factortools.py\n@@ -1147,7 +1147,7 @@ def dmp_ext_factor(f, u, K):\n         return lc, []\n \n     f, F = dmp_sqf_part(f, u, K), f\n-    s, g, r = dmp_sqf_norm(f, u, K)\n+    s, g, r = dmp_sqf_norm(F, u, K)\n \n     factors = dmp_factor_list_include(r, u, K.dom)\n \n",
      "tokens": 975,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-14534",
      "generated_patch": "--- a/django/forms/boundfield.py\n+++ b/django/forms/boundfield.py\n@@ -339,7 +339,7 @@ class BoundWidget:\n \t\treturn self.data['template_name']\n \n \tdef id_for_label(self):\n-\t\treturn 'id_%s_%s' % (self.data['name'], self.data['index'])\n+\t\treturn self.data['attrs'].get('id')",
      "expected_patch": "diff --git a/django/forms/boundfield.py b/django/forms/boundfield.py\n--- a/django/forms/boundfield.py\n+++ b/django/forms/boundfield.py\n@@ -277,7 +277,7 @@ def template_name(self):\n \n     @property\n     def id_for_label(self):\n-        return 'id_%s_%s' % (self.data['name'], self.data['index'])\n+        return self.data['attrs'].get('id')\n \n     @property\n     def choice_label(self):\n",
      "tokens": 548,
      "success": true,
      "similarity": 1.0
    },
    {
      "instance_id": "psf__requests-1921",
      "generated_patch": "--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -1,6 +1,7 @@\n # -*- coding: utf-8 -*-\n \n import os\n+import collections\n import sys\n import time\n \n@@ -55,6 +56,7 @@ from .structures import CaseInsensitiveDict\n from .utils import (\n     DEFAULT_CA_BUNDLE_PATH, get_auth_from_url, get_encoding_from_headers,\n     prepend_scheme_if_needed, select_proxy, urldefragauth, requote_uri,\n     stream_decode_response_unicode, to_key_val_list, parse_header_links,\n     iter_slices, guess_json_utf, super_len, check_header_validity,\n )\n@@ -470,6 +472,20 @@ class Session(SessionRedirectMixin):\n         self.mount(\"https://\", HTTPAdapter())\n \n     def __enter__(self):\n         return self\n \n     def __exit__(self, *args):\n         self.close()\n \n+    @staticmethod\n+    def _remove_none_headers(headers):\n+        if not headers:\n+            return headers\n+        if isinstance(headers, collections.abc.Mapping):\n+            return {k: v for k, v in headers.items() if v is not None}\n+        return [(k, v) for k, v in headers if v is not None]\n+\n     def prepare_request(self, request):\n         \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for\n         transmission and returns it. The :class:`PreparedRequest` has settings\n         merged from the :class:`Request <Request>` instance and those of the\n         :class:`Session`.\n@@ -479,7 +495,8 @@ class Session(SessionRedirectMixin):\n         :rtype: requests.PreparedRequest\n         \"\"\"\n \n-        cookies = request.cookies or {}\n+        request.headers = self._remove_none_headers(request.headers)\n+        cookies = request.cookies or {}\n \n         # Bootstrap CookieJar.\n         if not isinstance(cookies, cookielib.CookieJar):\n             cookies = cookiejar_from_dict(cookies)\n@@ -490,7 +507,7 @@ class Session(SessionRedirectMixin):\n         # Merge with session cookies\n         merged_cookies = merge_cookies(\n             merge_cookies(RequestsCookieJar(), self.cookies), cookies\n         )\n \n-        # Set environment's basic authentication if not explicitly set.\n+        # Set environment's basic authentication if not explicitly set.\n         auth = request.auth\n         if self.trust_env and not auth and not self.auth:\n             auth = get_netrc_auth(request.url)\n \n@@ -500,7 +517,7 @@ class Session(SessionRedirectMixin):\n         p = PreparedRequest()\n         p.prepare(\n             method=request.method.upper(),\n             url=request.url,\n-            files=request.files,\n+            files=request.files,\n             data=request.data,\n             json=request.json,\n             headers=merge_setting(\n                 request.headers, self.headers, dict_class=CaseInsensitiveDict\n             ),\n@@ -509,6 +526,7 @@ class Session(SessionRedirectMixin):\n             auth=merge_setting(auth, self.auth),\n             hooks=merge_hooks(request.hooks, self.hooks),\n         )\n+        p.headers = CaseInsensitiveDict(self._remove_none_headers(p.headers))\n \n         return p",
      "expected_patch": "diff --git a/requests/sessions.py b/requests/sessions.py\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -59,6 +59,8 @@ def merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n         if v is None:\n             del merged_setting[k]\n \n+    merged_setting = dict((k, v) for (k, v) in merged_setting.items() if v is not None)\n+\n     return merged_setting\n \n \n",
      "tokens": 932,
      "success": true,
      "similarity": 0.5
    },
    {
      "instance_id": "pallets__flask-5014",
      "generated_patch": "--- a/src/flask/blueprints.py\n+++ b/src/flask/blueprints.py\n@@ -1,6 +1,7 @@\n from __future__ import annotations\n \n import typing as t\n+from werkzeug.utils import cached_property\n \n from .helpers import _endpoint_from_view_func\n from .helpers import _matching_loader_thinks_module_is_package\n@@ -18,7 +19,6 @@\n from .typing import RouteCallable\n from .typing import TemplateFilterCallable\n from .typing import TemplateGlobalCallable\n from .typing import TemplateTestCallable\n-from werkzeug.utils import cached_property\n \n if t.TYPE_CHECKING:  # pragma: no cover\n     from .app import Flask\n@@ -135,6 +135,9 @@\n     def __init__(\n         self, name: str, import_name: str, static_folder: str | None = None, static_url_path: str | None = None,\n         template_folder: str | None = None, url_prefix: str | None = None, subdomain: str | None = None,\n@@ -142,6 +145,9 @@\n     ) -> None:\n+        if not name:\n+            raise ValueError(\"Blueprint name must not be empty.\")\n+\n         super().__init__(\n             import_name=import_name,\n             static_folder=static_folder,\n             static_url_path=static_url_path,",
      "expected_patch": "diff --git a/src/flask/blueprints.py b/src/flask/blueprints.py\n--- a/src/flask/blueprints.py\n+++ b/src/flask/blueprints.py\n@@ -190,6 +190,9 @@ def __init__(\n             root_path=root_path,\n         )\n \n+        if not name:\n+            raise ValueError(\"'name' may not be empty.\")\n+\n         if \".\" in name:\n             raise ValueError(\"'name' may not contain a dot '.' character.\")\n \n",
      "tokens": 426,
      "success": true,
      "similarity": 0.6666666666666666
    },
    {
      "instance_id": "django__django-14089",
      "generated_patch": "--- a/django/utils/datastructures.py\n+++ b/django/utils/datastructures.py\n@@ -1,6 +1,7 @@\n \"\"\"\n Various data structures used by Django.\n \"\"\"\n \n+from __future__ import annotations\n from collections import OrderedDict\n \n \n class OrderedSet:\n@@ -56,6 +57,9 @@ class OrderedSet:\n     def __iter__(self):\n         return iter(self.dict)\n \n+    def __reversed__(self):\n+        return reversed(self.dict)\n+\n     def __len__(self):\n         return len(self.dict)\n \n     def __contains__(self, item):\n         return item in self.dict",
      "expected_patch": "diff --git a/django/utils/datastructures.py b/django/utils/datastructures.py\n--- a/django/utils/datastructures.py\n+++ b/django/utils/datastructures.py\n@@ -25,6 +25,9 @@ def discard(self, item):\n     def __iter__(self):\n         return iter(self.dict)\n \n+    def __reversed__(self):\n+        return reversed(self.dict)\n+\n     def __contains__(self, item):\n         return item in self.dict\n \n",
      "tokens": 298,
      "success": true,
      "similarity": 1.0
    },
    {
      "instance_id": "sympy__sympy-15875",
      "generated_patch": "--- a/sympy/core/add.py\n+++ b/sympy/core/add.py\n@@ -1,6 +1,7 @@\n from __future__ import annotations\n \n from collections import defaultdict\n+from sympy.core.numbers import I\n from itertools import product\n from typing import TYPE_CHECKING\n \n@@ -706,6 +707,20 @@ class Add(Expr, AssocOp):\n         return self.func(*[a for a in args if a])\n \n     @property\n+    def is_zero(self):\n+        # Avoid incorrect False for expressions like -2*I + (1 + I)**2.\n+        # If we cannot decide reliably, return None rather than False.\n+        if self.is_extended_real is False:\n+            re, im = self.as_real_imag()\n+            if re.is_zero is True and im.is_zero is True:\n+                return True\n+            if re.is_zero is False or im.is_zero is False:\n+                return False\n+            return None\n+        return super().is_zero\n+\n+    @property\n     def is_number(self):\n         return all(obj.is_number for obj in self.args)\n \n@@ -1160,7 +1175,7 @@ class Add(Expr, AssocOp):\n         if not self.is_commutative:\n             return self\n \n-        if self.is_number:\n+        if self.is_number:\n             return self._eval_evalf(prec)\n \n         # if any term is NaN, the result is NaN\n",
      "expected_patch": "diff --git a/sympy/core/add.py b/sympy/core/add.py\n--- a/sympy/core/add.py\n+++ b/sympy/core/add.py\n@@ -554,7 +554,7 @@ def _eval_is_zero(self):\n                 return\n         if z == len(self.args):\n             return True\n-        if len(nz) == len(self.args):\n+        if len(nz) == 0 or len(nz) == len(self.args):\n             return None\n         b = self.func(*nz)\n         if b.is_zero:\n",
      "tokens": 558,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-16333",
      "generated_patch": "--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -260,13 +260,16 @@\n     def save(self, commit=True):\n         user = super().save(commit=False)\n         user.set_password(self.cleaned_data[\"password1\"])\n         if commit:\n             user.save()\n+            # Save many-to-many data for custom user models with M2M fields.\n+            if hasattr(self, \"save_m2m\"):\n+                self.save_m2m()\n         return user\n \n \n class UserChangeForm(forms.ModelForm):\n     password = ReadOnlyPasswordHashField(\n         label=_(\"Password\"), help_text=_(\"Raw passwords are not stored, so there is no way to see this user's password.\")",
      "expected_patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -141,6 +141,8 @@ def save(self, commit=True):\n         user.set_password(self.cleaned_data[\"password1\"])\n         if commit:\n             user.save()\n+            if hasattr(self, \"save_m2m\"):\n+                self.save_m2m()\n         return user\n \n \n",
      "tokens": 382,
      "success": true,
      "similarity": 1.0
    },
    {
      "instance_id": "django__django-12419",
      "generated_patch": "--- a/django/conf/global_settings.py\n+++ b/django/conf/global_settings.py\n@@ -656,7 +656,7 @@\n SECURE_CONTENT_TYPE_NOSNIFF = True\n SECURE_CROSS_ORIGIN_OPENER_POLICY = \"same-origin\"\n SECURE_HSTS_INCLUDE_SUBDOMAINS = False\n SECURE_HSTS_PRELOAD = False\n SECURE_HSTS_SECONDS = 0\n-SECURE_REFERRER_POLICY = \"same-origin\"\n+SECURE_REFERRER_POLICY = \"same-origin\"\n SECURE_SSL_HOST = None\n SECURE_SSL_REDIRECT = False\n SECURE_SSL_REDIRECT_EXEMPT = []\n SECURE_SSL_REDIRECT_HOST = None",
      "expected_patch": "diff --git a/django/conf/global_settings.py b/django/conf/global_settings.py\n--- a/django/conf/global_settings.py\n+++ b/django/conf/global_settings.py\n@@ -637,6 +637,6 @@ def gettext_noop(s):\n SECURE_HSTS_PRELOAD = False\n SECURE_HSTS_SECONDS = 0\n SECURE_REDIRECT_EXEMPT = []\n-SECURE_REFERRER_POLICY = None\n+SECURE_REFERRER_POLICY = 'same-origin'\n SECURE_SSL_HOST = None\n SECURE_SSL_REDIRECT = False\n",
      "tokens": 391,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-15098",
      "generated_patch": "--- a/django/conf/urls/i18n.py\n+++ b/django/conf/urls/i18n.py\n@@ -1,6 +1,7 @@\n from functools import partial\n \n from django.conf import settings\n+from django.utils.translation import get_supported_language_variant\n from django.urls import LocalePrefixPattern, URLPattern, URLResolver, path\n from django.utils.translation import gettext_lazy as _\n \n@@ -8,6 +9,7 @@\n def i18n_patterns(*urls, prefix_default_language=True):\n     \"\"\"\n     Add the language code prefix to every URL pattern within this function.\n     This may only be used in the root URLconf, not in an included URLconf.\n     \"\"\"\n+    languages = [get_supported_language_variant(code) for code, name in settings.LANGUAGES]\n     if not settings.USE_I18N:\n         return list(urls)\n     return [\n@@ -15,7 +17,7 @@\n             LocalePrefixPattern(\n                 prefix_default_language=prefix_default_language\n             ),\n-            list(urls),\n+            list(urls),\n             kwargs=None,\n             app_name=None,\n             namespace=None,\n@@ -23,6 +25,6 @@\n         )\n     ]\n \n--- a/django/urls/resolvers.py\n+++ b/django/urls/resolvers.py\n@@ -1,6 +1,7 @@\n import functools\n import inspect\n import re\n+from django.utils.translation import get_supported_language_variant\n \n from django.conf import settings\n from django.core.checks import Error, Warning\n@@ -369,7 +370,7 @@\n class LocalePrefixPattern:\n     def __init__(self, prefix_default_language=True):\n         self.prefix_default_language = prefix_default_language\n-        self.converters = {'language': settings.LANGUAGES}\n+        self.converters = {'language': [get_supported_language_variant(code) for code, name in settings.LANGUAGES]}\n \n     @property\n     def regex(self):\n@@ -377,7 +378,7 @@\n         # Use a non-capturing group for the language prefix.\n         # The language prefix is optional if prefix_default_language is False.\n         if not self.prefix_default_language:\n-            return re.compile(r'^(?:%s/)?' % '|'.join(re.escape(lang_code) for lang_code, _ in settings.LANGUAGES))\n+            return re.compile(r'^(?:%s/)?' % '|'.join(re.escape(lang_code) for lang_code in self.converters['language']))\n         return re.compile(r'^%s/' % self.language_prefix)\n \n     @property\n@@ -385,7 +386,7 @@\n         from django.utils.translation import get_language\n \n         language = get_language() or settings.LANGUAGE_CODE\n-        return language\n+        return get_supported_language_variant(language)\n \n     def match(self, path):\n         # Check if the path starts with a language prefix.\n@@ -393,7 +394,7 @@\n         if not self.prefix_default_language and path == '':\n             return '', (), {}\n \n-        for language_code, _ in settings.LANGUAGES:\n+        for language_code in self.converters['language']:\n             if path.startswith(language_code + '/'):\n                 return path[len(language_code) + 1:], (), {'language': language_code}\n         return None",
      "expected_patch": "diff --git a/django/utils/translation/trans_real.py b/django/utils/translation/trans_real.py\n--- a/django/utils/translation/trans_real.py\n+++ b/django/utils/translation/trans_real.py\n@@ -43,7 +43,7 @@\n     re.IGNORECASE\n )\n \n-language_code_prefix_re = _lazy_re_compile(r'^/(\\w+([@-]\\w+)?)(/|$)')\n+language_code_prefix_re = _lazy_re_compile(r'^/(\\w+([@-]\\w+){0,2})(/|$)')\n \n \n @receiver(setting_changed)\n",
      "tokens": 1519,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-14711",
      "generated_patch": "--- a/sympy/physics/vector/vector.py\n+++ b/sympy/physics/vector/vector.py\n@@ -56,10 +56,12 @@\n     def __add__(self, other):\n         \"\"\"The add operator for Vector. \"\"\"\n-        #if other == 0: return self\n+        if other == 0:\n+            return self\n         other = _check_vector(other)\n         return Vector(self.args + other.args)\n \n     def __radd__(self, other):\n         \"\"\"The right add operator for Vector. \"\"\"\n-        return self.__add__(other)\n+        if other == 0:\n+            return self\n+        return self.__add__(other)",
      "expected_patch": "diff --git a/sympy/physics/vector/vector.py b/sympy/physics/vector/vector.py\n--- a/sympy/physics/vector/vector.py\n+++ b/sympy/physics/vector/vector.py\n@@ -57,6 +57,8 @@ def __hash__(self):\n \n     def __add__(self, other):\n         \"\"\"The add operator for Vector. \"\"\"\n+        if other == 0:\n+            return self\n         other = _check_vector(other)\n         return Vector(self.args + other.args)\n \n",
      "tokens": 512,
      "success": true,
      "similarity": 1.0
    },
    {
      "instance_id": "sympy__sympy-17139",
      "generated_patch": "--- a/sympy/simplify/fu.py\n+++ b/sympy/simplify/fu.py\n@@ -501,7 +501,7 @@\n     def _f(rv):\n         if not rv.is_Pow:\n             return rv\n-        if (rv.exp < 0) == True:\n+        if rv.exp.is_negative:\n             return pow(rv.base, -rv.exp)\n         return rv\n     return bottom_up(rv, _f)",
      "expected_patch": "diff --git a/sympy/simplify/fu.py b/sympy/simplify/fu.py\n--- a/sympy/simplify/fu.py\n+++ b/sympy/simplify/fu.py\n@@ -500,6 +500,8 @@ def _f(rv):\n         # change is not going to allow a simplification as far as I can tell.\n         if not (rv.is_Pow and rv.base.func == f):\n             return rv\n+        if not rv.exp.is_real:\n+            return rv\n \n         if (rv.exp < 0) == True:\n             return rv\n",
      "tokens": 832,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-14915",
      "generated_patch": "--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -1418,6 +1418,9 @@ class ModelChoiceIteratorValue:\n     def __str__(self):\n         return str(self.value)\n \n+    def __hash__(self):\n+        return hash(self.value)\n+\n \n class ModelChoiceIterator:\n     def __init__(self, field):",
      "expected_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -1166,6 +1166,9 @@ def __init__(self, value, instance):\n     def __str__(self):\n         return str(self.value)\n \n+    def __hash__(self):\n+        return hash(self.value)\n+\n     def __eq__(self, other):\n         if isinstance(other, ModelChoiceIteratorValue):\n             other = other.value\n",
      "tokens": 425,
      "success": true,
      "similarity": 1.0
    },
    {
      "instance_id": "pylint-dev__pylint-7080",
      "generated_patch": "--- a/pylint/lint/pylinter.py\n+++ b/pylint/lint/pylinter.py\n@@ -1,6 +1,7 @@\n \"\"\"Main Pylint class.\"\"\"\n \n from __future__ import annotations\n \n+import os\n import argparse\n import collections\n import contextlib\n@@ -42,6 +43,7 @@\n from pylint.lint.expand_modules import expand_modules\n from pylint.lint.message_state_handler import _MessageStateHandler\n from pylint.lint.parallel import check_parallel\n+from pylint.utils.file_state import is_ignored_path\n from pylint.lint.report_functions import (\n     report_messages_by_module_stats,\n     report_messages_stats,\n@@ -1115,6 +1117,20 @@\n         self._ignore_paths = [re.compile(p) for p in self.config.ignore_paths]\n         self._ignore_patterns = [re.compile(p) for p in self.config.ignore_patterns]\n \n+    def _filter_ignored_paths(self, files_or_modules: list[str]) -> list[str]:\n+        if not self._ignore_paths:\n+            return files_or_modules\n+        filtered: list[str] = []\n+        for item in files_or_modules:\n+            # Only filter filesystem paths; module names are handled elsewhere.\n+            if os.path.exists(item):\n+                if is_ignored_path(item, self._ignore_paths):\n+                    continue\n+            filtered.append(item)\n+        return filtered\n+\n     def _discover_files(self, files_or_modules: list[str]) -> list[str]:\n         \"\"\"Discover python modules and packages in the given list of files or modules.\"\"\"\n         if self.config.recursive:\n@@ -1122,7 +1138,7 @@\n             # Expand directories and packages to all python files.\n             expanded = expand_modules(\n                 files_or_modules,\n                 self.config.ignore,\n                 self.config.ignore_patterns,\n                 self.config.ignore_paths,\n                 self.config.ignore_paths_regex,\n             )\n-            return expanded\n+            return self._filter_ignored_paths(expanded)\n         return files_or_modules",
      "expected_patch": "diff --git a/pylint/lint/expand_modules.py b/pylint/lint/expand_modules.py\n--- a/pylint/lint/expand_modules.py\n+++ b/pylint/lint/expand_modules.py\n@@ -52,6 +52,7 @@ def _is_ignored_file(\n     ignore_list_re: list[Pattern[str]],\n     ignore_list_paths_re: list[Pattern[str]],\n ) -> bool:\n+    element = os.path.normpath(element)\n     basename = os.path.basename(element)\n     return (\n         basename in ignore_list\n",
      "tokens": 7444,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-20428",
      "generated_patch": "--- a/sympy/polys/polytools.py\n+++ b/sympy/polys/polytools.py\n@@ -1,6 +1,7 @@\n \"\"\"User-friendly public interface to polynomial functions. \"\"\"\n \n from __future__ import annotations\n+from sympy.polys.densebasic import dmp_strip\n \n from sympy.core import Add, Expr, Mul, S, Symbol, sympify\n from sympy.core.basic import Basic\n from sympy.core.containers import Tuple\n@@ -5720,6 +5721,10 @@ class Poly(Basic):\n         if not opt.domain:\n             opt.domain = dom\n \n+        # Ensure the internal DMP representation is stripped. Some operations\n+        # (e.g. clear_denoms) can produce an unstripped zero like [0].\n+        rep = dmp_strip(rep, lev, dom)\n         return cls._from_rep(rep, opt)\n \n     @classmethod\n     def _from_list(cls, rep, gens, domain=None, modulus=None, symmetric=None, order=None):\n--- a/sympy/polys/polytools.py\n+++ b/sympy/polys/polytools.py\n@@ -3600,7 +3605,7 @@ class Poly(Basic):\n         if not denoms:\n             return S.One, f\n \n         coeff = reduce(lcm, denoms)\n-        return coeff, f.mul_ground(coeff)\n+        return coeff, f.mul_ground(coeff).strip()\n \n     def rat_clear_denoms(f, g):\n         \"\"\"Clear denominators in a rational function. \"\"\"",
      "expected_patch": "diff --git a/sympy/polys/domains/expressiondomain.py b/sympy/polys/domains/expressiondomain.py\n--- a/sympy/polys/domains/expressiondomain.py\n+++ b/sympy/polys/domains/expressiondomain.py\n@@ -120,7 +120,7 @@ def __ne__(f, g):\n             return not f == g\n \n         def __bool__(f):\n-            return f.ex != 0\n+            return not f.ex.is_zero\n \n         def gcd(f, g):\n             from sympy.polys import gcd\n",
      "tokens": 1677,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "matplotlib__matplotlib-23314",
      "generated_patch": "--- a/lib/mpl_toolkits/mplot3d/axes3d.py\n+++ b/lib/mpl_toolkits/mplot3d/axes3d.py\n@@ -412,6 +412,9 @@ class Axes3D(Axes):\n         self._axis3don = True\n         self._projection_init = projection_init\n \n+    def draw(self, renderer):\n+        if not self.get_visible():\n+            return\n+        super().draw(renderer)\n+\n     def set_axis_off(self):\n         self._axis3don = False\n         self.stale = True",
      "expected_patch": "diff --git a/lib/mpl_toolkits/mplot3d/axes3d.py b/lib/mpl_toolkits/mplot3d/axes3d.py\n--- a/lib/mpl_toolkits/mplot3d/axes3d.py\n+++ b/lib/mpl_toolkits/mplot3d/axes3d.py\n@@ -387,6 +387,8 @@ def apply_aspect(self, position=None):\n \n     @martist.allow_rasterization\n     def draw(self, renderer):\n+        if not self.get_visible():\n+            return\n         self._unstale_viewLim()\n \n         # draw the background patch\n",
      "tokens": 449,
      "success": true,
      "similarity": 1.0
    },
    {
      "instance_id": "sympy__sympy-19637",
      "generated_patch": "--- a/sympy/core/sympify.py\n+++ b/sympy/core/sympify.py\n@@ -1,6 +1,7 @@\n \"\"\"sympify -- convert objects SymPy internal format\"\"\"\n \n from __future__ import annotations\n+import re\n \n from sympy.core.basic import Basic\n from sympy.core.sympify import SympifyError\n@@ -420,6 +421,7 @@ def kernS(s):\n     \"\"\"\n     # kernS is used by sympify and parse_expr\n     # It is used to insert * between adjacent symbols and numbers.\n+    kern = re.compile(r'(?:(?<=\\d)(?=[A-Za-z_(]))|(?:(?<=[A-Za-z_)])(?=\\d))|(?:(?<=[A-Za-z_)])(?=[A-Za-z_(]))')\n \n     # if there is no kern in s, return s\n     hit = kern in s\n@@ -427,7 +429,7 @@ def kernS(s):\n         return s\n \n     # insert * between adjacent symbols and numbers\n-    return kern.sub('*', s)\n+    return kern.sub('*', s)",
      "expected_patch": "diff --git a/sympy/core/sympify.py b/sympy/core/sympify.py\n--- a/sympy/core/sympify.py\n+++ b/sympy/core/sympify.py\n@@ -513,7 +513,9 @@ def kernS(s):\n             while kern in s:\n                 kern += choice(string.ascii_letters + string.digits)\n             s = s.replace(' ', kern)\n-        hit = kern in s\n+            hit = kern in s\n+        else:\n+            hit = False\n \n     for i in range(2):\n         try:\n",
      "tokens": 405,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "pydata__xarray-3677",
      "generated_patch": "--- a/xarray/core/merge.py\n+++ b/xarray/core/merge.py\n@@ -820,6 +820,8 @@ def dataset_merge_method(\n     fill_value: Any = dtypes.NA,\n ) -> Dataset:\n     \"\"\"Merge method for Dataset objects.\"\"\"\n+    if isinstance(other, DataArray):\n+        other = other.to_dataset()\n     return merge_core(\n         [dataset, other],\n         compat=compat,\n         join=join,\n         combine_attrs=combine_attrs,\n         priority_arg=priority_arg,\n         fill_value=fill_value,\n     )",
      "expected_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -3604,6 +3604,7 @@ def merge(\n             If any variables conflict (see ``compat``).\n         \"\"\"\n         _check_inplace(inplace)\n+        other = other.to_dataset() if isinstance(other, xr.DataArray) else other\n         merge_result = dataset_merge_method(\n             self,\n             other,\n",
      "tokens": 619,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-17029",
      "generated_patch": "--- a/django/apps/registry.py\n+++ b/django/apps/registry.py\n@@ -370,6 +370,7 @@ class Apps:\n     def clear_cache(self):\n         \"\"\"\n         Clear all internal caches, for methods that alter the app registry.\n         \"\"\"\n         self.get_models.cache_clear()\n+        self.get_swappable_settings_name.cache_clear()\n         if self.ready:\n             # Call expire cache on each model. This will purge\n             # the relation tree and the fields cache.\n             for app_config in self.app_configs.values():",
      "expected_patch": "diff --git a/django/apps/registry.py b/django/apps/registry.py\n--- a/django/apps/registry.py\n+++ b/django/apps/registry.py\n@@ -373,6 +373,7 @@ def clear_cache(self):\n \n         This is mostly used in tests.\n         \"\"\"\n+        self.get_swappable_settings_name.cache_clear()\n         # Call expire cache on each model. This will purge\n         # the relation tree and the fields cache.\n         self.get_models.cache_clear()\n",
      "tokens": 441,
      "success": true,
      "similarity": 1.0
    },
    {
      "instance_id": "django__django-11880",
      "generated_patch": "--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -1,3 +1,4 @@\n+import copy\n import datetime\n import decimal\n import re\n@@ -197,10 +198,14 @@\n     def __deepcopy__(self, memo):\n         result = copy.copy(self)\n         memo[id(self)] = result\n         result.widget = copy.deepcopy(self.widget, memo)\n         result.validators = self.validators[:]\n+        # error_messages is a dict that may contain nested structures (e.g.\n+        # lazy objects). Ensure it's not shared between field copies.\n+        result.error_messages = copy.deepcopy(self.error_messages, memo)\n         return result\n \n     def prepare_value(self, value):\n         return value",
      "expected_patch": "diff --git a/django/forms/fields.py b/django/forms/fields.py\n--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -199,6 +199,7 @@ def __deepcopy__(self, memo):\n         result = copy.copy(self)\n         memo[id(self)] = result\n         result.widget = copy.deepcopy(self.widget, memo)\n+        result.error_messages = self.error_messages.copy()\n         result.validators = self.validators[:]\n         return result\n \n",
      "tokens": 512,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-15863",
      "generated_patch": "--- a/django/template/defaultfilters.py\n+++ b/django/template/defaultfilters.py\n@@ -1,12 +1,13 @@\n import datetime\n import functools\n import json\n import math\n import re\n import unicodedata\n from decimal import Decimal, InvalidOperation, ROUND_HALF_UP\n+from decimal import DecimalException\n \n from django.conf import settings\n from django.template.defaultfilters import stringfilter\n from django.utils import formats\n from django.utils.dateformat import format as date_format\n@@ -205,18 +206,23 @@ def floatformat(text, arg=-1):\n     try:\n         p = int(arg)\n     except (TypeError, ValueError):\n         return input\n \n-    try:\n-        d = Decimal(str(float(input)))\n-    except (ValueError, InvalidOperation, TypeError):\n-        return input\n+    if isinstance(input, Decimal):\n+        d = input\n+    else:\n+        try:\n+            d = Decimal(str(input))\n+        except (ValueError, InvalidOperation, TypeError, DecimalException):\n+            try:\n+                d = Decimal(str(float(input)))\n+            except (ValueError, InvalidOperation, TypeError, DecimalException):\n+                return input\n \n     try:\n         m = int(d) - d\n     except (ValueError, OverflowError, InvalidOperation):\n         return input",
      "expected_patch": "diff --git a/django/template/defaultfilters.py b/django/template/defaultfilters.py\n--- a/django/template/defaultfilters.py\n+++ b/django/template/defaultfilters.py\n@@ -149,7 +149,7 @@ def floatformat(text, arg=-1):\n             use_l10n = False\n             arg = arg[:-1] or -1\n     try:\n-        input_val = repr(text)\n+        input_val = str(text)\n         d = Decimal(input_val)\n     except InvalidOperation:\n         try:\n",
      "tokens": 562,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-16886",
      "generated_patch": "--- a/sympy/crypto/crypto.py\n+++ b/sympy/crypto/crypto.py\n@@ -1,6 +1,6 @@\n MORSE_CODE_DICT = {\n     \".-\": \"A\", \"-...\": \"B\", \"-.-.\": \"C\", \"-..\": \"D\", \".\": \"E\",\n     \"..-.\": \"F\", \"--.\": \"G\", \"....\": \"H\", \"..\": \"I\", \".---\": \"J\",\n     \"-.-\": \"K\", \".-..\": \"L\", \"--\": \"M\", \"-.\": \"N\", \"---\": \"O\",\n     \".--.\": \"P\", \"--.-\": \"Q\", \".-.\": \"R\", \"...\": \"S\", \"-\": \"T\",\n     \"..-\": \"U\", \"...-\": \"V\", \".--\": \"W\", \"-..-\": \"X\", \"-.--\": \"Y\",\n     \"--..\": \"Z\", \"-----\": \"0\",\n-    \"----\": \"1\",\n+    \".----\": \"1\",\n     \"..---\": \"2\", \"...--\": \"3\", \"....-\": \"4\", \".....\": \"5\",\n     \"-....\": \"6\", \"--...\": \"7\", \"---..\": \"8\", \"----.\": \"9\"\n }",
      "expected_patch": "diff --git a/sympy/crypto/crypto.py b/sympy/crypto/crypto.py\n--- a/sympy/crypto/crypto.py\n+++ b/sympy/crypto/crypto.py\n@@ -1520,7 +1520,7 @@ def decipher_kid_rsa(msg, key):\n     \"..-\": \"U\", \"...-\": \"V\",\n     \".--\": \"W\", \"-..-\": \"X\",\n     \"-.--\": \"Y\", \"--..\": \"Z\",\n-    \"-----\": \"0\", \"----\": \"1\",\n+    \"-----\": \"0\", \".----\": \"1\",\n     \"..---\": \"2\", \"...--\": \"3\",\n     \"....-\": \"4\", \".....\": \"5\",\n     \"-....\": \"6\", \"--...\": \"7\",\n",
      "tokens": 418,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "pytest-dev__pytest-6202",
      "generated_patch": "--- a/src/_pytest/python.py\n+++ b/src/_pytest/python.py\n@@ -271,7 +271,7 @@\n     def getmodpath(self, stopatmodule: bool = True) -> str:\n         \"\"\"Return python path relative to the rootdir.\"\"\"\n         s = self.nodeid\n-        return s.replace(\".[\", \"[\")\n+        return s",
      "expected_patch": "diff --git a/src/_pytest/python.py b/src/_pytest/python.py\n--- a/src/_pytest/python.py\n+++ b/src/_pytest/python.py\n@@ -285,8 +285,7 @@ def getmodpath(self, stopatmodule=True, includemodule=False):\n                     break\n             parts.append(name)\n         parts.reverse()\n-        s = \".\".join(parts)\n-        return s.replace(\".[\", \"[\")\n+        return \".\".join(parts)\n \n     def reportinfo(self):\n         # XXX caching?\n",
      "tokens": 827,
      "success": true,
      "similarity": 0.3333333333333333
    },
    {
      "instance_id": "pytest-dev__pytest-5262",
      "generated_patch": "--- a/src/_pytest/capture.py\n+++ b/src/_pytest/capture.py\n@@ -404,6 +404,7 @@ class EncodedFile(object):\n     def __init__(self, buffer, encoding):\n         self.buffer = buffer\n         self.encoding = encoding\n+        self.mode = getattr(buffer, \"mode\", \"\").replace(\"b\", \"\")\n \n     def write(self, obj):\n         if isinstance(obj, six.text_type):\n             obj = obj.encode(self.encoding, \"replace\")",
      "expected_patch": "diff --git a/src/_pytest/capture.py b/src/_pytest/capture.py\n--- a/src/_pytest/capture.py\n+++ b/src/_pytest/capture.py\n@@ -447,6 +447,10 @@ def name(self):\n         \"\"\"Ensure that file.name is a string.\"\"\"\n         return repr(self.buffer)\n \n+    @property\n+    def mode(self):\n+        return self.buffer.mode.replace(\"b\", \"\")\n+\n     def __getattr__(self, name):\n         return getattr(object.__getattribute__(self, \"buffer\"), name)\n \n",
      "tokens": 1382,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "pytest-dev__pytest-7982",
      "generated_patch": "--- a/src/_pytest/pathlib.py\n+++ b/src/_pytest/pathlib.py\n@@ -1,6 +1,7 @@\n from __future__ import annotations\n \n import fnmatch\n+import os\n import os.path\n from pathlib import Path\n from typing import Callable\n@@ -430,7 +431,7 @@ def visit(\n     ignore: Callable[[Path], bool] | None = None,\n ) -> Iterator[Path]:\n     \"\"\"Walk a directory recursively, yielding all files.\n \n     :param path: The directory to walk.\n     :param recurse: Whether to recurse into subdirectories.\n     :param ignore: A callable that takes a path and returns True if it should be ignored.\n     \"\"\"\n-    entries = scandir(path, follow_symlinks=False)\n+    entries = scandir(path)\n     for entry in entries:\n         if ignore is not None and ignore(entry):\n             continue\n         yield entry\n         if recurse and entry.is_dir():\n             yield from visit(entry, recurse=recurse, ignore=ignore)",
      "expected_patch": "diff --git a/src/_pytest/pathlib.py b/src/_pytest/pathlib.py\n--- a/src/_pytest/pathlib.py\n+++ b/src/_pytest/pathlib.py\n@@ -558,7 +558,7 @@ def visit(\n     entries = sorted(os.scandir(path), key=lambda entry: entry.name)\n     yield from entries\n     for entry in entries:\n-        if entry.is_dir(follow_symlinks=False) and recurse(entry):\n+        if entry.is_dir() and recurse(entry):\n             yield from visit(entry.path, recurse)\n \n \n",
      "tokens": 434,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-15349",
      "generated_patch": "--- a/sympy/algebras/quaternion.py\n+++ b/sympy/algebras/quaternion.py\n@@ -486,7 +486,7 @@\n         m = Matrix([[1 - 2*(c**2 + d**2), 2*(b*c - a*d), 2*(a*c + b*d)],\n                     [2*(b*c + a*d), 1 - 2*(b**2 + d**2), 2*(c*d - a*b)],\n-                    [2*(b*d - a*c), 2*(a*b + c*d), 1 - 2*(b**2 + c**2)]])\n+                    [2*(b*d - a*c), 2*(a*b - c*d), 1 - 2*(b**2 + c**2)]])\n         return m",
      "expected_patch": "diff --git a/sympy/algebras/quaternion.py b/sympy/algebras/quaternion.py\n--- a/sympy/algebras/quaternion.py\n+++ b/sympy/algebras/quaternion.py\n@@ -529,7 +529,7 @@ def to_rotation_matrix(self, v=None):\n \n         m10 = 2*s*(q.b*q.c + q.d*q.a)\n         m11 = 1 - 2*s*(q.b**2 + q.d**2)\n-        m12 = 2*s*(q.c*q.d + q.b*q.a)\n+        m12 = 2*s*(q.c*q.d - q.b*q.a)\n \n         m20 = 2*s*(q.b*q.d - q.c*q.a)\n         m21 = 2*s*(q.c*q.d + q.b*q.a)\n",
      "tokens": 498,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "pytest-dev__pytest-7521",
      "generated_patch": "--- a/src/_pytest/capture.py\n+++ b/src/_pytest/capture.py\n@@ -1,6 +1,7 @@\n # mypy: allow-untyped-defs\n from __future__ import annotations\n \n+import io\n import os\n import sys\n from contextlib import contextmanager\n@@ -488,6 +489,12 @@ class FDCaptureBinary(CaptureBase):\n     def snap(self) -> bytes:\n         self._assert_state(\"snap\", (\"started\", \"suspended\"))\n         self.tmpfile.seek(0)\n+        # Ensure we read raw bytes without any newline translation.\n+        # Some Python versions/platforms can apply universal newline\n+        # conversion when reading from a file opened in text mode.\n+        if isinstance(self.tmpfile, io.TextIOBase):\n+            return self.tmpfile.buffer.read()\n         res = self.tmpfile.read()\n         self.tmpfile.seek(0)\n         self.tmpfile.truncate()\n         return res",
      "expected_patch": "diff --git a/src/_pytest/capture.py b/src/_pytest/capture.py\n--- a/src/_pytest/capture.py\n+++ b/src/_pytest/capture.py\n@@ -388,6 +388,7 @@ def __init__(self, targetfd: int) -> None:\n                 TemporaryFile(buffering=0),  # type: ignore[arg-type]\n                 encoding=\"utf-8\",\n                 errors=\"replace\",\n+                newline=\"\",\n                 write_through=True,\n             )\n             if targetfd in patchsysdict:\n",
      "tokens": 1370,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-16485",
      "generated_patch": "--- a/django/template/defaultfilters.py\n+++ b/django/template/defaultfilters.py\n@@ -1,6 +1,7 @@\n import datetime\n import re\n from decimal import Decimal, InvalidOperation, ROUND_HALF_UP\n+from decimal import localcontext\n \n from django.utils import formats\n from django.utils.dateformat import format as date_format\n@@ -199,7 +200,7 @@ def floatformat(text, arg=-1):\n     try:\n         input_val = Decimal(str(text))\n     except InvalidOperation:\n         return \"\"\n-    if not input_val.is_finite():\n+    if not input_val.is_finite():\n         return str(text)\n \n     try:\n@@ -210,13 +211,17 @@ def floatformat(text, arg=-1):\n     except (ValueError, TypeError):\n         return \"\"\n \n-    if p < 0:\n-        exp = input_val.as_tuple().exponent\n-        if exp >= 0:\n-            p = 0\n-        else:\n-            p = -exp\n+    if p < 0:\n+        exp = input_val.as_tuple().exponent\n+        if exp >= 0:\n+            p = 0\n+        else:\n+            p = -exp\n \n     # Set the precision high enough to avoid rounding errors.\n-    prec = max(p, input_val.adjusted() + 1)\n-    input_val = input_val.quantize(Decimal(1).scaleb(-p), rounding=ROUND_HALF_UP, context=Context(prec=prec))\n+    prec = max(p, input_val.adjusted() + 1)\n+    prec = max(1, prec)\n+    with localcontext() as ctx:\n+        ctx.prec = prec\n+        input_val = input_val.quantize(Decimal(1).scaleb(-p), rounding=ROUND_HALF_UP, context=ctx)\n \n     if p == 0:\n         return formats.number_format(input_val, 0)",
      "expected_patch": "diff --git a/django/template/defaultfilters.py b/django/template/defaultfilters.py\n--- a/django/template/defaultfilters.py\n+++ b/django/template/defaultfilters.py\n@@ -168,7 +168,7 @@ def floatformat(text, arg=-1):\n     except (ValueError, OverflowError, InvalidOperation):\n         return input_val\n \n-    if not m and p < 0:\n+    if not m and p <= 0:\n         return mark_safe(\n             formats.number_format(\n                 \"%d\" % (int(d)),\n",
      "tokens": 573,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "pydata__xarray-6721",
      "generated_patch": "--- a/xarray/core/common.py\n+++ b/xarray/core/common.py\n@@ -1808,15 +1808,20 @@ def get_chunksizes(variables):\n     \"\"\"\n     chunks: dict[Any, tuple[int, ...]] = {}\n     for v in variables:\n-        if hasattr(v.data, \"chunks\"):\n-            for dim, c in v.chunksizes.items():\n-                if dim in chunks and c != chunks[dim]:\n-                    raise ValueError(\n-                        \"Object has inconsistent chunks along dimension %s. \"\n-                        \"This can be fixed by calling unify_chunks().\" % dim\n-                    )\n-                chunks[dim] = c\n+        # Avoid triggering Variable.data / Variable.values, which can materialize\n+        # lazily-loaded backend arrays (e.g. zarr) into memory.\n+        data = v._data\n+        if hasattr(data, \"chunks\"):\n+            for dim, c in v.chunksizes.items():\n+                if dim in chunks and c != chunks[dim]:\n+                    raise ValueError(\n+                        \"Object has inconsistent chunks along dimension %s. \"\n+                        \"This can be fixed by calling unify_chunks().\" % dim\n+                    )\n+                chunks[dim] = c\n     return chunks",
      "expected_patch": "diff --git a/xarray/core/common.py b/xarray/core/common.py\n--- a/xarray/core/common.py\n+++ b/xarray/core/common.py\n@@ -2023,7 +2023,7 @@ def get_chunksizes(\n \n     chunks: dict[Any, tuple[int, ...]] = {}\n     for v in variables:\n-        if hasattr(v.data, \"chunks\"):\n+        if hasattr(v._data, \"chunks\"):\n             for dim, c in v.chunksizes.items():\n                 if dim in chunks and c != chunks[dim]:\n                     raise ValueError(\n",
      "tokens": 3065,
      "success": true,
      "similarity": 0.5
    },
    {
      "instance_id": "psf__requests-6028",
      "generated_patch": "--- a/requests/adapters.py\n+++ b/requests/adapters.py\n@@ -1,6 +1,7 @@\n import os.path\n import socket  # noqa: F401\n import typing\n+import urllib.parse\n \n from urllib3.exceptions import ClosedPoolError\n from urllib3.exceptions import ConnectTimeoutError\n@@ -1,6 +1,7 @@\n from urllib3.exceptions import HTTPError as _HTTPError\n from urllib3.exceptions import InvalidHeader as _InvalidHeader\n from urllib3.exceptions import LocationParseError\n+from urllib3.util import make_headers\n from urllib3.exceptions import MaxRetryError\n from urllib3.exceptions import NewConnectionError\n from urllib3.exceptions import ProtocolError\n@@ -1,6 +1,7 @@\n from .auth import _basic_auth_str\n from .compat import basestring\n from .compat import urlparse\n+from .compat import unquote\n from .compat import urlunparse\n from .exceptions import ConnectionError\n from .exceptions import ConnectTimeout\n@@ -1,6 +1,7 @@\n from .exceptions import ProxyError\n from .exceptions import ReadTimeout\n from .exceptions import RetryError\n+from .exceptions import InvalidURL\n from .exceptions import SSLError\n from .exceptions import Timeout\n from .exceptions import TooManyRedirects\n@@ -1,6 +1,7 @@\n from .models import Response\n from .structures import CaseInsensitiveDict\n from .utils import DEFAULT_CA_BUNDLE_PATH\n+from .utils import get_auth_from_url\n from .utils import extract_zipped_paths\n from .utils import get_encoding_from_headers\n from .utils import prepend_scheme_if_needed\n@@ -1,6 +1,7 @@\n from .utils import should_bypass_proxies\n from .utils import urldefragauth\n from .utils import urlparse as _urlparse\n+from .utils import urlunparse as _urlunparse\n \n \n DEFAULT_POOLBLOCK = False\n@@ -1,6 +1,7 @@\n class HTTPAdapter(BaseAdapter):\n     \"\"\"The built-in HTTP Adapter for urllib3.\n \n     Provides a general-case interface for Requests sessions to contact HTTP and\n@@ -1,6 +1,7 @@\n     def proxy_manager_for(self, proxy, **proxy_kwargs):\n         \"\"\"Return urllib3 ProxyManager for the given proxy.\n \n         This method should not be called from user code, and is only exposed for\n@@ -1,6 +1,7 @@\n         if proxy in self.proxy_manager:\n             return self.proxy_manager[proxy]\n \n+        proxy_headers = proxy_kwargs.pop(\"proxy_headers\", None)\n         proxy_headers = self.proxy_headers(proxy)\n \n         if proxy.lower().startswith(\"socks\"):\n@@ -1,6 +1,7 @@\n             manager = self.proxy_manager[proxy] = SOCKSProxyManager(\n                 proxy,\n                 username=username,\n                 password=password,\n                 **proxy_kwargs\n             )\n         else:\n             manager = self.proxy_manager[proxy] = proxy_from_url(\n                 proxy,\n                 proxy_headers=proxy_headers,\n                 **proxy_kwargs\n             )\n \n         return manager\n@@ -1,6 +1,7 @@\n     def proxy_headers(self, proxy):\n         \"\"\"Returns a dictionary of the headers to add to any request sent\n         through a proxy. This works with urllib3 magic to ensure that they are\n         correctly sent to the proxy, rather than in a tunnelled request if\n         CONNECT is being used.\n         \"\"\"\n-        headers = {}\n-        username, password = get_auth_from_url(proxy)\n-        if username and password:\n-            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n-        return headers\n+        headers = {}\n+        try:\n+            username, password = get_auth_from_url(proxy)\n+        except (ValueError, TypeError):\n+            raise InvalidURL(f\"Invalid proxy URL: {proxy!r}\")\n+\n+        if username is None and password is None:\n+            return headers\n+\n+        # Python 3.8.12 tightened URL parsing/validation; ensure proxy auth is\n+        # derived from the parsed URL components and properly unquoted.\n+        if username is not None:\n+            username = unquote(username)\n+        if password is not None:\n+            password = unquote(password)\n+\n+        if username is not None and password is not None:\n+            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n+        return headers",
      "expected_patch": "diff --git a/requests/utils.py b/requests/utils.py\n--- a/requests/utils.py\n+++ b/requests/utils.py\n@@ -974,6 +974,10 @@ def prepend_scheme_if_needed(url, new_scheme):\n     if not netloc:\n         netloc, path = path, netloc\n \n+    if auth:\n+        # parse_url doesn't provide the netloc with auth\n+        # so we'll add it ourselves.\n+        netloc = '@'.join([auth, netloc])\n     if scheme is None:\n         scheme = new_scheme\n     if path is None:\n",
      "tokens": 1407,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "pytest-dev__pytest-7432",
      "generated_patch": "--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -1,6 +1,7 @@\n from __future__ import annotations\n \n import dataclasses\n+import inspect\n from dataclasses import dataclass\n from typing import Any\n from typing import Callable\n from typing import cast\n@@ -210,6 +211,22 @@ def pytest_runtest_setup(item: Item) -> None:\n     if skip:\n         raise skip.Exception(skip.reason)\n \n+def _is_internal_skip_location(filename: str) -> bool:\n+    # When --runxfail is enabled, we might end up re-raising a skip from within\n+    # this module, which would incorrectly report the skip location here.\n+    return filename.replace(\"\\\\\", \"/\").endswith(\"/_pytest/skipping.py\")\n+\n+def _fix_skip_location(report: TestReport, item: Item) -> None:\n+    if report.outcome != \"skipped\":\n+        return\n+    if not report.longrepr or not isinstance(report.longrepr, tuple):\n+        return\n+    filename, lineno, reason = report.longrepr\n+    if _is_internal_skip_location(str(filename)):\n+        report.longrepr = (str(item.fspath), item.location[1] + 1, reason)\n+\n \n def pytest_runtest_makereport(item: Item, call: CallInfo[None]) -> None:\n     if not call.excinfo:\n@@ -229,6 +246,7 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]) -> None:\n     if item.config.option.runxfail:\n         if call.excinfo.errisinstance(xfail.Exception):\n             call.excinfo = None  # type: ignore[assignment]\n+        return\n \n-        if call.excinfo and call.excinfo.errisinstance(skip.Exception):\n-            # When --runxfail is enabled, we might end up re-raising a skip from\n-            # within this module, which would incorrectly report the skip location.\n-            # Fix it up to point to the test item instead.\n-            rep = item._store.get(\"rep_call\")\n-            if rep is not None:\n-                _fix_skip_location(rep, item)\n+    rep = item._store.get(\"rep_call\")\n+    if rep is not None:\n+        _fix_skip_location(rep, item)",
      "expected_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -291,7 +291,8 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n             else:\n                 rep.outcome = \"passed\"\n                 rep.wasxfail = xfailed.reason\n-    elif (\n+\n+    if (\n         item._store.get(skipped_by_mark_key, True)\n         and rep.skipped\n         and type(rep.longrepr) is tuple\n",
      "tokens": 803,
      "success": true,
      "similarity": 0.3333333333333333
    },
    {
      "instance_id": "django__django-15741",
      "generated_patch": "--- a/django/utils/formats.py\n+++ b/django/utils/formats.py\n@@ -1,6 +1,7 @@\n from __future__ import unicode_literals\n \n from django.conf import settings\n+from django.utils.encoding import force_str\n from django.utils import dateformat, numberformat\n from django.utils.functional import lazy\n from django.utils.translation import get_language, to_locale\n@@ -92,6 +93,7 @@ def get_format(format_type, lang=None, use_l10n=None):\n     \"\"\"\n     if use_l10n is None:\n         use_l10n = True\n+    format_type = force_str(format_type)\n     if use_l10n and lang is None:\n         lang = get_language()\n     cache_key = (format_type, lang, use_l10n)",
      "expected_patch": "diff --git a/django/utils/formats.py b/django/utils/formats.py\n--- a/django/utils/formats.py\n+++ b/django/utils/formats.py\n@@ -113,6 +113,7 @@ def get_format(format_type, lang=None, use_l10n=None):\n             use_l10n = settings.USE_L10N\n     if use_l10n and lang is None:\n         lang = get_language()\n+    format_type = str(format_type)  # format_type may be lazy.\n     cache_key = (format_type, lang)\n     try:\n         return _format_cache[cache_key]\n",
      "tokens": 344,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-12209",
      "generated_patch": "--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -1039,12 +1039,18 @@\n         if not meta.auto_created:\n             pre_save.send(\n                 sender=origin, instance=self, raw=raw, using=using, update_fields=update_fields\n             )\n \n         # A transaction isn't needed if one query is issued.\n         if meta.parents:\n             context_manager = transaction.atomic(using=using, savepoint=False)\n         else:\n             context_manager = transaction.mark_for_rollback_on_error(using=using)\n         with context_manager:\n             parent_inserted = False\n             if not raw:\n                 for parent, field in meta.parents.items():\n                     # At this point, parent's primary key field may be unknown\n                     # (for example, a UUIDField with default set). If so, assign\n                     # it.\n                     if field and getattr(self, parent._meta.pk.attname) is None:\n                         setattr(self, parent._meta.pk.attname, self._get_pk_val(parent._meta))\n                         if getattr(self, parent._meta.pk.attname) is None:\n                             setattr(self, parent._meta.pk.attname, parent._meta.pk.get_pk_value_on_save(self))\n                     parent_inserted = self._save_parents(\n                         cls=parent, using=using, update_fields=update_fields\n                     ) or parent_inserted\n             updated = self._save_table(\n                 raw,\n                 cls,\n                 force_insert or parent_inserted,\n                 force_update,\n                 using,\n                 update_fields,\n             )\n         # Store the database on which the object was saved\n         self._state.db = using\n         # Once saved, this is no longer a to-be-added instance.\n         self._state.adding = False\n \n         # Signal that the save is complete\n         if not meta.auto_created:\n             post_save.send(\n                 sender=origin,\n                 instance=self,\n                 created=(not updated),\n                 update_fields=update_fields,\n                 raw=raw,\n                 using=using,\n             )\n \n@@ -1052,6 +1058,14 @@\n     def _save_table(\n         self,\n         raw=False,\n         cls=None,\n         force_insert=False,\n         force_update=False,\n         using=None,\n         update_fields=None,\n     ):\n         \"\"\"\n         Do the heavy-lifting involved in saving. Update or insert the data\n         for a single table.\n         \"\"\"\n         meta = cls._meta\n         non_pks = [f for f in meta.local_concrete_fields if not f.primary_key]\n         if update_fields:\n             non_pks = [f for f in non_pks if f.name in update_fields]\n \n         pk_val = self._get_pk_val(meta)\n         if pk_val is None:\n             pk_val = meta.pk.get_pk_value_on_save(self)\n             setattr(self, meta.pk.attname, pk_val)\n+        else:\n+            # If an explicit primary key value is set, prefer an UPDATE over an\n+            # INSERT. This preserves historical behavior for primary keys with\n+            # defaults (e.g. UUIDField(default=uuid4)) and avoids attempting a\n+            # duplicate INSERT when saving a new instance with an existing pk.\n+            force_insert = False\n \n         pk_set = pk_val is not None\n         if not pk_set and (force_update or update_fields):\n             raise ValueError(\"Cannot force an update in save() with no primary key.\")\n \n         updated = False\n         # If possible, try an UPDATE. If that doesn't update anything, do an INSERT.\n         if pk_set and not force_insert:\n             base_qs = cls._base_manager.using(using)\n             values = [\n                 (\n                     f,\n                     None,\n                     (getattr(self, f.attname) if raw else f.pre_save(self, False)),\n                 )\n                 for f in non_pks\n             ]\n             forced_update = update_fields or force_update\n             updated = self._do_update(\n                 base_qs, using, pk_val, values, update_fields, forced_update\n             )\n             if force_update and not updated:\n                 raise DatabaseError(\"Forced update did not affect any rows.\")\n             if update_fields and not updated:\n                 raise DatabaseError(\"Save with update_fields did not affect any rows.\")\n \n         if not updated:\n             if meta.order_with_respect_to:\n                 # If this is a model with an order_with_respect_to\n                 # field, set the _order field.\n                 field = meta.order_with_respect_to\n                 filter_args = field.get_filter_kwargs_for_object(self)\n                 self._order = cls._base_manager.using(using).filter(**filter_args).count()\n             fields = meta.local_concrete_fields\n             if not pk_set:\n                 fields = [f for f in fields if f is not meta.auto_field]\n             returning_fields = meta.db_returning_fields\n             results = self._do_insert(\n                 cls._base_manager, using, fields, returning_fields, raw\n             )\n             if results:\n                 for value, field in zip(results[0], returning_fields):\n                     setattr(self, field.attname, value)\n         return updated",
      "expected_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -849,6 +849,7 @@ def _save_table(self, raw=False, cls=None, force_insert=False,\n         updated = False\n         # Skip an UPDATE when adding an instance and primary key has a default.\n         if (\n+            not raw and\n             not force_insert and\n             self._state.adding and\n             self._meta.pk.default and\n",
      "tokens": 1428,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "astropy__astropy-12907",
      "generated_patch": "--- a/astropy/modeling/separable.py\n+++ b/astropy/modeling/separable.py\n@@ -1,6 +1,7 @@\n # Licensed under a 3-clause BSD style license - see LICENSE.rst\n \n import numpy as np\n+from astropy.modeling.core import CompoundModel\n \n __all__ = [\"separability_matrix\"]\n \n@@ -15,6 +16,18 @@ def separability_matrix(transform):\n     \"\"\"\n     Compute the separability matrix for a transform.\n \n+    Notes\n+    -----\n+    For nested compound models, the separability matrix must be computed\n+    recursively. Relying on the compound model's internal representation can\n+    incorrectly treat nested compound models as non-separable blocks.\n+\n     Parameters\n     ----------\n     transform : `~astropy.modeling.core.Model`\n         A transform.\n@@ -24,6 +37,47 @@ def separability_matrix(transform):\n     matrix : ndarray\n         A boolean array with shape (n_outputs, n_inputs).\n     \"\"\"\n+    if isinstance(transform, CompoundModel):\n+        op = transform.op\n+        left = transform.left\n+        right = transform.right\n+\n+        if op == \"&\":\n+            lmat = separability_matrix(left)\n+            rmat = separability_matrix(right)\n+            out = np.zeros(\n+                (left.n_outputs + right.n_outputs, left.n_inputs + right.n_inputs),\n+                dtype=bool,\n+            )\n+            out[: left.n_outputs, : left.n_inputs] = lmat\n+            out[left.n_outputs :, left.n_inputs :] = rmat\n+            return out\n+\n+        if op == \"|\":\n+            lmat = separability_matrix(left)\n+            rmat = separability_matrix(right)\n+            return (rmat.astype(int) @ lmat.astype(int)).astype(bool)\n+\n+        # For arithmetic operators, conservatively assume full coupling between\n+        # any inputs that affect either side.\n+        lmat = separability_matrix(left)\n+        rmat = separability_matrix(right)\n+        if left.n_inputs != right.n_inputs or left.n_outputs != right.n_outputs:\n+            # Fallback to generic computation below if shapes don't match.\n+            pass\n+        else:\n+            return np.logical_or(lmat, rmat)\n+\n     # Default implementation: compute the dependency matrix by probing the model\n     # with basis vectors in input space.\n     n_inputs = transform.n_inputs\n     n_outputs = transform.n_outputs",
      "expected_patch": "diff --git a/astropy/modeling/separable.py b/astropy/modeling/separable.py\n--- a/astropy/modeling/separable.py\n+++ b/astropy/modeling/separable.py\n@@ -242,7 +242,7 @@ def _cstack(left, right):\n         cright = _coord_matrix(right, 'right', noutp)\n     else:\n         cright = np.zeros((noutp, right.shape[1]))\n-        cright[-right.shape[0]:, -right.shape[1]:] = 1\n+        cright[-right.shape[0]:, -right.shape[1]:] = right\n \n     return np.hstack([cleft, cright])\n \n",
      "tokens": 946,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "pydata__xarray-4629",
      "generated_patch": "--- a/xarray/core/merge.py\n+++ b/xarray/core/merge.py\n@@ -501,7 +501,7 @@\n     elif combine_attrs == \"drop\":\n         return {}\n     elif combine_attrs == \"override\":\n-        return variable_attrs[0]\n+        return dict(variable_attrs[0])\n     elif callable(combine_attrs):\n         return combine_attrs(variable_attrs, context=context)\n     else:\n         raise ValueError(f\"Unrecognized value for combine_attrs={combine_attrs!r}\")",
      "expected_patch": "diff --git a/xarray/core/merge.py b/xarray/core/merge.py\n--- a/xarray/core/merge.py\n+++ b/xarray/core/merge.py\n@@ -501,7 +501,7 @@ def merge_attrs(variable_attrs, combine_attrs):\n     if combine_attrs == \"drop\":\n         return {}\n     elif combine_attrs == \"override\":\n-        return variable_attrs[0]\n+        return dict(variable_attrs[0])\n     elif combine_attrs == \"no_conflicts\":\n         result = dict(variable_attrs[0])\n         for attrs in variable_attrs[1:]:\n",
      "tokens": 1071,
      "success": true,
      "similarity": 1.0
    },
    {
      "instance_id": "django__django-13516",
      "generated_patch": "--- a/django/core/management/base.py\n+++ b/django/core/management/base.py\n@@ -1,6 +1,7 @@\n import argparse\n import os\n import sys\n+import io\n import warnings\n from argparse import ArgumentParser\n from io import TextIOBase\n \n@@ -140,6 +141,10 @@ class OutputWrapper(TextIOBase):\n     ending = \"\\n\"\n \n     def __init__(self, out, style_func=None, ending=None):\n+        # Ensure we always have a flushable stream. Some wrappers (e.g.\n+        # colorama's AnsiToWin32) expose the underlying stream via `.stream`.\n+        out = getattr(out, \"stream\", out)\n         self._out = out\n         self.style_func = style_func\n         if ending is not None:\n@@ -170,6 +175,13 @@ class OutputWrapper(TextIOBase):\n         if ending and not msg.endswith(ending):\n             msg += ending\n         self._out.write(msg)\n+\n+    def flush(self):\n+        if hasattr(self._out, \"flush\"):\n+            self._out.flush()\n+\n+    def isatty(self):\n+        return hasattr(self._out, \"isatty\") and self._out.isatty()\n \n     def writelines(self, lines):\n         for line in lines:",
      "expected_patch": "diff --git a/django/core/management/base.py b/django/core/management/base.py\n--- a/django/core/management/base.py\n+++ b/django/core/management/base.py\n@@ -140,6 +140,10 @@ def __init__(self, out, ending='\\n'):\n     def __getattr__(self, name):\n         return getattr(self._out, name)\n \n+    def flush(self):\n+        if hasattr(self._out, 'flush'):\n+            self._out.flush()\n+\n     def isatty(self):\n         return hasattr(self._out, 'isatty') and self._out.isatty()\n \n",
      "tokens": 511,
      "success": true,
      "similarity": 0.75
    },
    {
      "instance_id": "django__django-13670",
      "generated_patch": "--- a/django/utils/dateformat.py\n+++ b/django/utils/dateformat.py\n@@ -1,6 +1,7 @@\n \"\"\"\n PHP date() style date formatting\n See https://www.php.net/date for format strings\n \"\"\"\n \n+from datetime import date, datetime\n from django.utils.dates import MONTHS, MONTHS_3, WEEKDAYS, WEEKDAYS_ABBR\n from django.utils.timezone import is_aware, make_naive\n \n@@ -245,7 +246,7 @@ class DateFormat(TimeFormat):\n         return self.data.year\n \n     def y(self):\n-        return self.data.year % 100\n+        return \"%02d\" % (self.data.year % 100)\n \n     def z(self):\n         \"\"\"Day of the year, 0-365.\"\"\"",
      "expected_patch": "diff --git a/django/utils/dateformat.py b/django/utils/dateformat.py\n--- a/django/utils/dateformat.py\n+++ b/django/utils/dateformat.py\n@@ -325,8 +325,8 @@ def W(self):\n         return self.data.isocalendar()[1]\n \n     def y(self):\n-        \"Year, 2 digits; e.g. '99'\"\n-        return str(self.data.year)[2:]\n+        \"\"\"Year, 2 digits with leading zeros; e.g. '99'.\"\"\"\n+        return '%02d' % (self.data.year % 100)\n \n     def Y(self):\n         \"Year, 4 digits; e.g. '1999'\"\n",
      "tokens": 484,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-14373",
      "generated_patch": "--- a/django/utils/dateformat.py\n+++ b/django/utils/dateformat.py\n@@ -1,6 +1,7 @@\n \"\"\"\n PHP date() style date formatting\n See https://www.php.net/date for format strings.\n \"\"\"\n \n+from django.utils.numberformat import format as nformat\n from django.utils.dates import MONTHS, MONTHS_3, WEEKDAYS, WEEKDAYS_ABBR\n from django.utils.formats import get_format\n from django.utils.regex_helper import _lazy_re_compile\n@@ -250,7 +251,7 @@ class DateFormat(TimeFormat):\n     def y(self):\n         return str(self.data.year)[2:]\n \n     def Y(self):\n-        return str(self.data.year)\n+        return nformat(self.data.year, decimal_pos=0, use_l10n=False, force_grouping=False).zfill(4)\n \n     def z(self):\n         \"\"\"Day of the year, 0-365.\"\"\"\n         return str(self.data.timetuple().tm_yday - 1)",
      "expected_patch": "diff --git a/django/utils/dateformat.py b/django/utils/dateformat.py\n--- a/django/utils/dateformat.py\n+++ b/django/utils/dateformat.py\n@@ -313,8 +313,8 @@ def y(self):\n         return '%02d' % (self.data.year % 100)\n \n     def Y(self):\n-        \"Year, 4 digits; e.g. '1999'\"\n-        return self.data.year\n+        \"\"\"Year, 4 digits with leading zeros; e.g. '1999'.\"\"\"\n+        return '%04d' % self.data.year\n \n     def z(self):\n         \"\"\"Day of the year, i.e. 1 to 366.\"\"\"\n",
      "tokens": 358,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "astropy__astropy-14539",
      "generated_patch": "--- a/astropy/io/fits/diff.py\n+++ b/astropy/io/fits/diff.py\n@@ -1,6 +1,7 @@\n # Licensed under a 3-clause BSD style license - see LICENSE.rst\n \n import fnmatch\n+import numpy as np\n import os\n import re\n import sys\n@@ -1048,6 +1049,31 @@\n         return self._diff_data\n \n \n+def _vla_equal(a, b):\n+    \"\"\"\n+    Compare two VLA (variable-length array) elements for equality.\n+\n+    VLA elements are commonly represented as object arrays containing\n+    ndarrays (or sequences). FITSDiff's generic element-wise comparison\n+    can mis-handle these, leading to false positives even when comparing\n+    a file to itself.\n+    \"\"\"\n+    if a is b:\n+        return True\n+    if a is None or b is None:\n+        return a is b\n+    try:\n+        aa = np.asarray(a)\n+        bb = np.asarray(b)\n+    except Exception:\n+        return a == b\n+    if aa.shape != bb.shape:\n+        return False\n+    return np.array_equal(aa, bb)\n+\n+\n class TableDataDiff(_BaseDiff):\n     \"\"\"\n     Diff two table data arrays.\n@@ -1237,6 +1263,16 @@\n                 if self.ignore_fields and colname in self.ignore_fields:\n                     continue\n \n+                # Special-case VLA columns (object dtype). Each cell may be an\n+                # ndarray/sequence; comparing these with the generic machinery\n+                # can yield false differences.\n+                if a[colname].dtype.kind == \"O\" or b[colname].dtype.kind == \"O\":\n+                    for i in range(nrows):\n+                        if not _vla_equal(a[colname][i], b[colname][i]):\n+                            self._diff_rows.append((colname, i))\n+                    continue\n+\n                 # Compare the column data\n                 col_a = a[colname]\n                 col_b = b[colname]",
      "expected_patch": "diff --git a/astropy/io/fits/diff.py b/astropy/io/fits/diff.py\n--- a/astropy/io/fits/diff.py\n+++ b/astropy/io/fits/diff.py\n@@ -1449,7 +1449,7 @@ def _diff(self):\n                 arrb.dtype, np.floating\n             ):\n                 diffs = where_not_allclose(arra, arrb, rtol=self.rtol, atol=self.atol)\n-            elif \"P\" in col.format:\n+            elif \"P\" in col.format or \"Q\" in col.format:\n                 diffs = (\n                     [\n                         idx\n",
      "tokens": 985,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-15569",
      "generated_patch": "--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -209,12 +209,13 @@\n     def _unregister_lookup(cls, lookup, lookup_name=None):\n         if lookup_name is None:\n             lookup_name = lookup.lookup_name\n         try:\n             del cls.class_lookups[lookup_name]\n         except KeyError:\n             pass\n+        cls._clear_cached_lookups()\n \n     def get_lookup(cls, lookup_name):\n         return cls.get_lookups().get(lookup_name, None)\n \n     def get_transform(cls, lookup_name):\n--- a/tests/schema/tests.py\n+++ b/tests/schema/tests.py\n@@ -3510,7 +3510,7 @@\n         with register_lookup(CharField, Upper):\n             with register_lookup(Upper, Exact):\n                 constraint = models.UniqueConstraint(\n                     Upper(\"name\"),\n                     name=\"func_upper_uq\",\n                 )\n                 with connection.schema_editor() as editor:\n                     editor.add_constraint(Author, constraint)\n-                self.assertIn(\"exact\", Upper.get_lookups())\n+                self.assertNotIn(\"exact\", Upper.get_lookups())\n         with connection.schema_editor() as editor:\n             editor.remove_constraint(Author, constraint)",
      "expected_patch": "diff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -217,6 +217,7 @@ def _unregister_lookup(cls, lookup, lookup_name=None):\n         if lookup_name is None:\n             lookup_name = lookup.lookup_name\n         del cls.class_lookups[lookup_name]\n+        cls._clear_cached_lookups()\n \n \n def select_related_descend(field, restricted, requested, load_fields, reverse=False):\n",
      "tokens": 507,
      "success": true,
      "similarity": 1.0
    },
    {
      "instance_id": "django__django-14792",
      "generated_patch": "--- a/django/db/backends/postgresql/operations.py\n+++ b/django/db/backends/postgresql/operations.py\n@@ -1,6 +1,7 @@\n import datetime\n import json\n import re\n+from zoneinfo import ZoneInfo\n \n from django.conf import settings\n from django.db.backends.base.operations import BaseDatabaseOperations\n@@ -100,6 +101,23 @@ class DatabaseOperations(BaseDatabaseOperations):\n     def _prepare_tzname_delta(self, tzname):\n         \"\"\"\n         Convert a timezone name into a format that can be used in a query.\n@@ -107,6 +125,17 @@ class DatabaseOperations(BaseDatabaseOperations):\n         if tzname is None:\n             return None\n+        # Handle \"Etc/GMT\u00b1X\" time zones. In the IANA database, the sign is\n+        # reversed (e.g. \"Etc/GMT-10\" is UTC+10). PostgreSQL follows the IANA\n+        # convention for these names, but Django's historical behavior for\n+        # Trunc/Extract was to interpret them as fixed offsets (UTC+10 -> '-10'\n+        # in AT TIME ZONE). Normalize to a fixed offset to preserve behavior.\n+        m = re.fullmatch(r\"Etc/GMT([+-])(\\d{1,2})\", tzname)\n+        if m:\n+            sign, hours = m.groups()\n+            return f\"{'+' if sign == '-' else '-'}{int(hours)}\"\n         if tzname.startswith((\"+\", \"-\")):\n             return tzname\n         return tzname",
      "expected_patch": "diff --git a/django/utils/timezone.py b/django/utils/timezone.py\n--- a/django/utils/timezone.py\n+++ b/django/utils/timezone.py\n@@ -72,8 +72,11 @@ def get_current_timezone_name():\n \n \n def _get_timezone_name(timezone):\n-    \"\"\"Return the name of ``timezone``.\"\"\"\n-    return str(timezone)\n+    \"\"\"\n+    Return the offset for fixed offset timezones, or the name of timezone if\n+    not set.\n+    \"\"\"\n+    return timezone.tzname(None) or str(timezone)\n \n # Timezone selection functions.\n \n",
      "tokens": 852,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-11119",
      "generated_patch": "--- a/django/template/engine.py\n+++ b/django/template/engine.py\n@@ -1,6 +1,7 @@\n from django.core.exceptions import ImproperlyConfigured\n from django.template import Context, TemplateDoesNotExist\n from django.template.backends.django import get_installed_libraries\n+from django.template.context import make_context\n from django.template.library import InvalidTemplateLibrary\n from django.utils.functional import cached_property\n from django.utils.module_loading import import_string\n@@ -183,12 +184,10 @@ class Engine:\n     def render_to_string(self, template_name, context=None):\n         \"\"\"\n         Render the template specified by template_name with the given context.\n         \"\"\"\n-        if context is None:\n-            context = {}\n-        template = self.get_template(template_name)\n-        return template.render(Context(context))\n+        template = self.get_template(template_name)\n+        return template.render(make_context(context, autoescape=self.autoescape))",
      "expected_patch": "diff --git a/django/template/engine.py b/django/template/engine.py\n--- a/django/template/engine.py\n+++ b/django/template/engine.py\n@@ -160,7 +160,7 @@ def render_to_string(self, template_name, context=None):\n         if isinstance(context, Context):\n             return t.render(context)\n         else:\n-            return t.render(Context(context))\n+            return t.render(Context(context, autoescape=self.autoescape))\n \n     def select_template(self, template_name_list):\n         \"\"\"\n",
      "tokens": 371,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-13647",
      "generated_patch": "--- a/sympy/matrices/common.py\n+++ b/sympy/matrices/common.py\n@@ -1968,16 +1968,20 @@\n     def col_insert(self, pos, other):\n         \"\"\"Insert one or more columns at the given column position.\n \n         Examples\n         ========\n \n         >>> from sympy import Matrix, eye\n         >>> M = eye(3)\n         >>> V = Matrix([[1, 2, 3]]).T\n         >>> M.col_insert(1, V)\n         Matrix([\n         [1, 1, 0, 0],\n         [0, 2, 1, 0],\n         [0, 3, 0, 1]])\n \n         \"\"\"\n-        if pos < 0:\n-            pos = self.cols + pos\n-        if pos < 0 or pos > self.cols:\n-            raise IndexError(\"col_insert: pos out of range\")\n-        other = self._new(other)\n-        if self.rows != other.rows:\n-            raise ShapeError(\"col_insert: matrices have incompatible number of rows\")\n-        return self._new(self.rows, self.cols + other.cols,\n-            lambda i, j: self[i, j] if j < pos else\n-            (other[i, j - pos] if j < pos + other.cols else self[i, j - other.cols]))\n+        if pos < 0:\n+            pos = self.cols + pos\n+        if pos < 0 or pos > self.cols:\n+            raise IndexError(\"col_insert: pos out of range\")\n+        other = self._new(other)\n+        if self.rows != other.rows:\n+            raise ShapeError(\"col_insert: matrices have incompatible number of rows\")\n+        # Use explicit loops to avoid any issues with lazy evaluation capturing\n+        # indices incorrectly in the constructor callback.\n+        rows, cols = self.rows, self.cols + other.cols\n+        mat = [[None]*cols for _ in range(rows)]\n+        for i in range(rows):\n+            for j in range(cols):\n+                if j < pos:\n+                    mat[i][j] = self[i, j]\n+                elif j < pos + other.cols:\n+                    mat[i][j] = other[i, j - pos]\n+                else:\n+                    mat[i][j] = self[i, j - other.cols]\n+        return self._new(mat)",
      "expected_patch": "diff --git a/sympy/matrices/common.py b/sympy/matrices/common.py\n--- a/sympy/matrices/common.py\n+++ b/sympy/matrices/common.py\n@@ -86,7 +86,7 @@ def entry(i, j):\n                 return self[i, j]\n             elif pos <= j < pos + other.cols:\n                 return other[i, j - pos]\n-            return self[i, j - pos - other.cols]\n+            return self[i, j - other.cols]\n \n         return self._new(self.rows, self.cols + other.cols,\n                          lambda i, j: entry(i, j))\n",
      "tokens": 1266,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-15809",
      "generated_patch": "--- a/sympy/functions/elementary/miscellaneous.py\n+++ b/sympy/functions/elementary/miscellaneous.py\n@@ -1,6 +1,7 @@\n from __future__ import annotations\n \n from sympy.core import S, sympify\n+from sympy.core.numbers import Infinity, NegativeInfinity\n from sympy.core.add import Add\n from sympy.core.basic import Basic\n from sympy.core.cache import cacheit\n@@ -545,10 +546,14 @@ class MinMaxBase(Expr):\n     def __new__(cls, *args, **assumptions):\n         args = (sympify(arg) for arg in args)\n         args = frozenset(args)\n-        if not args:\n-            raise ValueError(\"The Max/Min functions must have arguments.\")\n+        if not args:\n+            if cls is Max:\n+                return NegativeInfinity\n+            if cls is Min:\n+                return Infinity\n+            raise ValueError(\"The Max/Min functions must have arguments.\")\n         if len(args) == 1:\n             return args.pop()\n         return Expr.__new__(cls, *ordered(args), **assumptions)",
      "expected_patch": "diff --git a/sympy/functions/elementary/miscellaneous.py b/sympy/functions/elementary/miscellaneous.py\n--- a/sympy/functions/elementary/miscellaneous.py\n+++ b/sympy/functions/elementary/miscellaneous.py\n@@ -339,8 +339,6 @@ def real_root(arg, n=None, evaluate=None):\n \n class MinMaxBase(Expr, LatticeOp):\n     def __new__(cls, *args, **assumptions):\n-        if not args:\n-            raise ValueError(\"The Max/Min functions must have arguments.\")\n \n         args = (sympify(arg) for arg in args)\n \n",
      "tokens": 423,
      "success": true,
      "similarity": 1.0
    },
    {
      "instance_id": "sphinx-doc__sphinx-8621",
      "generated_patch": "--- a/sphinx/roles.py\n+++ b/sphinx/roles.py\n@@ -1,6 +1,7 @@\n \"\"\"Handlers for additional ReST roles.\"\"\"\n \n from __future__ import annotations\n+import re\n \n import re\n from typing import TYPE_CHECKING\n \n@@ -357,6 +358,34 @@ def menusel_role(typ: str, rawtext: str, text: str, lineno: int,\n     return [node], []\n \n \n+_kbd_sep_re = re.compile(r'(?<!\\\\)([-+^])')\n+\n+\n+def _parse_kbd(text: str) -> list[str]:\n+    \"\"\"Split kbd text into tokens, keeping separators as separate tokens.\n+\n+    Separators (-, +, ^) can be escaped with a backslash to be treated as a\n+    literal keystroke character.\n+    \"\"\"\n+    parts = _kbd_sep_re.split(text)\n+    tokens: list[str] = []\n+    for part in parts:\n+        if not part:\n+            continue\n+        if part in ('-', '+', '^'):\n+            if tokens and tokens[-1] in ('-', '+', '^'):\n+                # consecutive separators: treat as literal\n+                tokens[-1] += part\n+            else:\n+                tokens.append(part)\n+        else:\n+            tokens.append(part.replace(r'\\-', '-').replace(r'\\+', '+').replace(r'\\^', '^'))\n+    # If the whole text is a single separator, treat it as a keystroke.\n+    if len(tokens) == 1 and tokens[0] in ('-', '+', '^'):\n+        return [tokens[0]]\n+    return tokens\n+\n+\n def kbd_role(typ: str, rawtext: str, text: str, lineno: int,\n              inliner: Inliner, options: dict = {}, content: list[str] = []\n              ) -> tuple[list[Node], list[system_message]]:\n@@ -365,16 +394,22 @@ def kbd_role(typ: str, rawtext: str, text: str, lineno: int,\n     text = utils.unescape(text)\n     node = nodes.literal(rawtext, text, classes=['kbd'])\n     node['classes'].append('kbd')\n-    parts = re.split(r'([-+^])', text)\n-    if len(parts) == 1:\n+    parts = _parse_kbd(text)\n+    if len(parts) == 1:\n         return [node], []\n \n     children: list[Node] = []\n-    for part in parts:\n-        if part in '-+^':\n-            children.append(nodes.Text(part))\n-        else:\n-            children.append(nodes.literal(part, part, classes=['kbd']))\n+    for i, part in enumerate(parts):\n+        if part in ('-', '+', '^'):\n+            # Treat leading/trailing separators as literal keystrokes.\n+            if i == 0 or i == len(parts) - 1:\n+                children.append(nodes.literal(part, part, classes=['kbd']))\n+            else:\n+                children.append(nodes.Text(part))\n+        else:\n+            children.append(nodes.literal(part, part, classes=['kbd']))\n     node[:] = children\n     return [node], []",
      "expected_patch": "diff --git a/sphinx/builders/html/transforms.py b/sphinx/builders/html/transforms.py\n--- a/sphinx/builders/html/transforms.py\n+++ b/sphinx/builders/html/transforms.py\n@@ -37,7 +37,7 @@ class KeyboardTransform(SphinxPostTransform):\n     \"\"\"\n     default_priority = 400\n     builders = ('html',)\n-    pattern = re.compile(r'(-|\\+|\\^|\\s+)')\n+    pattern = re.compile(r'(?<=.)(-|\\+|\\^|\\s+)(?=.)')\n \n     def run(self, **kwargs: Any) -> None:\n         matcher = NodeMatcher(nodes.literal, classes=[\"kbd\"])\n",
      "tokens": 1338,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-13439",
      "generated_patch": "--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1,6 +1,7 @@\n \"\"\"Utilities to build a composite estimator as a chain of transforms and estimators.\"\"\"\n \n # Author: Edouard Duchesnay\n+#         Guillaume Lemaitre\n #         Gael Varoquaux\n #         Virgile Fritsch\n #         Alexandre Gramfort\n@@ -33,6 +34,7 @@ from .utils.metaestimators import available_if\n from .utils.validation import check_memory\n from .utils.validation import check_is_fitted\n from .utils.validation import _deprecate_positional_args\n+from .utils.validation import _num_samples\n \n \n def _name_estimators(estimators):\n@@ -214,6 +216,9 @@ class Pipeline(_BaseComposition):\n     def __getitem__(self, ind):\n         \"\"\"Returns a sub-pipeline or a single estimator in the pipeline\"\"\"\n         if isinstance(ind, slice):\n+            if ind.stop is None:\n+                ind = slice(ind.start, len(self), ind.step)\n             if ind.step not in (1, None):\n                 raise ValueError(\"Pipeline slicing only supports a step of 1\")\n             return self.__class__(self.steps[ind])\n@@ -223,6 +228,9 @@ class Pipeline(_BaseComposition):\n         else:\n             raise TypeError(\"Pipeline indices must be integers or slices, not %s\"\n                             % type(ind))\n+\n+    def __len__(self):\n+        return len(self.steps)\n \n     @property\n     def _estimator_type(self):\n         return self.steps[-1][1]._estimator_type",
      "expected_patch": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -199,6 +199,12 @@ def _iter(self, with_final=True):\n             if trans is not None and trans != 'passthrough':\n                 yield idx, name, trans\n \n+    def __len__(self):\n+        \"\"\"\n+        Returns the length of the Pipeline\n+        \"\"\"\n+        return len(self.steps)\n+\n     def __getitem__(self, ind):\n         \"\"\"Returns a sub-pipeline or a single esimtator in the pipeline\n \n",
      "tokens": 823,
      "success": true,
      "similarity": 0.6
    },
    {
      "instance_id": "matplotlib__matplotlib-13989",
      "generated_patch": "--- a/lib/matplotlib/axes/_axes.py\n+++ b/lib/matplotlib/axes/_axes.py\n@@ -7040,7 +7040,7 @@\n         if np.isscalar(x):\n             x = [x]\n \n-        if bins is None:\n+        if bins is None or (bins == 'auto' and range is not None):\n             bins = mpl.rcParams['hist.bins']\n \n         # Validate string inputs here to avoid problems later.  (If `bins` is a\n@@ -7050,7 +7050,7 @@\n         if isinstance(bins, str):\n             bins = bins.lower()\n \n-        if range is None:\n+        if range is None or (bins == 'auto' and range is not None):\n             # Compute the default range based on the data.\n             xmin = np.inf\n             xmax = -np.inf",
      "expected_patch": "diff --git a/lib/matplotlib/axes/_axes.py b/lib/matplotlib/axes/_axes.py\n--- a/lib/matplotlib/axes/_axes.py\n+++ b/lib/matplotlib/axes/_axes.py\n@@ -6686,7 +6686,7 @@ def hist(self, x, bins=None, range=None, density=None, weights=None,\n \n         density = bool(density) or bool(normed)\n         if density and not stacked:\n-            hist_kwargs = dict(density=density)\n+            hist_kwargs['density'] = density\n \n         # List to store all the top coordinates of the histograms\n         tops = []\n",
      "tokens": 720,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-12096",
      "generated_patch": "--- a/sympy/core/function.py\n+++ b/sympy/core/function.py\n@@ -1,1 +1,1 @@\n@@ -560,14 +560,16 @@\n     def _eval_evalf(self, prec):\n         if getattr(self, '_imp_', None) is not None:\n             try:\n-                return self._imp_(*self.args)\n+                res = self._imp_(*self.args)\n             except (TypeError, ValueError):\n                 return None\n+            if hasattr(res, 'evalf'):\n+                return res.evalf(prec)\n+            return res\n         return None",
      "expected_patch": "diff --git a/sympy/core/function.py b/sympy/core/function.py\n--- a/sympy/core/function.py\n+++ b/sympy/core/function.py\n@@ -507,7 +507,7 @@ def _eval_evalf(self, prec):\n             func = getattr(mpmath, fname)\n         except (AttributeError, KeyError):\n             try:\n-                return Float(self._imp_(*self.args), prec)\n+                return Float(self._imp_(*[i.evalf(prec) for i in self.args]), prec)\n             except (AttributeError, TypeError, ValueError):\n                 return\n \n",
      "tokens": 400,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-17655",
      "generated_patch": "--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -1,6 +1,7 @@\n from __future__ import annotations\n \n from sympy.core.add import Add\n+from sympy.core.mul import Mul\n from sympy.core.basic import Basic\n from sympy.core.compatibility import is_sequence\n from sympy.core.containers import Tuple\n from sympy.core.evalf import EvalfMixin\n@@ -206,6 +207,16 @@\n         return self\n \n     def __add__(self, other):\n+        if isinstance(other, Mul):\n+            c, p = other.as_coeff_Mul()\n+            if p.is_Point:\n+                try:\n+                    return self + (Point(p, evaluate=False) * c)\n+                except TypeError:\n+                    pass\n         try:\n             s, o = Point._normalize_dimension(self, Point(other, evaluate=False))\n         except TypeError:\n             raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))",
      "expected_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -278,6 +278,10 @@ def __mul__(self, factor):\n         coords = [simplify(x*factor) for x in self.args]\n         return Point(coords, evaluate=False)\n \n+    def __rmul__(self, factor):\n+        \"\"\"Multiply a factor by point's coordinates.\"\"\"\n+        return self.__mul__(factor)\n+\n     def __neg__(self):\n         \"\"\"Negate the point.\"\"\"\n         coords = [-x for x in self.args]\n",
      "tokens": 804,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-12304",
      "generated_patch": "--- a/django/db/models/enums.py\n+++ b/django/db/models/enums.py\n@@ -1,6 +1,7 @@\n from enum import Enum, IntEnum\n \n from django.utils.functional import Promise\n+from django.utils.inspect import isclass\n \n \n class ChoicesMeta(EnumMeta):\n@@ -54,6 +55,9 @@\n class Choices(Enum, metaclass=ChoicesMeta):\n     \"\"\"Class for creating enumerated choices.\"\"\"\n \n+    # Prevent Django templates from calling the class (as it's callable).\n+    do_not_call_in_templates = True\n     @classmethod\n     def choices(cls):\n         return [(member.value, member.label) for member in cls]\n@@ -105,6 +109,9 @@\n class IntegerChoices(IntEnum, Choices):\n     \"\"\"Class for creating enumerated integer choices.\"\"\"\n \n+    # Prevent Django templates from calling the class (as it's callable).\n+    do_not_call_in_templates = True\n     pass\n \n \n class TextChoices(str, Choices):\n     \"\"\"Class for creating enumerated string choices.\"\"\"\n \n+    # Prevent Django templates from calling the class (as it's callable).\n+    do_not_call_in_templates = True\n     pass",
      "expected_patch": "diff --git a/django/db/models/enums.py b/django/db/models/enums.py\n--- a/django/db/models/enums.py\n+++ b/django/db/models/enums.py\n@@ -31,6 +31,7 @@ def __new__(metacls, classname, bases, classdict):\n         # that is passed in as \"self\" as the value to use when looking up the\n         # label in the choices.\n         cls.label = property(lambda self: cls._value2label_map_.get(self.value))\n+        cls.do_not_call_in_templates = True\n         return enum.unique(cls)\n \n     def __contains__(cls, member):\n",
      "tokens": 460,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-13012",
      "generated_patch": "--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -1484,6 +1484,9 @@ class ExpressionWrapper(SQLiteNumericMixin, Expression):\n     def get_group_by_cols(self):\n         if isinstance(self.expression, Expression):\n             expression = self.expression.copy()\n+            if expression.contains_aggregate:\n+                return []\n             expression.output_field = self.output_field\n             return expression.get_group_by_cols()\n         return []",
      "expected_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -863,6 +863,9 @@ def set_source_expressions(self, exprs):\n     def get_source_expressions(self):\n         return [self.expression]\n \n+    def get_group_by_cols(self, alias=None):\n+        return self.expression.get_group_by_cols(alias=alias)\n+\n     def as_sql(self, compiler, connection):\n         return self.expression.as_sql(compiler, connection)\n \n",
      "tokens": 523,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-14672",
      "generated_patch": "--- a/django/db/models/fields/reverse_related.py\n+++ b/django/db/models/fields/reverse_related.py\n@@ -1,6 +1,7 @@\n from django.core import checks\n from django.db.models.query_utils import PathInfo\n from django.utils.functional import cached_property\n+from django.utils.hashable import make_hashable\n \n \n class ForeignObjectRel:\n@@ -344,7 +345,7 @@ class ManyToManyRel(ForeignObjectRel):\n     @property\n     def identity(self):\n         return super().identity + (\n             self.through,\n-            self.through_fields,\n+            make_hashable(self.through_fields),\n             self.db_constraint,\n         )",
      "expected_patch": "diff --git a/django/db/models/fields/reverse_related.py b/django/db/models/fields/reverse_related.py\n--- a/django/db/models/fields/reverse_related.py\n+++ b/django/db/models/fields/reverse_related.py\n@@ -310,7 +310,7 @@ def __init__(self, field, to, related_name=None, related_query_name=None,\n     def identity(self):\n         return super().identity + (\n             self.through,\n-            self.through_fields,\n+            make_hashable(self.through_fields),\n             self.db_constraint,\n         )\n \n",
      "tokens": 2022,
      "success": true,
      "similarity": 1.0
    },
    {
      "instance_id": "psf__requests-5414",
      "generated_patch": "--- a/requests/models.py\n+++ b/requests/models.py\n@@ -1,6 +1,7 @@\n # -*- coding: utf-8 -*-\n \n import datetime\n+import codecs\n import encodings.idna\n import os\n import re\n@@ -397,12 +398,18 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         try:\n             host = idna.encode(host, uts46=True).decode(\"utf-8\")\n         except UnicodeError:\n-            raise InvalidURL(\"URL has an invalid label.\")\n+            raise InvalidURL(\"URL has an invalid label.\")\n+        except (ValueError, codecs.CodecError, UnicodeError):\n+            # idna can raise a variety of exceptions depending on the input and\n+            # Python/idna versions. Normalize these to InvalidURL.\n+            raise InvalidURL(\"URL has an invalid label.\")\n \n         return host",
      "expected_patch": "diff --git a/requests/models.py b/requests/models.py\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -403,7 +403,7 @@ def prepare_url(self, url, params):\n                 host = self._get_idna_encoded_host(host)\n             except UnicodeError:\n                 raise InvalidURL('URL has an invalid label.')\n-        elif host.startswith(u'*'):\n+        elif host.startswith((u'*', u'.')):\n             raise InvalidURL('URL has an invalid label.')\n \n         # Carefully reconstruct the network location\n",
      "tokens": 710,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-16450",
      "generated_patch": "--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -1,6 +1,7 @@\n from __future__ import annotations\n \n from collections import defaultdict\n+from sympy.core.assumptions import StdFactKB\n from itertools import product\n from sympy.core import (Add, Basic, Dummy, Expr, Mul, Pow, S, Symbol,\n     Wild, cacheit, sympify)\n@@ -228,6 +229,7 @@ def posify(eq):\n     \"\"\"\n     from sympy.core.symbol import uniquely_named_symbol\n \n+    preserve = ('finite', 'infinite')\n     reps = {}\n     eq = sympify(eq)\n     for s in eq.free_symbols:\n@@ -235,12 +237,20 @@ def posify(eq):\n             continue\n         if s.is_positive:\n             continue\n-        # the assumption that s is real is made since it is\n-        # needed for the positive assumption to make sense\n-        reps[s] = uniquely_named_symbol('p', s, positive=True, real=True)\n+        # the assumption that s is real is made since it is\n+        # needed for the positive assumption to make sense\n+        assumps = {'positive': True, 'real': True}\n+        kb = getattr(s, '_assumptions', None)\n+        if isinstance(kb, StdFactKB):\n+            for k in preserve:\n+                v = kb.get(k, None)\n+                if v is not None:\n+                    assumps[k] = v\n+        reps[s] = uniquely_named_symbol('p', s, **assumps)\n     eq = eq.xreplace(reps)\n     return eq, reps",
      "expected_patch": "diff --git a/sympy/simplify/simplify.py b/sympy/simplify/simplify.py\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -251,7 +251,7 @@ def posify(eq):\n             eq[i] = e.subs(reps)\n         return f(eq), {r: s for s, r in reps.items()}\n \n-    reps = {s: Dummy(s.name, positive=True)\n+    reps = {s: Dummy(s.name, positive=True, **s.assumptions0)\n                  for s in eq.free_symbols if s.is_positive is None}\n     eq = eq.subs(reps)\n     return eq, {r: s for s, r in reps.items()}\n",
      "tokens": 709,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "astropy__astropy-13453",
      "generated_patch": "--- a/astropy/io/ascii/html.py\n+++ b/astropy/io/ascii/html.py\n@@ -1,6 +1,7 @@\n # Licensed under a 3-clause BSD style license - see LICENSE.rst\n \"\"\"An HTML table reader/writer.\n \"\"\"\n \n+from astropy.io.ascii.core import _apply_include_exclude_names\n from astropy.io.ascii.core import BaseReader\n from astropy.io.ascii.core import BaseSplitter\n from astropy.io.ascii.core import BaseWriter\n@@ -165,6 +166,7 @@ class HTML(BaseReader):\n class HTMLWriter(BaseWriter):\n     \"\"\"HTML table writer.\"\"\"\n \n     default_converters = []\n+    _format_name = \"html\"\n \n     def __init__(self, header=None, data=None, **kwargs):\n         super().__init__(header=header, data=data, **kwargs)\n@@ -172,6 +174,25 @@ class HTMLWriter(BaseWriter):\n         self.html = kwargs.get(\"html\", {})\n         self.css = kwargs.get(\"css\", None)\n \n+    def _set_col_formats(self, table):\n+        \"\"\"\n+        Apply user-supplied ``formats`` to table columns.\n+\n+        The HTML writer bypasses the normal ASCII formatting pipeline, so we\n+        need to explicitly set per-column ``format`` callables/strings here.\n+        \"\"\"\n+        formats = self.formats\n+        if not formats:\n+            return\n+\n+        names = _apply_include_exclude_names(table.colnames, self.include_names, self.exclude_names)\n+        for name in names:\n+            if name in formats:\n+                table[name].format = formats[name]\n+\n     def write(self, table):\n         \"\"\"\n         Write the ``table`` as an HTML table.\n@@ -179,6 +200,7 @@ class HTMLWriter(BaseWriter):\n         Parameters\n         ----------\n         table : `~astropy.table.Table`\n         \"\"\"\n+        self._set_col_formats(table)\n         from astropy.io.ascii import html\n \n         # Use the Table's HTML representation, which uses column formatting\n         # (col.format) and handles masking, units, etc.\n         return html._table_to_html(table, css=self.css, **self.html)",
      "expected_patch": "diff --git a/astropy/io/ascii/html.py b/astropy/io/ascii/html.py\n--- a/astropy/io/ascii/html.py\n+++ b/astropy/io/ascii/html.py\n@@ -349,11 +349,13 @@ def write(self, table):\n         cols = list(table.columns.values())\n \n         self.data.header.cols = cols\n+        self.data.cols = cols\n \n         if isinstance(self.data.fill_values, tuple):\n             self.data.fill_values = [self.data.fill_values]\n \n         self.data._set_fill_values(cols)\n+        self.data._set_col_formats()\n \n         lines = []\n \n",
      "tokens": 2759,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-15851",
      "generated_patch": "--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -1,6 +1,7 @@\n import os\n import signal\n import subprocess\n+from itertools import chain\n \n from django.db.backends.base.client import BaseDatabaseClient\n from django.utils.functional import cached_property\n@@ -33,7 +34,7 @@ class DatabaseClient(BaseDatabaseClient):\n     @classmethod\n     def settings_to_cmd_args_env(cls, settings_dict, parameters):\n         args = [cls.executable_name]\n-        dbname = settings_dict[\"NAME\"]\n+        dbname = settings_dict[\"NAME\"] or \"\"\n         user = settings_dict[\"USER\"]\n         password = settings_dict[\"PASSWORD\"]\n         host = settings_dict[\"HOST\"]\n@@ -54,13 +55,17 @@ class DatabaseClient(BaseDatabaseClient):\n         if port:\n             args += [\"-p\", str(port)]\n         if dbname:\n-            args += [dbname]\n+            dbname_args = [dbname]\n+        else:\n+            dbname_args = []\n         args.extend(parameters)\n+        # psql expects all options to precede the database name.\n+        if dbname_args:\n+            args = list(chain(args[:-len(parameters)] if parameters else args, parameters, dbname_args))\n         env = os.environ.copy()\n         if password:\n             env[\"PGPASSWORD\"] = str(password)\n         return args, env",
      "expected_patch": "diff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -32,9 +32,9 @@ def settings_to_cmd_args_env(cls, settings_dict, parameters):\n             args += [\"-h\", host]\n         if port:\n             args += [\"-p\", str(port)]\n+        args.extend(parameters)\n         if dbname:\n             args += [dbname]\n-        args.extend(parameters)\n \n         env = {}\n         if passwd:\n",
      "tokens": 541,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "pydata__xarray-4094",
      "generated_patch": "--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -1,6 +1,7 @@\n from __future__ import annotations\n \n from collections.abc import Hashable, Iterable, Mapping, Sequence\n+from typing import Any\n from datetime import datetime, timedelta\n from functools import partial\n from numbers import Number\n@@ -1,6 +1,7 @@\n import numpy as np\n import pandas as pd\n \n+from xarray.core.merge import merge\n from xarray.core import dtypes, duck_array_ops, formatting, indexing, ops, utils\n from xarray.core.alignment import align\n from xarray.core.arithmetic import DataArrayArithmetic\n@@ -1,6 +1,7 @@\n from xarray.core.common import (\n     AbstractArray,\n     DataWithCoords,\n     _contains_datetime_like_objects,\n@@ -1,6 +1,7 @@\n from xarray.core.dataset import Dataset\n from xarray.core.indexes import Index, Indexes\n from xarray.core.options import OPTIONS, _get_keep_attrs\n+from xarray.core.variable import Variable\n \n \n class DataArray(\n@@ -3081,6 +3082,35 @@ class DataArray(\n         return Dataset(data_vars=data_vars, coords=coords, attrs=attrs)\n \n     def to_unstacked_dataset(self, dim: Hashable, level: int = 0) -> Dataset:\n+        # Work around merge conflicts when unstacking stacked arrays that include\n+        # a coordinate with the same name as the stacked dimension (e.g. \"y\").\n+        # This can happen for single-dimension variables stacked via\n+        # Dataset.to_stacked_array, where the stacked dimension coordinate is\n+        # carried through each variable and then conflicts on merge.\n+        if dim in self.coords:\n+            coord = self.coords[dim]\n+            if coord.dims == (dim,) and coord.size == self.sizes.get(dim, coord.size):\n+                # Only drop if it's a simple 1D coordinate along the stacked dim.\n+                # It will be recreated from the concatenated result.\n+                obj = self.drop_vars(dim)\n+            else:\n+                obj = self\n+        else:\n+            obj = self\n+\n         if dim not in self.dims:\n             raise ValueError(f\"dimension {dim!r} not found\")\n \n-        return Dataset({k: v for k, v in self.groupby(dim, squeeze=False)})\n+        datasets = []\n+        for k, v in obj.groupby(dim, squeeze=False):\n+            datasets.append(v.to_dataset(name=k))\n+        if not datasets:\n+            return Dataset()\n+        return merge(datasets)",
      "expected_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -1961,7 +1961,7 @@ def to_unstacked_dataset(self, dim, level=0):\n         # pull variables out of datarray\n         data_dict = {}\n         for k in variables:\n-            data_dict[k] = self.sel({variable_dim: k}).squeeze(drop=True)\n+            data_dict[k] = self.sel({variable_dim: k}, drop=True).squeeze(drop=True)\n \n         # unstacked dataset\n         return Dataset(data_dict)\n",
      "tokens": 1235,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-13569",
      "generated_patch": "--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -1,6 +1,7 @@\n from itertools import chain\n \n from django.core.exceptions import EmptyResultSet, FieldError\n+from django.db.models.functions import Random\n from django.db.models.sql.constants import (\n     CURSOR, GET_ITERATOR_CHUNK_SIZE, MULTI, NO_RESULTS, ORDER_DIR, SINGLE,\n )\n@@ -175,6 +176,7 @@ class SQLCompiler:\n     def get_group_by(self, select, order_by):\n         \"\"\"\n         Return a list of 2-tuples of the form (sql, params) for the GROUP BY\n         clause.\n         \"\"\"\n         if self.query.group_by is None:\n             return []\n@@ -232,16 +234,22 @@ class SQLCompiler:\n         # Add any expressions used for ordering that aren't already in the\n         # group by.\n         if order_by:\n             expressions = []\n             for expr, (sql, params, is_ref) in order_by:\n                 if expr.contains_aggregate:\n                     continue\n                 if is_ref:\n                     continue\n-                expressions.extend(expr.get_source_expressions())\n+                expressions.extend(\n+                    exp\n+                    for exp in expr.get_source_expressions()\n+                    if not isinstance(exp, Random)\n+                )\n             for expr in expressions:\n                 if expr in group_by:\n                     continue\n                 group_by.append(expr)\n \n         return group_by",
      "expected_patch": "diff --git a/django/db/models/functions/math.py b/django/db/models/functions/math.py\n--- a/django/db/models/functions/math.py\n+++ b/django/db/models/functions/math.py\n@@ -154,6 +154,9 @@ def as_oracle(self, compiler, connection, **extra_context):\n     def as_sqlite(self, compiler, connection, **extra_context):\n         return super().as_sql(compiler, connection, function='RAND', **extra_context)\n \n+    def get_group_by_cols(self, alias=None):\n+        return []\n+\n \n class Round(Transform):\n     function = 'ROUND'\n",
      "tokens": 901,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "matplotlib__matplotlib-23476",
      "generated_patch": "--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -2900,14 +2900,21 @@\n     def __setstate__(self, state):\n         # re-initialise some things that are not pickled\n         self.__dict__ = state\n         self._cachedRenderer = None\n         self._axobservers = cbook.CallbackRegistry()\n         self._canvas_callbacks = cbook.CallbackRegistry()\n+        # Prevent backend initialization from applying device pixel ratio\n+        # scaling multiple times across repeated pickle roundtrips (notably on\n+        # macOS Retina / M1 with the MacOSX backend).\n+        # The backend will re-apply any necessary scaling when attaching a new\n+        # canvas/manager.\n+        self._dpi = self._dpi / getattr(self, \"_device_pixel_ratio\", 1) if hasattr(self, \"_device_pixel_ratio\") else self._dpi\n+        self._device_pixel_ratio = 1\n         # re-initialise the figure manager\n         if self.canvas is not None:\n             import matplotlib.pyplot as plt\n             num = self.number\n             mgr = plt._backend_mod.new_figure_manager_given_figure(num, self)\n             self.canvas = mgr.canvas\n             self.stale = True",
      "expected_patch": "diff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -3023,6 +3023,9 @@ def __getstate__(self):\n         # Set cached renderer to None -- it can't be pickled.\n         state[\"_cachedRenderer\"] = None\n \n+        # discard any changes to the dpi due to pixel ratio changes\n+        state[\"_dpi\"] = state.get('_original_dpi', state['_dpi'])\n+\n         # add version information to the state\n         state['__mpl_version__'] = mpl.__version__\n \n",
      "tokens": 1460,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-12585",
      "generated_patch": "--- a/sklearn/base.py\n+++ b/sklearn/base.py\n@@ -48,7 +48,7 @@ def clone(estimator, safe=True):\n     if estimator_type in (list, tuple, set, frozenset):\n         return estimator_type([clone(e, safe=safe) for e in estimator])\n     elif not hasattr(estimator, 'get_params') or isinstance(estimator, type):\n         if not safe:\n             return copy.deepcopy(estimator)\n         else:\n             raise TypeError(\"Cannot clone object '%s' (type %s): \"\n                             \"it does not seem to be a scikit-learn estimator \"\n                             \"as it does not implement a 'get_params' method.\"\n                             % (repr(estimator), type(estimator)))",
      "expected_patch": "diff --git a/sklearn/base.py b/sklearn/base.py\n--- a/sklearn/base.py\n+++ b/sklearn/base.py\n@@ -48,7 +48,7 @@ def clone(estimator, safe=True):\n     # XXX: not handling dictionaries\n     if estimator_type in (list, tuple, set, frozenset):\n         return estimator_type([clone(e, safe=safe) for e in estimator])\n-    elif not hasattr(estimator, 'get_params'):\n+    elif not hasattr(estimator, 'get_params') or isinstance(estimator, type):\n         if not safe:\n             return copy.deepcopy(estimator)\n         else:\n",
      "tokens": 577,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-10999",
      "generated_patch": "--- a/django/utils/dateparse.py\n+++ b/django/utils/dateparse.py\n@@ -1,18 +1,18 @@\n import datetime\n import re\n \n from django.utils.regex_helper import _lazy_re_compile\n \n \n standard_duration_re = _lazy_re_compile(\n     r'^'\n     r'(?:(?P<days>-?\\d+) (days?, )?)?'\n-    r'((?:(?P<hours>-?\\d+):)(?=\\d+:\\d+))?'\n+    r'((?:(?P<hours>-?\\d+):)(?=-?\\d+:-?\\d+))?'\n     r'(?:(?P<minutes>-?\\d+):)?'\n     r'(?P<seconds>-?\\d+)'\n     r'(?:\\.(?P<microseconds>\\d{1,6})\\d{0,6})?'\n     r'$'\n )",
      "expected_patch": "diff --git a/django/utils/dateparse.py b/django/utils/dateparse.py\n--- a/django/utils/dateparse.py\n+++ b/django/utils/dateparse.py\n@@ -29,9 +29,10 @@\n standard_duration_re = re.compile(\n     r'^'\n     r'(?:(?P<days>-?\\d+) (days?, )?)?'\n-    r'((?:(?P<hours>-?\\d+):)(?=\\d+:\\d+))?'\n-    r'(?:(?P<minutes>-?\\d+):)?'\n-    r'(?P<seconds>-?\\d+)'\n+    r'(?P<sign>-?)'\n+    r'((?:(?P<hours>\\d+):)(?=\\d+:\\d+))?'\n+    r'(?:(?P<minutes>\\d+):)?'\n+    r'(?P<seconds>\\d+)'\n     r'(?:\\.(?P<microseconds>\\d{1,6})\\d{0,6})?'\n     r'$'\n )\n",
      "tokens": 507,
      "success": true,
      "similarity": 0.14285714285714285
    },
    {
      "instance_id": "pylint-dev__pylint-4970",
      "generated_patch": "--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -1,6 +1,7 @@\n # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html\n # For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE\n # Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt\n \n+from __future__ import annotations\n from collections import defaultdict\n from collections.abc import Iterable, Iterator, Sequence\n from dataclasses import dataclass\n from pathlib import Path\n from typing import Any, NamedTuple\n \n@@ -760,6 +761,10 @@\n     def open(self) -> None:\n         \"\"\"Initialize visit variables.\"\"\"\n         self._duplicates = []\n+        # Setting min-similarity-lines to 0 should disable duplicate code checking.\n+        if self.linter.config.min_similarity_lines == 0:\n+            self._disabled = True\n+            return\n         self._disabled = False\n         self._similarities = Similarities(\n             min_lines=self.linter.config.min_similarity_lines,\n             ignore_comments=self.linter.config.ignore_comments,\n             ignore_docstrings=self.linter.config.ignore_docstrings,\n             ignore_imports=self.linter.config.ignore_imports,\n             ignore_signatures=self.linter.config.ignore_signatures,\n         )",
      "expected_patch": "diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -390,6 +390,8 @@ def append_stream(self, streamid: str, stream: TextIO, encoding=None) -> None:\n \n     def run(self) -> None:\n         \"\"\"start looking for similarities and display results on stdout\"\"\"\n+        if self.min_lines == 0:\n+            return\n         self._display_sims(self._compute_sims())\n \n     def _compute_sims(self) -> List[Tuple[int, Set[LinesChunkLimits_T]]]:\n",
      "tokens": 538,
      "success": true,
      "similarity": 0.5
    },
    {
      "instance_id": "django__django-12965",
      "generated_patch": "--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -1,6 +1,7 @@\n from collections import Counter, namedtuple\n from itertools import chain\n \n+from django.db import connections\n from django.core.exceptions import EmptyResultSet, FieldError\n from django.db import DatabaseError, NotSupportedError\n from django.db.models.constants import LOOKUP_SEP\n@@ -2010,6 +2011,15 @@\n         return sql, params\n \n     def as_sql(self):\n+        # Fast-path: deleting all rows from a single table should use a simple\n+        # \"DELETE FROM <table>\" statement. Avoid generating a self-referencing\n+        # subquery (e.g. \"WHERE id IN (SELECT id FROM <table>)\") which can be\n+        # significantly slower on some MySQL/MariaDB versions and breaks\n+        # LOCK TABLES usage due to multiple references to the same table name.\n+        if self.query.can_filter() and not self.query.where and not self.query.low_mark and not self.query.high_mark:\n+            return self._as_sql_without_where()\n         if self.query.can_filter():\n             return self._as_sql()\n         return self._as_sql_subqueries()\n@@ -2020,6 +2030,21 @@\n         sql, params = self._as_sql()\n         return sql, params\n \n+    def _as_sql_without_where(self):\n+        \"\"\"\n+        Generate SQL for deleting all rows from a single table without any WHERE\n+        clause.\n+        \"\"\"\n+        assert len(self.query.tables) == 1\n+        qn = self.quote_name_unless_alias\n+        table = qn(self.query.tables[0])\n+        sql = 'DELETE FROM %s' % table\n+        return sql, ()\n+\n     def _as_sql(self):\n         \"\"\"\n         Generate the SQL for the DELETE statement. The query must have been\n         prepared by the query's get_compiler() method.",
      "expected_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -1407,6 +1407,8 @@ def execute_sql(self, returning_fields=None):\n class SQLDeleteCompiler(SQLCompiler):\n     @cached_property\n     def single_alias(self):\n+        # Ensure base table is in aliases.\n+        self.query.get_initial_alias()\n         return sum(self.query.alias_refcount[t] > 0 for t in self.query.alias_map) == 1\n \n     def _as_sql(self, query):\n",
      "tokens": 1186,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-9296",
      "generated_patch": "--- a/django/core/paginator.py\n+++ b/django/core/paginator.py\n@@ -1,6 +1,7 @@\n \"\"\"\n Pagination utilities.\n \"\"\"\n \n+from __future__ import annotations\n from math import ceil\n \n from django.utils.functional import cached_property\n@@ -56,6 +57,10 @@ class Paginator:\n         self.orphans = int(orphans)\n         self.allow_empty_first_page = allow_empty_first_page\n \n+    def __iter__(self):\n+        for page_num in self.page_range:\n+            yield self.page(page_num)\n+\n     def validate_number(self, number):\n         \"\"\"Validate the given 1-based page number.\"\"\"\n         try:",
      "expected_patch": "diff --git a/django/core/paginator.py b/django/core/paginator.py\n--- a/django/core/paginator.py\n+++ b/django/core/paginator.py\n@@ -34,6 +34,10 @@ def __init__(self, object_list, per_page, orphans=0,\n         self.orphans = int(orphans)\n         self.allow_empty_first_page = allow_empty_first_page\n \n+    def __iter__(self):\n+        for page_number in self.page_range:\n+            yield self.page(page_number)\n+\n     def validate_number(self, number):\n         \"\"\"Validate the given 1-based page number.\"\"\"\n         try:\n",
      "tokens": 327,
      "success": true,
      "similarity": 0.5
    },
    {
      "instance_id": "django__django-12193",
      "generated_patch": "--- a/django/contrib/postgres/forms/array.py\n+++ b/django/contrib/postgres/forms/array.py\n@@ -1,6 +1,7 @@\n from django import forms\n from django.core.exceptions import ValidationError\n from django.forms.fields import Field\n+from django.utils.datastructures import MultiValueDict\n from django.utils.translation import gettext_lazy as _\n \n \n@@ -197,14 +198,16 @@ class SplitArrayWidget(forms.MultiWidget):\n     def get_context(self, name, value, attrs):\n         context = super().get_context(name, value, attrs)\n         if value is None:\n             value = []\n-        final_attrs = context[\"widget\"][\"attrs\"]\n+        final_attrs = context[\"widget\"][\"attrs\"]\n         id_ = final_attrs.get(\"id\")\n         subwidgets = []\n         for i in range(self.size):\n             widget_name = \"%s_%s\" % (name, i)\n             try:\n                 widget_value = value[i]\n             except IndexError:\n                 widget_value = None\n-            widget_attrs = final_attrs\n+            widget_attrs = final_attrs.copy()\n             if id_:\n                 widget_attrs = widget_attrs.copy()\n                 widget_attrs[\"id\"] = \"%s_%s\" % (id_, i)\n             subwidgets.append(\n                 self.widgets[i].get_context(widget_name, widget_value, widget_attrs)[\"widget\"]\n             )\n         context[\"widget\"][\"subwidgets\"] = subwidgets\n         return context",
      "expected_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -522,9 +522,7 @@ def format_value(self, value):\n \n     def get_context(self, name, value, attrs):\n         if self.check_test(value):\n-            if attrs is None:\n-                attrs = {}\n-            attrs['checked'] = True\n+            attrs = {**(attrs or {}), 'checked': True}\n         return super().get_context(name, value, attrs)\n \n     def value_from_datadict(self, data, files, name):\n",
      "tokens": 550,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-10908",
      "generated_patch": "--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -1458,11 +1458,13 @@ class CountVectorizer(_VectorizerMixin, BaseEstimator):\n         return self\n \n     def get_feature_names_out(self, input_features=None):\n-        check_is_fitted(self, \"vocabulary_\")\n+        # If a fixed vocabulary was provided at init, allow feature name\n+        # retrieval without calling fit/transform.\n+        self._validate_vocabulary()\n \n         if input_features is not None:\n             raise ValueError(\"input_features is not supported.\")\n \n         return np.asarray(\n             [t for t, i in sorted(self.vocabulary_.items(), key=itemgetter(1))],\n             dtype=object,\n         )",
      "expected_patch": "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -971,6 +971,9 @@ def inverse_transform(self, X):\n \n     def get_feature_names(self):\n         \"\"\"Array mapping from feature integer indices to feature name\"\"\"\n+        if not hasattr(self, 'vocabulary_'):\n+            self._validate_vocabulary()\n+\n         self._check_vocabulary()\n \n         return [t for t, i in sorted(six.iteritems(self.vocabulary_),\n",
      "tokens": 772,
      "success": true,
      "similarity": 0.3333333333333333
    },
    {
      "instance_id": "django__django-11211",
      "generated_patch": "--- a/django/contrib/contenttypes/fields.py\n+++ b/django/contrib/contenttypes/fields.py\n@@ -1,6 +1,7 @@\n from collections import defaultdict\n \n from django.apps import apps\n+from django.db import models\n from django.contrib.contenttypes.models import ContentType\n from django.core import checks\n from django.core.exceptions import FieldDoesNotExist, ObjectDoesNotExist\n@@ -160,6 +161,7 @@ class GenericForeignKey(FieldCacheMixin, Field):\n     def __init__(self, ct_field=\"content_type\", fk_field=\"object_id\", for_concrete_model=True):\n         self.ct_field = ct_field\n         self.fk_field = fk_field\n+        self._fk_field = None\n         self.for_concrete_model = for_concrete_model\n         self.editable = False\n         self.rel = None\n@@ -170,6 +172,7 @@ class GenericForeignKey(FieldCacheMixin, Field):\n         self.model = cls\n         self.opts = cls._meta\n         self.ct_field = self.opts.get_field(self.ct_field)\n+        self._fk_field = self.opts.get_field(self.fk_field)\n         self.fk_field = self.opts.get_field(self.fk_field)\n         self.cache_name = self.name\n \n@@ -190,6 +193,18 @@ class GenericForeignKey(FieldCacheMixin, Field):\n     def get_content_type(self, obj=None, id=None, using=None):\n         return ContentType.objects.db_manager(using).get_for_model(\n             obj, for_concrete_model=self.for_concrete_model\n         )\n \n+    def _convert_object_id(self, ct, object_id):\n+        \"\"\"\n+        Convert the stored object_id value to the correct Python type for the\n+        target model's primary key.\n+        \"\"\"\n+        if object_id is None:\n+            return None\n+        model = ct.model_class()\n+        if model is None:\n+            return object_id\n+        return model._meta.pk.to_python(object_id)\n+\n     def get_prefetch_querysets(self, instances, querysets=None):\n         if querysets is not None and len(querysets) != 1:\n             raise ValueError(\"querysets argument of get_prefetch_querysets() should have a length of 1.\")\n@@ -201,7 +216,7 @@ class GenericForeignKey(FieldCacheMixin, Field):\n         # For efficiency, group the instances by content type and then do one\n         # query per model\n         fk_dict = defaultdict(set)\n         for instance in instances:\n-            fk_val = getattr(instance, self.fk_field.attname)\n+            fk_val = getattr(instance, self.fk_field.attname)\n             if fk_val is not None:\n                 ct_id = getattr(instance, self.ct_field.attname)\n                 fk_dict[ct_id].add(fk_val)\n@@ -214,7 +229,7 @@ class GenericForeignKey(FieldCacheMixin, Field):\n             ct = ContentType.objects.db_manager(using).get_for_id(ct_id)\n             model = ct.model_class()\n             if model is None:\n                 continue\n-            qs = (querysets[0] if querysets is not None else model._base_manager.db_manager(using)).all()\n+            qs = (querysets[0] if querysets is not None else model._base_manager.db_manager(using)).all()\n             ret.extend(qs.filter(pk__in=fk_dict[ct_id]))\n \n         def rel_obj_attr(rel_obj):\n@@ -222,7 +237,7 @@ class GenericForeignKey(FieldCacheMixin, Field):\n \n         def instance_attr(instance):\n             ct_id = getattr(instance, self.ct_field.attname)\n-            return (ct_id, getattr(instance, self.fk_field.attname))\n+            return (ct_id, self._convert_object_id(ContentType.objects.db_manager(using).get_for_id(ct_id), getattr(instance, self.fk_field.attname)))\n \n         return (\n             ret,\n             rel_obj_attr,\n             instance_attr,\n             True,\n             self.cache_name,\n         )",
      "expected_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -2325,6 +2325,10 @@ def deconstruct(self):\n     def get_internal_type(self):\n         return \"UUIDField\"\n \n+    def get_prep_value(self, value):\n+        value = super().get_prep_value(value)\n+        return self.to_python(value)\n+\n     def get_db_prep_value(self, value, connection, prepared=False):\n         if value is None:\n             return None\n",
      "tokens": 1155,
      "success": true,
      "similarity": 0.25
    },
    {
      "instance_id": "django__django-16667",
      "generated_patch": "--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -1154,12 +1154,12 @@\n         if y == m == d == \"0\":\n             return None\n         if y and m and d:\n             try:\n-                date_value = datetime.date(int(y), int(m), int(d))\n-            except ValueError:\n+                date_value = datetime.date(int(y), int(m), int(d))\n+            except (ValueError, OverflowError):\n                 return data.get(name)\n             else:\n                 return date_value\n         return data.get(name)",
      "expected_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -1161,6 +1161,8 @@ def value_from_datadict(self, data, files, name):\n                 # Return pseudo-ISO dates with zeros for any unselected values,\n                 # e.g. '2017-0-23'.\n                 return \"%s-%s-%s\" % (y or 0, m or 0, d or 0)\n+            except OverflowError:\n+                return \"0-0-0\"\n             return date_value.strftime(input_format)\n         return data.get(name)\n \n",
      "tokens": 644,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "pydata__xarray-2905",
      "generated_patch": "--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -1,6 +1,7 @@\n from __future__ import annotations\n \n import functools\n+import numpy as np\n import operator\n import warnings\n from collections.abc import Hashable, Iterable, Mapping, Sequence\n from typing import TYPE_CHECKING, Any, Callable, Generic, Literal, NoReturn, TypeVar, overload\n@@ -638,12 +639,23 @@ class Variable(NamedArray, AbstractArray, VariableArithmetic):\n     def __setitem__(self, key, value):\n         \"\"\"__setitem__ is overloaded to access the underlying numpy array.\"\"\"\n         key = self._item_key_to_tuple(key)\n-        value = as_compatible_data(value)\n+        # Avoid coercing arbitrary Python objects that happen to have a `.values`\n+        # attribute (e.g. lmfit ModelResult) when assigning into object arrays.\n+        # In this case we want to store the object itself, not its `.values`.\n+        if (\n+            self.dtype == object\n+            and not isinstance(value, (np.ndarray, Variable))\n+            and hasattr(value, \"values\")\n+        ):\n+            value = np.asarray(value, dtype=object)\n+        else:\n+            value = as_compatible_data(value)\n         if isinstance(value, Variable):\n             value = value.data\n         self.data[key] = value",
      "expected_patch": "diff --git a/xarray/core/variable.py b/xarray/core/variable.py\n--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -218,7 +218,8 @@ def as_compatible_data(data, fastpath=False):\n         data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n \n     # we don't want nested self-described arrays\n-    data = getattr(data, \"values\", data)\n+    if isinstance(data, (pd.Series, pd.Index, pd.DataFrame)):\n+        data = data.values\n \n     if isinstance(data, np.ma.MaskedArray):\n         mask = np.ma.getmaskarray(data)\n",
      "tokens": 1050,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-14493",
      "generated_patch": "--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -240,18 +240,19 @@\n         if not processed:\n             return\n \n         # Post process the files to update references to the hashed names.\n+        substitutions = False\n         for i in range(self.max_post_process_passes):\n             substitutions = False\n             for name, hashed_name, processed in processed_files:\n                 if not processed:\n                     continue\n                 content = self._post_process(name, hashed_name, processed_files)\n                 if content is not None:\n                     substitutions = True\n                     yield name, hashed_name, content\n             if not substitutions:\n                 break\n \n         if substitutions:\n             raise RuntimeError(\n                 \"Max post-process passes exceeded. This may be caused by \"\n                 \"circular references in your static files.\"\n             )",
      "expected_patch": "diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py\n--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -260,6 +260,7 @@ def post_process(self, paths, dry_run=False, **options):\n                 processed_adjustable_paths[name] = (name, hashed_name, processed)\n \n         paths = {path: paths[path] for path in adjustable_paths}\n+        substitutions = False\n \n         for i in range(self.max_post_process_passes):\n             substitutions = False\n",
      "tokens": 632,
      "success": true,
      "similarity": 1.0
    },
    {
      "instance_id": "sphinx-doc__sphinx-9230",
      "generated_patch": "--- a/sphinx/util/docfields.py\n+++ b/sphinx/util/docfields.py\n@@ -1,6 +1,7 @@\n \"\"\"Utilities for doc fields.\"\"\"\n \n from __future__ import annotations\n \n+import re\n from typing import TYPE_CHECKING, Any\n \n from docutils import nodes\n from docutils.parsers.rst import roles\n \n@@ -34,6 +35,22 @@ if TYPE_CHECKING:\n     from sphinx.environment import BuildEnvironment\n \n \n+_field_type_re = re.compile(r'^\\s*(?P<type>.+?)\\s+(?P<name>\\S+)\\s*$')\n+\n+\n+def _split_field_type_name(arg: str) -> tuple[str | None, str]:\n+    \"\"\"Split a doc field argument into (type, name).\n+\n+    This is more robust than rsplit(' ', 1) for types containing spaces,\n+    e.g. ``dict(str, str) opc_meta``.\n+    \"\"\"\n+    m = _field_type_re.match(arg)\n+    if m:\n+        return m.group('type'), m.group('name')\n+    return None, arg.strip()\n+\n+\n class Field:\n     \"\"\"A doc field.\"\"\"\n \n@@ -250,10 +267,11 @@ class TypedField(Field):\n         if self.is_typed:\n             # typed field: 'type name'\n             # type is optional\n-            parts = fieldarg.split(None, 1)\n-            if len(parts) == 2:\n-                fieldtype, fieldname = parts\n+            fieldtype, fieldname = _split_field_type_name(fieldarg)\n+            if fieldtype is not None:\n                 typename = self.make_xrefs(self.typerolename, domain,\n                                           fieldtype, addnodes.literal_emphasis,\n                                           env=env)\n             else:\n-                fieldname = parts[0]\n                 typename = None\n         else:\n             fieldname = fieldarg\n             typename = None",
      "expected_patch": "diff --git a/sphinx/util/docfields.py b/sphinx/util/docfields.py\n--- a/sphinx/util/docfields.py\n+++ b/sphinx/util/docfields.py\n@@ -298,7 +298,7 @@ def transform(self, node: nodes.field_list) -> None:\n             # also support syntax like ``:param type name:``\n             if typedesc.is_typed:\n                 try:\n-                    argtype, argname = fieldarg.split(None, 1)\n+                    argtype, argname = fieldarg.rsplit(None, 1)\n                 except ValueError:\n                     pass\n                 else:\n",
      "tokens": 868,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-11163",
      "generated_patch": "--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -98,7 +98,7 @@ def model_to_dict(instance, fields=None, exclude=None):\n     for f in chain(opts.concrete_fields, opts.private_fields, opts.many_to_many):\n         if not getattr(f, 'editable', False):\n             continue\n-        if fields and f.name not in fields:\n+        if fields is not None and f.name not in fields:\n             continue\n         if exclude and f.name in exclude:\n             continue\n         data[f.name] = f.value_from_object(instance)",
      "expected_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -83,7 +83,7 @@ def model_to_dict(instance, fields=None, exclude=None):\n     for f in chain(opts.concrete_fields, opts.private_fields, opts.many_to_many):\n         if not getattr(f, 'editable', False):\n             continue\n-        if fields and f.name not in fields:\n+        if fields is not None and f.name not in fields:\n             continue\n         if exclude and f.name in exclude:\n             continue\n",
      "tokens": 313,
      "success": true,
      "similarity": 1.0
    },
    {
      "instance_id": "django__django-14580",
      "generated_patch": "--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -1,6 +1,7 @@\n import datetime\n import os\n import re\n+import types\n from collections import defaultdict\n from importlib import import_module\n \n@@ -146,6 +147,14 @@ class MigrationWriter:\n         self.needs_manual_porting = False\n         self.indentation = indentation\n \n+    def _is_models_module(self, obj):\n+        \"\"\"\n+        Return True if obj is the django.db.models module (or a proxy to it).\n+        \"\"\"\n+        if isinstance(obj, types.ModuleType):\n+            return obj.__name__ == 'django.db.models'\n+        return False\n+\n     def as_string(self):\n         \"\"\"Return the migration as a string.\"\"\"\n         items = {\n@@ -170,6 +179,10 @@ class MigrationWriter:\n         imports = set()\n         for operation in self.migration.operations:\n             operation_string, operation_imports = OperationWriter(operation).serialize()\n+            # If an operation references django.db.models (e.g. bases=(..., models.Model)),\n+            # ensure \"from django.db import models\" is present.\n+            if self._is_models_module(getattr(operation, 'bases', None)):\n+                imports.add('from django.db import models')\n             imports.update(operation_imports)\n             operations.append(operation_string)\n         items['operations'] = \"\\n\".join(operations) + \"\\n\" if operations else \"\"",
      "expected_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -273,7 +273,7 @@ def _format(self):\n class TypeSerializer(BaseSerializer):\n     def serialize(self):\n         special_cases = [\n-            (models.Model, \"models.Model\", []),\n+            (models.Model, \"models.Model\", ['from django.db import models']),\n             (type(None), 'type(None)', []),\n         ]\n         for case, string, imports in special_cases:\n",
      "tokens": 790,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-16255",
      "generated_patch": "--- a/django/contrib/sitemaps/__init__.py\n+++ b/django/contrib/sitemaps/__init__.py\n@@ -167,7 +167,7 @@\n         if not hasattr(self, \"lastmod\"):\n             return None\n         if callable(self.lastmod):\n             try:\n                 return max([self.lastmod(item) for item in self.items()])\n-            except TypeError:\n+            except (TypeError, ValueError):\n                 return None\n         else:\n             return self.lastmod",
      "expected_patch": "diff --git a/django/contrib/sitemaps/__init__.py b/django/contrib/sitemaps/__init__.py\n--- a/django/contrib/sitemaps/__init__.py\n+++ b/django/contrib/sitemaps/__init__.py\n@@ -167,7 +167,7 @@ def get_latest_lastmod(self):\n             return None\n         if callable(self.lastmod):\n             try:\n-                return max([self.lastmod(item) for item in self.items()])\n+                return max([self.lastmod(item) for item in self.items()], default=None)\n             except TypeError:\n                 return None\n         else:\n",
      "tokens": 597,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "sphinx-doc__sphinx-9591",
      "generated_patch": "--- a/sphinx/ext/autodoc/typehints.py\n+++ b/sphinx/ext/autodoc/typehints.py\n@@ -1,6 +1,7 @@\n \"\"\"Utilities for autodoc typehints.\"\"\"\n \n from __future__ import annotations\n+from inspect import isclass\n \n from typing import Any\n \n@@ -24,6 +25,7 @@\n from sphinx.util import inspect\n from sphinx.util.inspect import Signature, stringify_signature\n from sphinx.util.typing import get_type_hints, stringify_annotation\n+from sphinx.util.typing import restify\n \n if TYPE_CHECKING:\n     from collections.abc import Callable, Mapping\n@@ -188,6 +190,22 @@ def record_typehints(app: Sphinx, objtype: str, name: str, obj: Any,\n     except (AttributeError, TypeError):\n         return\n \n+    # For properties, the return annotation is the property's type.\n+    # Ensure it is recorded so it can be cross-referenced later.\n+    if isinstance(obj, property):\n+        try:\n+            rtype = get_type_hints(obj.fget, None, None).get('return')\n+        except Exception:\n+            rtype = None\n+        if rtype is not None:\n+            # store as reST so it can be resolved to a cross-reference\n+            if isclass(rtype):\n+                annotations['return'] = restify(rtype, 'class')\n+            else:\n+                annotations['return'] = stringify_annotation(rtype)\n+\n     if objtype in ('function', 'method'):\n         if app.config.autodoc_typehints_format == 'short':\n             for key, value in annotations.items():\n@@ -214,6 +232,10 @@ def merge_typehints(app: Sphinx, domain: str, objtype: str, contentnode: Element)\n     if domain != 'py':\n         return\n \n+    # properties are documented as attributes; their type is stored as 'return'\n+    if objtype == 'attribute' and 'return' in annotations and 'type' not in annotations:\n+        annotations['type'] = annotations['return']\n     if app.config.autodoc_typehints in ('none', 'description'):\n         return\n \n@@ -224,7 +246,7 @@ def merge_typehints(app: Sphinx, domain: str, objtype: str, contentnode: Element)\n     if objtype == 'attribute':\n         field_lists = [n for n in contentnode if isinstance(n, nodes.field_list)]\n         if field_lists:\n-            field_list = field_lists[-1]\n+            field_list = field_lists[-1]\n         else:\n             field_list = nodes.field_list()\n             contentnode += field_list",
      "expected_patch": "diff --git a/sphinx/domains/python.py b/sphinx/domains/python.py\n--- a/sphinx/domains/python.py\n+++ b/sphinx/domains/python.py\n@@ -861,7 +861,8 @@ def handle_signature(self, sig: str, signode: desc_signature) -> Tuple[str, str]\n \n         typ = self.options.get('type')\n         if typ:\n-            signode += addnodes.desc_annotation(typ, ': ' + typ)\n+            annotations = _parse_annotation(typ, self.env)\n+            signode += addnodes.desc_annotation(typ, '', nodes.Text(': '), *annotations)\n \n         return fullname, prefix\n \n",
      "tokens": 1141,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-21612",
      "generated_patch": "--- a/sympy/parsing/latex/_parse_latex_antlr.py\n+++ b/sympy/parsing/latex/_parse_latex_antlr.py\n@@ -1,6 +1,7 @@\n from __future__ import print_function, division\n \n from sympy import Add, Mul, Pow, Symbol, Integer, Rational, Float\n+from sympy.core.expr import Expr\n from sympy.core.numbers import Infinity, NegativeInfinity\n from sympy.core.sympify import sympify\n from sympy.functions.elementary.exponential import exp, log\n@@ -470,10 +471,18 @@\n         return self._convert_relation(rel)\n \n     def convertFrac(self, ctx):\n-        numer = self.convert(ctx.numer)\n-        denom = self.convert(ctx.denom)\n-        return numer/denom\n+        numer = self.convert(ctx.numer)\n+        denom = self.convert(ctx.denom)\n+        # Ensure the denominator is treated as a single expression.\n+        # Without this, nested fractions in the denominator can lose\n+        # grouping and be interpreted as chained division.\n+        if isinstance(denom, Expr):\n+            denom = denom.parenthesize()\n+        return numer/denom\n \n     def convertSqrt(self, ctx):\n         if ctx.index is None:\n             return sqrt(self.convert(ctx.base))",
      "expected_patch": "diff --git a/sympy/printing/str.py b/sympy/printing/str.py\n--- a/sympy/printing/str.py\n+++ b/sympy/printing/str.py\n@@ -333,7 +333,7 @@ def apow(i):\n                     b.append(apow(item))\n                 else:\n                     if (len(item.args[0].args) != 1 and\n-                            isinstance(item.base, Mul)):\n+                            isinstance(item.base, (Mul, Pow))):\n                         # To avoid situations like #14160\n                         pow_paren.append(item)\n                     b.append(item.base)\n",
      "tokens": 627,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-12125",
      "generated_patch": "--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -1,6 +1,7 @@\n import builtins\n import collections\n import datetime\n+import inspect\n import decimal\n import enum\n import functools\n import importlib\n@@ -269,6 +270,15 @@ class DeconstructableSerializer(BaseSerializer):\n         return self.serialize_deconstructed(path, args, kwargs)\n \n \n+def _qualname(obj):\n+    try:\n+        return obj.__qualname__\n+    except AttributeError:\n+        return obj.__name__\n+\n+\n class FunctionTypeSerializer(BaseSerializer):\n     def serialize(self):\n         if self.value.__name__ == '<lambda>':\n@@ -277,7 +287,7 @@ class FunctionTypeSerializer(BaseSerializer):\n         if self.value.__module__ == '__main__':\n             raise ValueError(\"Cannot serialize function: lambda\")\n-        return '%s.%s' % (self.value.__module__, self.value.__name__), set([self.value.__module__])\n+        return '%s.%s' % (self.value.__module__, _qualname(self.value)), set([self.value.__module__])\n \n \n class FunctoolsPartialSerializer(BaseSerializer):\n@@ -287,7 +297,7 @@ class FunctoolsPartialSerializer(BaseSerializer):\n \n \n class TypeSerializer(BaseSerializer):\n     def serialize(self):\n-        special_cases = [\n+        special_cases = [\n             (datetime.datetime, 'datetime.datetime'),\n             (datetime.date, 'datetime.date'),\n             (datetime.time, 'datetime.time'),\n@@ -303,7 +313,7 @@ class TypeSerializer(BaseSerializer):\n         for case, string in special_cases:\n             if case is self.value:\n                 return string, {'datetime'}\n-        return '%s.%s' % (self.value.__module__, self.value.__name__), {self.value.__module__}\n+        return '%s.%s' % (self.value.__module__, _qualname(self.value)), {self.value.__module__}\n \n \n class UUIDSerializer(BaseSerializer):\n     def serialize(self):\n@@ -313,7 +323,7 @@ class UUIDSerializer(BaseSerializer):\n \n \n class EnumSerializer(BaseSerializer):\n     def serialize(self):\n-        enum_class = self.value.__class__\n+        enum_class = self.value.__class__\n         module = enum_class.__module__\n-        return '%s.%s[%r]' % (module, enum_class.__name__, self.value.name), {module}\n+        return '%s.%s[%r]' % (module, _qualname(enum_class), self.value.name), {module}\n \n \n class BaseSequenceSerializer(BaseSerializer):\n     def _serialize(self):\n@@ -340,7 +350,7 @@ class BaseSequenceSerializer(BaseSerializer):\n \n \n class ModelFieldSerializer(DeconstructableSerializer):\n     def serialize(self):\n         # Deconstruct the field, then serialize the result.\n         name, path, args, kwargs = self.value.deconstruct()\n-        return self.serialize_deconstructed(path, args, kwargs)\n+        return self.serialize_deconstructed(path, args, kwargs)\n \n \n class ModelManagerSerializer(DeconstructableSerializer):\n     def serialize(self):\n         name, path, args, kwargs = self.value.deconstruct()\n         return self.serialize_deconstructed(path, args, kwargs)\n@@ -349,7 +359,7 @@ class ModelManagerSerializer(DeconstructableSerializer):\n class ModelSerializer(BaseSerializer):\n     def serialize(self):\n         if self.value._meta.swapped:\n             raise ValueError(\"Cannot serialize swapped model: %s\" % self.value)\n-        return \"%s.%s\" % (self.value._meta.app_label, self.value._meta.object_name), set()\n+        return \"%s.%s\" % (self.value._meta.app_label, self.value._meta.object_name), set()\n \n \n class SettingsReferenceSerializer(BaseSerializer):\n     def serialize(self):\n         return \"settings.%s\" % self.value.setting_name, {'django.conf'}",
      "expected_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -269,7 +269,7 @@ def serialize(self):\n             if module == builtins.__name__:\n                 return self.value.__name__, set()\n             else:\n-                return \"%s.%s\" % (module, self.value.__name__), {\"import %s\" % module}\n+                return \"%s.%s\" % (module, self.value.__qualname__), {\"import %s\" % module}\n \n \n class UUIDSerializer(BaseSerializer):\n",
      "tokens": 1277,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-17087",
      "generated_patch": "--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -1,6 +1,7 @@\n import builtins\n import collections.abc\n import datetime\n+import inspect\n import decimal\n import enum\n import functools\n@@ -1,6 +1,7 @@\n import importlib\n import math\n import os\n+import sys\n import pathlib\n import re\n import types\n@@ -1,6 +1,7 @@\n from django.conf import settings\n from django.db.migrations.utils import COMPILED_REGEX_TYPE, RegexObject\n from django.utils.functional import Promise\n+from django.utils.module_loading import import_string\n \n \n class BaseSerializer:\n@@ -1,6 +1,7 @@\n class FunctionTypeSerializer(BaseSerializer):\n     def serialize(self):\n         func = self.value\n+        module = sys.modules.get(func.__module__)\n         if getattr(func, \"__self__\", None) and isinstance(func.__self__, type):\n             klass = func.__self__\n             module = klass.__module__\n@@ -1,12 +1,33 @@\n             if klass.__module__ == \"builtins\":\n                 return \"%s.%s\" % (klass.__name__, func.__name__), set()\n             return \"%s.%s.%s\" % (module, klass.__name__, func.__name__), {module}\n-        if hasattr(func, \"__qualname__\"):\n-            return \"%s.%s\" % (func.__module__, func.__qualname__), {func.__module__}\n+        if hasattr(func, \"__qualname__\"):\n+            qualname = func.__qualname__\n+            # If this is a method of a nested class, __qualname__ contains\n+            # '<locals>' for locally defined classes/functions. For nested\n+            # classes defined at module scope, ensure the full dotted path is\n+            # used (e.g. Profile.Capability.default).\n+            if module is not None and \"<locals>\" not in qualname:\n+                try:\n+                    obj = module\n+                    for part in qualname.split(\".\"):\n+                        obj = getattr(obj, part)\n+                    if obj is func:\n+                        return \"%s.%s\" % (func.__module__, qualname), {func.__module__}\n+                except Exception:\n+                    pass\n+            # Fall back to resolving via __self__ for classmethods/staticmethods\n+            # where __qualname__ may not be sufficient.\n+            if getattr(func, \"__self__\", None) and isinstance(func.__self__, type):\n+                klass = func.__self__\n+                return \"%s.%s.%s\" % (klass.__module__, klass.__qualname__, func.__name__), {klass.__module__}\n+            return \"%s.%s\" % (func.__module__, qualname), {func.__module__}\n         raise ValueError(\"Cannot serialize function: %r\" % func)",
      "expected_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -168,7 +168,7 @@ def serialize(self):\n         ):\n             klass = self.value.__self__\n             module = klass.__module__\n-            return \"%s.%s.%s\" % (module, klass.__name__, self.value.__name__), {\n+            return \"%s.%s.%s\" % (module, klass.__qualname__, self.value.__name__), {\n                 \"import %s\" % module\n             }\n         # Further error checking\n",
      "tokens": 980,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-13480",
      "generated_patch": "--- a/sympy/functions/elementary/hyperbolic.py\n+++ b/sympy/functions/elementary/hyperbolic.py\n@@ -587,7 +587,7 @@\n         if arg.is_Number:\n             t = tanh(arg)\n             if t is S.ComplexInfinity:\n-                if cotm is S.ComplexInfinity:\n+                if t is S.ComplexInfinity:\n                     return S.NaN\n                 return S.Zero\n             return 1/t",
      "expected_patch": "diff --git a/sympy/functions/elementary/hyperbolic.py b/sympy/functions/elementary/hyperbolic.py\n--- a/sympy/functions/elementary/hyperbolic.py\n+++ b/sympy/functions/elementary/hyperbolic.py\n@@ -587,7 +587,7 @@ def eval(cls, arg):\n                 x, m = _peeloff_ipi(arg)\n                 if m:\n                     cothm = coth(m)\n-                    if cotm is S.ComplexInfinity:\n+                    if cothm is S.ComplexInfinity:\n                         return coth(x)\n                     else: # cothm == 0\n                         return tanh(x)\n",
      "tokens": 344,
      "success": true,
      "similarity": 0.5
    },
    {
      "instance_id": "pylint-dev__pylint-6903",
      "generated_patch": "--- a/pylint/lint/run.py\n+++ b/pylint/lint/run.py\n@@ -28,6 +28,7 @@\n from __future__ import annotations\n \n import argparse\n+import math\n import os\n import sys\n from pathlib import Path\n@@ -49,7 +50,7 @@\n     try:\n         with open(\"/sys/fs/cgroup/cpu/cpu.cfs_quota_us\", encoding=\"utf-8\") as quota_file:\n             quota = int(quota_file.read())\n-        if quota > 0:\n+        if quota > 0:\n             with open(\n                 \"/sys/fs/cgroup/cpu/cpu.cfs_period_us\", encoding=\"utf-8\"\n             ) as period_file:\n@@ -57,7 +58,7 @@\n             return quota // period\n         with open(\"/sys/fs/cgroup/cpu/cpu.shares\", encoding=\"utf-8\") as shares_file:\n             shares = int(shares_file.read())\n-        return int(shares / 1024)\n+        return max(1, math.ceil(shares / 1024))\n     except OSError:\n         return os.cpu_count() or 1",
      "expected_patch": "diff --git a/pylint/lint/run.py b/pylint/lint/run.py\n--- a/pylint/lint/run.py\n+++ b/pylint/lint/run.py\n@@ -58,6 +58,13 @@ def _query_cpu() -> int | None:\n             cpu_shares = int(file.read().rstrip())\n         # For AWS, gives correct value * 1024.\n         avail_cpu = int(cpu_shares / 1024)\n+\n+    # In K8s Pods also a fraction of a single core could be available\n+    # As multiprocessing is not able to run only a \"fraction\" of process\n+    # assume we have 1 CPU available\n+    if avail_cpu == 0:\n+        avail_cpu = 1\n+\n     return avail_cpu\n \n \n",
      "tokens": 1183,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-14053",
      "generated_patch": "--- a/sklearn/tree/export.py\n+++ b/sklearn/tree/export.py\n@@ -1,6 +1,7 @@\n \"\"\"Utilities to export decision trees.\"\"\"\n \n # Authors: The scikit-learn developers\n+# SPDX-License-Identifier: BSD-3-Clause\n \n from io import StringIO\n \n@@ -1000,7 +1001,7 @@ def export_text(decision_tree, feature_names=None, max_depth=10,\n     if feature_names is not None:\n         if len(feature_names) != n_features:\n             raise ValueError(\n-                \"feature_names must contain %d elements, got %d\"\n+                \"feature_names must contain %d elements, got %d\"\n                 % (n_features, len(feature_names))\n             )\n \n@@ -1010,7 +1011,7 @@ def export_text(decision_tree, feature_names=None, max_depth=10,\n         feature_names = [\"feature_%d\" % i for i in range(n_features)]\n \n     # The tree_.feature attribute contains the feature index for each node.\n-    feature_names_ = [feature_names[i] for i in tree_.feature]\n+    feature_names_ = [feature_names[i] if i >= 0 else None for i in tree_.feature]\n \n     def _add_leaf(value, class_names, indent):\n         if class_names is not None:\n@@ -1046,7 +1047,7 @@ def export_text(decision_tree, feature_names=None, max_depth=10,\n             if tree_.children_left[node_id] == tree_.children_right[node_id]:\n                 # leaf node\n                 value = tree_.value[node_id][0]\n                 _add_leaf(value, class_names, indent)\n                 return\n \n-            name = feature_names_[node_id]\n+            name = feature_names_[node_id] if feature_names_[node_id] is not None else \"undefined!\"\n             threshold = tree_.threshold[node_id]\n \n             # left child\n             text_report.write(\n                 \"%s|--- %s <= %.4f\\n\" % (indent, name, threshold)\n             )",
      "expected_patch": "diff --git a/sklearn/tree/export.py b/sklearn/tree/export.py\n--- a/sklearn/tree/export.py\n+++ b/sklearn/tree/export.py\n@@ -890,7 +890,8 @@ def export_text(decision_tree, feature_names=None, max_depth=10,\n         value_fmt = \"{}{} value: {}\\n\"\n \n     if feature_names:\n-        feature_names_ = [feature_names[i] for i in tree_.feature]\n+        feature_names_ = [feature_names[i] if i != _tree.TREE_UNDEFINED\n+                          else None for i in tree_.feature]\n     else:\n         feature_names_ = [\"feature_{}\".format(i) for i in tree_.feature]\n \n",
      "tokens": 1352,
      "success": true,
      "similarity": 0.3333333333333333
    },
    {
      "instance_id": "django__django-11964",
      "generated_patch": "--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -1,6 +1,7 @@\n import copy\n import datetime\n import decimal\n+import enum\n import functools\n import inspect\n import operator\n@@ -1158,6 +1159,10 @@ class Field(RegisterLookupMixin):\n         \"\"\"\n         return value\n \n+    def _coerce_enum_value(self, value):\n+        return value.value if isinstance(value, enum.Enum) else value\n+\n     def get_prep_value(self, value):\n         \"\"\"Perform preliminary non-db specific value checks and conversions.\"\"\"\n         if isinstance(value, Promise):\n@@ -1165,7 +1170,7 @@ class Field(RegisterLookupMixin):\n         return value\n \n     def get_db_prep_value(self, value, connection, prepared=False):\n-        if not prepared:\n+        if not prepared:\n             value = self.get_prep_value(value)\n         return value\n \n@@ -1200,7 +1205,7 @@ class Field(RegisterLookupMixin):\n         \"\"\"\n         if value is None:\n             return None\n-        return self.to_python(value)\n+        return self.to_python(self._coerce_enum_value(value))\n \n     def get_prep_value(self, value):\n         \"\"\"\n@@ -1210,7 +1215,7 @@ class Field(RegisterLookupMixin):\n         \"\"\"\n         if value is None:\n             return None\n-        return value\n+        return self._coerce_enum_value(value)\n \n     def get_db_prep_save(self, value, connection):\n         \"\"\"Return field's value prepared for saving into a database.\"\"\"",
      "expected_patch": "diff --git a/django/db/models/enums.py b/django/db/models/enums.py\n--- a/django/db/models/enums.py\n+++ b/django/db/models/enums.py\n@@ -60,7 +60,13 @@ def values(cls):\n \n class Choices(enum.Enum, metaclass=ChoicesMeta):\n     \"\"\"Class for creating enumerated choices.\"\"\"\n-    pass\n+\n+    def __str__(self):\n+        \"\"\"\n+        Use value when cast to str, so that Choices set as model instance\n+        attributes are rendered as expected in templates and similar contexts.\n+        \"\"\"\n+        return str(self.value)\n \n \n class IntegerChoices(int, Choices):\n",
      "tokens": 950,
      "success": true,
      "similarity": 0.14285714285714285
    },
    {
      "instance_id": "pydata__xarray-4695",
      "generated_patch": "--- a/xarray/core/indexing.py\n+++ b/xarray/core/indexing.py\n@@ -1,6 +1,7 @@\n from __future__ import annotations\n \n from collections.abc import Mapping\n+import inspect\n from typing import Any\n \n import numpy as np\n \n@@ -431,11 +432,19 @@ class _LocIndexer:\n     def __getitem__(self, key: Any) -> Any:\n         if not isinstance(key, Mapping):\n             raise TypeError(\"can only lookup dictionaries from .loc\")\n-        return self._obj.sel(**key)\n+        sel = getattr(self._obj, \"sel\")\n+        try:\n+            params = inspect.signature(sel).parameters\n+        except (TypeError, ValueError):\n+            params = {}\n+        if \"method\" in key and \"method\" in params:\n+            # Disambiguate between a dimension/coordinate named \"method\"\n+            # and the `method=` keyword argument to `.sel`.\n+            return sel(indexers=key)\n+        return sel(**key)",
      "expected_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -196,7 +196,7 @@ def __getitem__(self, key) -> \"DataArray\":\n             # expand the indexer so we can handle Ellipsis\n             labels = indexing.expanded_indexer(key, self.data_array.ndim)\n             key = dict(zip(self.data_array.dims, labels))\n-        return self.data_array.sel(**key)\n+        return self.data_array.sel(key)\n \n     def __setitem__(self, key, value) -> None:\n         if not utils.is_dict_like(key):\n",
      "tokens": 1594,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-10097",
      "generated_patch": "--- a/django/core/validators.py\n+++ b/django/core/validators.py\n@@ -1,6 +1,7 @@\n import ipaddress\n import re\n from pathlib import Path\n+from urllib.parse import unquote\n \n from django.core.exceptions import ValidationError\n from django.utils.deconstruct import deconstructible\n@@ -129,7 +130,7 @@\n     r\"(?:(?:[a-z\\u00a1-\\uffff0-9]-*)*[a-z\\u00a1-\\uffff0-9]+)\"\n     r\"(?:\\.(?:[a-z\\u00a1-\\uffff0-9]-*)*[a-z\\u00a1-\\uffff0-9]+)*\"\n     r\"(?:\\.(?:[a-z\\u00a1-\\uffff]{2,}))\"\n     r\")\"\n     r\"(?::\\d{2,5})?\"\n     r\"(?:[/?#][^\\s]*)?\"\n     r\"\\Z\",\n     re.IGNORECASE,\n )\n@@ -138,6 +139,7 @@\n @deconstructible\n class URLValidator(RegexValidator):\n     regex = _lazy_re_compile(\n         r\"^(?:[a-z0-9.+-]*)://\"  # scheme is validated separately\n         r\"(?:\\S+(?::\\S*)?@)?\"  # user:pass authentication\n         r\"(?:\" + ipv4_re + \"|\" + ipv6_re + \"|\" + hostname_re + \")\"\n         r\"(?::\\d{2,5})?\"  # port\n         r\"(?:[/?#][^\\s]*)?\"  # resource path\n         r\"\\Z\",\n         re.IGNORECASE,\n     )\n@@ -171,6 +173,23 @@\n     def __call__(self, value):\n         if not isinstance(value, str):\n             raise ValidationError(self.message, code=self.code)\n+        # RFC 1738 section 3.1: within the user and password field, any\n+        # \":\", \"@\", or \"/\" must be %-encoded.\n+        m = re.match(r\"^(?:[a-z0-9.+-]*)://([^/?#]*)\", value, re.IGNORECASE)\n+        if m:\n+            authority = m.group(1)\n+            if \"@\" in authority:\n+                userinfo = authority.rsplit(\"@\", 1)[0]\n+                if \":\" in userinfo:\n+                    username, password = userinfo.split(\":\", 1)\n+                else:\n+                    username, password = userinfo, \"\"\n+                for part in (username, password):\n+                    decoded = unquote(part)\n+                    if any(c in decoded for c in (\":\", \"@\", \"/\")):\n+                        raise ValidationError(self.message, code=self.code)\n         # Check if the scheme is valid.\n         scheme = value.split(\"://\")[0].lower()\n         if scheme not in self.schemes:\n             raise ValidationError(self.message, code=self.code)\n         super().__call__(value)\n--- a/tests/validators/tests.py\n+++ b/tests/validators/tests.py\n@@ -1,6 +1,7 @@\n import os\n import re\n import unittest\n+from django.core.exceptions import ValidationError\n \n from django.core.validators import (\n     EmailValidator,\n     URLValidator,\n@@ -96,6 +97,14 @@\n class TestURLValidator(SimpleTestCase):\n     def test_valid_urls(self):\n         v = URLValidator()\n         for url in self.valid_urls:\n             v(url)\n \n+    def test_invalid_userinfo_characters_must_be_percent_encoded(self):\n+        v = URLValidator()\n+        invalid = [\n+            \"http://foo/bar@example.com\",\n+            \"http://foo:bar/baz@example.com\",\n+            \"http://foo@bar:baz@example.com\",\n+        ]\n+        for url in invalid:\n+            with self.assertRaises(ValidationError):\n+                v(url)\n+\n     def test_invalid_urls(self):\n         v = URLValidator()\n         for url in self.invalid_urls:\n             with self.assertRaises(ValidationError):\n                 v(url)",
      "expected_patch": "diff --git a/django/core/validators.py b/django/core/validators.py\n--- a/django/core/validators.py\n+++ b/django/core/validators.py\n@@ -94,7 +94,7 @@ class URLValidator(RegexValidator):\n \n     regex = _lazy_re_compile(\n         r'^(?:[a-z0-9\\.\\-\\+]*)://'  # scheme is validated separately\n-        r'(?:\\S+(?::\\S*)?@)?'  # user:pass authentication\n+        r'(?:[^\\s:@/]+(?::[^\\s:@/]*)?@)?'  # user:pass authentication\n         r'(?:' + ipv4_re + '|' + ipv6_re + '|' + host_re + ')'\n         r'(?::\\d{2,5})?'  # port\n         r'(?:[/?#][^\\s]*)?'  # resource path\n",
      "tokens": 1520,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-12273",
      "generated_patch": "--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -1040,6 +1040,11 @@ class Model(metaclass=ModelBase):\n         if not meta.auto_created:\n             pre_save.send(sender=origin, instance=self, raw=raw, using=using,\n                           update_fields=update_fields)\n+\n+        # If the primary key is reset on a multi-table inherited child instance,\n+        # ensure the instance is treated as unsaved so INSERT is used.\n+        if meta.parents and self._is_pk_set(meta) is False:\n+            self._state.adding = True\n \n         # A transaction isn't needed if one query is issued.\n         if meta.parents:\n             context_manager = transaction.atomic(using=using, savepoint=False)\n@@ -1050,6 +1055,11 @@ class Model(metaclass=ModelBase):\n         with context_manager:\n             parent_inserted = False\n             if meta.parents:\n+                # If the primary key is reset, force INSERT for parent and child.\n+                if self._is_pk_set(meta) is False:\n+                    force_insert = True\n+                    force_update = False\n                 for parent, field in meta.parents.items():\n                     # Make sure the link fields are synced between parent and\n                     # child.\n                     if field:\n                         setattr(self, field.attname, self._get_pk_val(parent._meta))\n",
      "expected_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -569,6 +569,9 @@ def _get_pk_val(self, meta=None):\n         return getattr(self, meta.pk.attname)\n \n     def _set_pk_val(self, value):\n+        for parent_link in self._meta.parents.values():\n+            if parent_link and parent_link != self._meta.pk:\n+                setattr(self, parent_link.target_field.attname, value)\n         return setattr(self, self._meta.pk.attname, value)\n \n     pk = property(_get_pk_val, _set_pk_val)\n",
      "tokens": 610,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-13779",
      "generated_patch": "--- a/sklearn/ensemble/_voting.py\n+++ b/sklearn/ensemble/_voting.py\n@@ -1,6 +1,7 @@\n \"\"\"Voting Classifier and Regressor.\"\"\"\n \n # Authors: The scikit-learn developers\n+# SPDX-License-Identifier: BSD-3-Clause\n \n from abc import ABCMeta, abstractmethod\n from numbers import Integral\n@@ -78,6 +79,7 @@ class _BaseVoting(TransformerMixin, _BaseHeterogeneousEnsemble, metaclass=ABCMeta\n         self.verbose = verbose\n         self.n_jobs = n_jobs\n         self.flatten_transform = flatten_transform\n+        self.weights = weights\n \n     def _log_message(self, name, idx, total):\n         if not self.verbose:\n@@ -89,6 +91,7 @@ class _BaseVoting(TransformerMixin, _BaseHeterogeneousEnsemble, metaclass=ABCMeta\n             return f\"({idx} of {total}) Processing {name}\"\n \n     def fit(self, X, y, **fit_params):\n+        self._validate_estimators()\n         if self.voting == \"soft\":\n             self._validate_estimators()\n \n@@ -96,16 +99,18 @@ class _BaseVoting(TransformerMixin, _BaseHeterogeneousEnsemble, metaclass=ABCMeta\n         self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n             delayed(_fit_single_estimator)(\n                 clone(clf),\n                 X,\n                 y,\n                 fit_params=fit_params,\n                 message_clsname=\"Voting\",\n                 message=self._log_message(name, idx + 1, len(self.estimators)),\n             )\n-            for idx, (name, clf) in enumerate(self.estimators)\n+            for idx, (name, clf) in enumerate(self.estimators)\n+            if clf is not None\n         )\n \n         self.named_estimators_ = Bunch()\n         for name, est in zip(self.estimators, self.estimators_):\n             self.named_estimators_[name[0]] = est",
      "expected_patch": "diff --git a/sklearn/ensemble/voting.py b/sklearn/ensemble/voting.py\n--- a/sklearn/ensemble/voting.py\n+++ b/sklearn/ensemble/voting.py\n@@ -78,6 +78,8 @@ def fit(self, X, y, sample_weight=None):\n \n         if sample_weight is not None:\n             for name, step in self.estimators:\n+                if step is None:\n+                    continue\n                 if not has_fit_parameter(step, 'sample_weight'):\n                     raise ValueError('Underlying estimator \\'%s\\' does not'\n                                      ' support sample weights.' % name)\n",
      "tokens": 669,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-15017",
      "generated_patch": "--- a/sympy/tensor/array/ndim_array.py\n+++ b/sympy/tensor/array/ndim_array.py\n@@ -1,6 +1,7 @@\n from __future__ import print_function, division\n \n from sympy.core.basic import Basic\n+from sympy.core.numbers import Integer\n from sympy.core.compatibility import is_sequence\n from sympy.core.sympify import sympify\n from sympy.core.singleton import S\n@@ -183,7 +184,7 @@ class NDimArray(Basic):\n         return self._rank\n \n     def __len__(self):\n-        return self._loop_size\n+        return Integer(1) if self.rank() == 0 else self._loop_size\n \n     def __iter__(self):\n         if self.rank() == 0:\n             yield self._array[0]",
      "expected_patch": "diff --git a/sympy/tensor/array/dense_ndim_array.py b/sympy/tensor/array/dense_ndim_array.py\n--- a/sympy/tensor/array/dense_ndim_array.py\n+++ b/sympy/tensor/array/dense_ndim_array.py\n@@ -149,7 +149,7 @@ def _new(cls, iterable, shape, **kwargs):\n         self._shape = shape\n         self._array = list(flat_list)\n         self._rank = len(shape)\n-        self._loop_size = functools.reduce(lambda x,y: x*y, shape) if shape else 0\n+        self._loop_size = functools.reduce(lambda x,y: x*y, shape, 1)\n         return self\n \n     def __setitem__(self, index, value):\n",
      "tokens": 563,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "pytest-dev__pytest-7205",
      "generated_patch": "--- a/src/_pytest/setuponly.py\n+++ b/src/_pytest/setuponly.py\n@@ -1,6 +1,7 @@\n \"\"\"Implementation of the --setup-show option.\"\"\"\n \n from typing import Any\n+from _pytest._io.saferepr import saferepr\n \n \n def pytest_addoption(parser):\n@@ -66,7 +67,7 @@ def _show_fixture_action(fixturedef, msg):\n                 tw.write(\" (fixtures used: {})\".format(\", \".join(deps)))\n \n         if hasattr(fixturedef, \"cached_param\"):\n-            tw.write(\"[{}]\".format(fixturedef.cached_param))\n+            tw.write(\"[{}]\".format(saferepr(fixturedef.cached_param)))\n \n         tw.flush()\n \n         if capman:",
      "expected_patch": "diff --git a/src/_pytest/setuponly.py b/src/_pytest/setuponly.py\n--- a/src/_pytest/setuponly.py\n+++ b/src/_pytest/setuponly.py\n@@ -1,4 +1,5 @@\n import pytest\n+from _pytest._io.saferepr import saferepr\n \n \n def pytest_addoption(parser):\n@@ -66,7 +67,7 @@ def _show_fixture_action(fixturedef, msg):\n             tw.write(\" (fixtures used: {})\".format(\", \".join(deps)))\n \n     if hasattr(fixturedef, \"cached_param\"):\n-        tw.write(\"[{}]\".format(fixturedef.cached_param))\n+        tw.write(\"[{}]\".format(saferepr(fixturedef.cached_param, maxsize=42)))\n \n     tw.flush()\n \n",
      "tokens": 1426,
      "success": true,
      "similarity": 0.6666666666666666
    },
    {
      "instance_id": "sphinx-doc__sphinx-8721",
      "generated_patch": "--- a/sphinx/ext/viewcode.py\n+++ b/sphinx/ext/viewcode.py\n@@ -1,6 +1,7 @@\n \"\"\"Add links to module code in Python object descriptions.\"\"\"\n \n from __future__ import annotations\n \n+from sphinx.builders.epub3 import Epub3Builder\n from sphinx.application import Sphinx\n from sphinx.locale import _\n from sphinx.util import logging\n from sphinx.util.inspect import safe_getattr\n from sphinx.util.nodes import make_refnode\n@@ -90,6 +91,10 @@ def should_generate_module_page(app: Sphinx) -> bool:\n     if app.builder.format != 'html':\n         return False\n \n+    if isinstance(app.builder, Epub3Builder):\n+        return app.config.viewcode_enable_epub\n+\n     return True\n \n \n def collect_pages(app: Sphinx) -> Iterator[tuple[str, dict[str, Any], str]]:\n@@ -98,7 +103,7 @@ def collect_pages(app: Sphinx) -> Iterator[tuple[str, dict[str, Any], str]]:\n     if not should_generate_module_page(app):\n         return\n \n-    if app.builder.name == 'epub' and not app.config.viewcode_enable_epub:\n+    if app.builder.name == 'epub' and not app.config.viewcode_enable_epub:\n         return\n \n     highlighter = app.builder.highlighter",
      "expected_patch": "diff --git a/sphinx/ext/viewcode.py b/sphinx/ext/viewcode.py\n--- a/sphinx/ext/viewcode.py\n+++ b/sphinx/ext/viewcode.py\n@@ -182,6 +182,10 @@ def collect_pages(app: Sphinx) -> Generator[Tuple[str, Dict[str, Any], str], Non\n     env = app.builder.env\n     if not hasattr(env, '_viewcode_modules'):\n         return\n+    if app.builder.name == \"singlehtml\":\n+        return\n+    if app.builder.name.startswith(\"epub\") and not env.config.viewcode_enable_epub:\n+        return\n     highlighter = app.builder.highlighter  # type: ignore\n     urito = app.builder.get_relative_uri\n \n",
      "tokens": 529,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-11451",
      "generated_patch": "--- a/django/contrib/auth/backends.py\n+++ b/django/contrib/auth/backends.py\n@@ -54,10 +54,13 @@\n class ModelBackend(BaseBackend):\n     \"\"\"\n     Authenticates against settings.AUTH_USER_MODEL.\n     \"\"\"\n \n     def authenticate(self, request, username=None, password=None, **kwargs):\n         if username is None:\n             username = kwargs.get(UserModel.USERNAME_FIELD)\n+        if username is None or password is None:\n+            return\n         try:\n             user = UserModel._default_manager.get_by_natural_key(username)\n         except UserModel.DoesNotExist:\n             # Run the default password hasher once to reduce the timing\n             # difference between an existing and a nonexistent user (#20760).\n             UserModel().set_password(password)\n         else:\n             if user.check_password(password) and self.user_can_authenticate(user):\n                 return user",
      "expected_patch": "diff --git a/django/contrib/auth/backends.py b/django/contrib/auth/backends.py\n--- a/django/contrib/auth/backends.py\n+++ b/django/contrib/auth/backends.py\n@@ -39,6 +39,8 @@ class ModelBackend(BaseBackend):\n     def authenticate(self, request, username=None, password=None, **kwargs):\n         if username is None:\n             username = kwargs.get(UserModel.USERNAME_FIELD)\n+        if username is None or password is None:\n+            return\n         try:\n             user = UserModel._default_manager.get_by_natural_key(username)\n         except UserModel.DoesNotExist:\n",
      "tokens": 719,
      "success": true,
      "similarity": 1.0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-11578",
      "generated_patch": "--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -919,7 +919,8 @@ def _log_reg_scoring_path(X, y, train, test, pos_class=None, Cs=10,\n     else:\n         class_weight_ = None\n \n-    log_reg = LogisticRegression(fit_intercept=fit_intercept)\n+    log_reg = LogisticRegression(fit_intercept=fit_intercept,\n+                                 multi_class=multi_class)\n \n     # The score is computed on the test set\n     X_test = X[test]\n     y_test = y[test]",
      "expected_patch": "diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py\n--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -922,7 +922,7 @@ def _log_reg_scoring_path(X, y, train, test, pos_class=None, Cs=10,\n         check_input=False, max_squared_sum=max_squared_sum,\n         sample_weight=sample_weight)\n \n-    log_reg = LogisticRegression(fit_intercept=fit_intercept)\n+    log_reg = LogisticRegression(multi_class=multi_class)\n \n     # The score method of Logistic Regression has a classes_ attribute.\n     if multi_class == 'ovr':\n",
      "tokens": 2008,
      "success": true,
      "similarity": 0.5
    },
    {
      "instance_id": "django__django-11179",
      "generated_patch": "--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -273,12 +273,12 @@\n         if not self.data:\n             return\n         # sort instance collections\n         for model, instances in self.data.items():\n             self.data[model] = sorted(instances, key=attrgetter(\"pk\"))\n         self.sort()\n         # send pre_delete signals\n         for model, obj in self.instances_with_model():\n             if not model._meta.auto_created:\n                 signals.pre_delete.send(\n                     sender=model, instance=obj, using=self.using, origin=self.origin,\n                 )\n         # fast deletes\n         for qs in self.fast_deletes:\n             qs._raw_delete(using=self.using)\n         # update fields\n         for (field, value), instances_list in self.field_updates.items():\n             query = sql.UpdateQuery(field.model)\n             query.update_batch([obj.pk for obj in instances_list], {field.name: value}, self.using)\n         # delete instances\n         for model, instances in self.data.items():\n             query = sql.DeleteQuery(model)\n             pk_list = [obj.pk for obj in instances]\n             count = query.delete_batch(pk_list, self.using)\n             if count:\n                 deleted_counter[model._meta.label] += count\n-            for obj in instances:\n-                setattr(obj, model._meta.pk.attname, None)\n+            for obj in instances:\n+                setattr(obj, model._meta.pk.attname, None)\n         # send post_delete signals\n         for model, obj in self.instances_with_model():\n             if not model._meta.auto_created:\n                 signals.post_delete.send(\n                     sender=model, instance=obj, using=self.using, origin=self.origin,\n                 )\n         return sum(deleted_counter.values()), dict(deleted_counter)",
      "expected_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -277,6 +277,7 @@ def delete(self):\n             if self.can_fast_delete(instance):\n                 with transaction.mark_for_rollback_on_error():\n                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+                setattr(instance, model._meta.pk.attname, None)\n                 return count, {model._meta.label: count}\n \n         with transaction.atomic(using=self.using, savepoint=False):\n",
      "tokens": 530,
      "success": true,
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-12663",
      "generated_patch": "--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -1,6 +1,7 @@\n import copy\n import datetime\n import decimal\n+from django.utils.functional import Promise\n import operator\n import uuid\n \n@@ -964,6 +965,9 @@ class IntegerField(Field):\n     def get_prep_value(self, value):\n         value = super().get_prep_value(value)\n         if value is None:\n             return None\n+        # Unwrap lazy objects (e.g. SimpleLazyObject) before coercion.\n+        if isinstance(value, Promise):\n+            value = value._proxy____cast()\n         return int(value)",
      "expected_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -233,7 +233,8 @@ def __init__(self, model, where=WhereNode, alias_cols=True):\n     @property\n     def output_field(self):\n         if len(self.select) == 1:\n-            return self.select[0].field\n+            select = self.select[0]\n+            return getattr(select, 'target', None) or select.field\n         elif len(self.annotation_select) == 1:\n             return next(iter(self.annotation_select.values())).output_field\n \n",
      "tokens": 990,
      "success": true,
      "similarity": 0.0
    }
  ],
  "mutated": [
    {
      "instance_id": "sympy__sympy-22914_mutated_46f0a261",
      "generated_patch": "--- a/sympy/printing/pycode.py\n+++ b/sympy/printing/pycode.py\n@@ -1,6 +1,6 @@\n \"\"\"\n Python code printer\n \n-See sympy.printing.pycode for more information.\n+See sympy.printing.pycode for more information.\n \"\"\"\n \n from __future__ import annotations\n@@ -327,6 +327,12 @@ class PythonCodePrinter(AbstractPythonCodePrinter):\n     def _print_Abs(self, expr):\n         return \"abs(%s)\" % self._print(expr.args[0])\n \n+    def _print_Min(self, expr):\n+        return \"min({})\".format(\", \".join(self._print(arg) for arg in expr.args))\n+\n+    def _print_Max(self, expr):\n+        return \"max({})\".format(\", \".join(self._print(arg) for arg in expr.args))\n+\n     def _print_Rational(self, expr):\n         if expr.q != 1:\n             return '%d/%d' % (expr.p, expr.q)",
      "expected_patch": "diff --git a/sympy/printing/pycode.py b/sympy/printing/pycode.py\n--- a/sympy/printing/pycode.py\n+++ b/sympy/printing/pycode.py\n@@ -18,6 +18,8 @@\n \n _known_functions = {\n     'Abs': 'abs',\n+    'Min': 'min',\n+    'Max': 'max',\n }\n _known_functions_math = {\n     'acos': 'acos',\n",
      "tokens": 483,
      "success": true,
      "original_instance_id": "sympy__sympy-22914",
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-23950_mutated_d6382cbc",
      "generated_patch": "--- a/sympy/sets/contains.py\n+++ b/sympy/sets/contains.py\n@@ -1,6 +1,7 @@\n from __future__ import annotations\n \n from sympy.core.relational import Relational\n+from sympy.logic.boolalg import BooleanAtom\n from sympy.core.sympify import _sympify\n from sympy.core.singleton import S\n from sympy.core.basic import Basic\n@@ -8,7 +9,7 @@\n from sympy.core.logic import fuzzy_bool\n from sympy.sets.sets import Set\n \n \n-class Contains(Relational):\n+class Contains(Relational, BooleanAtom):\n     \"\"\"\n     Asserts that x is an element of the set S\n \n@@ -63,6 +64,10 @@\n     def as_set(self):\n-        return self\n+        raise TypeError(\"Contains is a Boolean and cannot be converted to a Set\")\n \n     def _eval_as_set(self):\n         return self.as_set()",
      "expected_patch": "diff --git a/sympy/sets/contains.py b/sympy/sets/contains.py\n--- a/sympy/sets/contains.py\n+++ b/sympy/sets/contains.py\n@@ -45,4 +45,4 @@ def binary_symbols(self):\n             isinstance(i, (Eq, Ne))])\n \n     def as_set(self):\n-        raise NotImplementedError()\n+        return self.args[1]\n",
      "tokens": 513,
      "success": true,
      "original_instance_id": "sympy__sympy-23950",
      "similarity": 0.0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-14141_mutated_83827337",
      "generated_patch": "--- a/sklearn/utils/_show_versions.py\n+++ b/sklearn/utils/_show_versions.py\n@@ -1,6 +1,7 @@\n \"\"\"Utility methods to display system info for debugging.\n \n Adapted from pandas.\n \"\"\"\n \n import platform\n import sys\n \n import numpy\n import scipy\n \n from .. import __version__\n \n try:\n     import Cython\n except ImportError:\n     Cython = None\n \n try:\n     import pandas\n except ImportError:\n     pandas = None\n \n+try:\n+    import joblib\n+except ImportError:\n+    joblib = None\n+\n \n def _get_sys_info():\n     \"\"\"System information.\n \n     Returns\n     -------\n     sys_info : dict\n         system and Python version information\n     \"\"\"\n     python = sys.version.replace(\"\\n\", \" \")\n \n     blob = [\n         (\"python\", python),\n         (\"executable\", sys.executable),\n         (\"machine\", platform.platform()),\n     ]\n \n     return dict(blob)\n \n \n def _get_deps_info():\n     \"\"\"Overview of the installed version of main dependencies.\n \n     Returns\n     -------\n     deps_info : dict\n         version information on relevant Python libraries\n     \"\"\"\n     deps = [\n         (\"numpy\", numpy.__version__),\n         (\"scipy\", scipy.__version__),\n         (\"Cython\", Cython.__version__ if Cython else None),\n         (\"pandas\", pandas.__version__ if pandas else None),\n+        (\"joblib\", joblib.__version__ if joblib else None),\n     ]\n \n     return dict(deps)",
      "expected_patch": "diff --git a/sklearn/utils/_show_versions.py b/sklearn/utils/_show_versions.py\n--- a/sklearn/utils/_show_versions.py\n+++ b/sklearn/utils/_show_versions.py\n@@ -48,6 +48,7 @@ def _get_deps_info():\n         \"Cython\",\n         \"pandas\",\n         \"matplotlib\",\n+        \"joblib\",\n     ]\n \n     def get_version(module):\n",
      "tokens": 455,
      "success": true,
      "original_instance_id": "scikit-learn__scikit-learn-14141",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-16082_mutated_06d830ac",
      "generated_patch": "--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -1,6 +1,7 @@\n import copy\n import datetime\n import functools\n+import operator\n import inspect\n import itertools\n import math\n@@ -42,6 +43,7 @@\n from django.db.models.fields import (\n     AutoField,\n     BigAutoField,\n+    DecimalField,\n     DurationField,\n     Field,\n     FloatField,\n@@ -706,6 +708,7 @@\n class Combinable:\n     # Arithmetic connectors\n     ADD = \"+\"\n     SUB = \"-\"\n     MUL = \"*\"\n     DIV = \"/\"\n     POW = \"^\"\n     MOD = \"%%\"\n@@ -713,6 +716,7 @@\n     # Bitwise connectors\n     BITAND = \"&\"\n     BITOR = \"|\"\n     BITLEFTSHIFT = \"<<\"\n     BITRIGHTSHIFT = \">>\"\n     BITXOR = \"#\"\n@@ -722,6 +726,7 @@\n     # Mapping of connectors to Python operators.\n     _connector_combinators = {\n         ADD: operator.add,\n         SUB: operator.sub,\n         MUL: operator.mul,\n         DIV: operator.truediv,\n         POW: operator.pow,\n+        MOD: operator.mod,\n         BITAND: operator.and_,\n         BITOR: operator.or_,\n         BITLEFTSHIFT: operator.lshift,\n         BITRIGHTSHIFT: operator.rshift,\n         BITXOR: operator.xor,\n     }\n@@ -741,6 +746,7 @@\n     def _combine(self, other, connector, reversed):\n         if not hasattr(other, \"resolve_expression\"):\n             # everything must be resolvable to an expression\n             other = Value(other)\n+        other = other if not reversed else other\n         return CombinedExpression(self, connector, other, reversed)\n \n@@ -758,6 +764,7 @@\n     def __mod__(self, other):\n         return self._combine(other, self.MOD, False)\n \n     def __rmod__(self, other):\n         return self._combine(other, self.MOD, True)\n@@ -820,6 +827,23 @@\n class CombinedExpression(SQLiteNumericMixin, Expression):\n     def __init__(self, lhs, connector, rhs, reversed=False, output_field=None):\n         super().__init__(output_field=output_field)\n         self.lhs = lhs\n         self.connector = connector\n         self.rhs = rhs\n         self.reversed = reversed\n+\n+    def _resolve_output_field(self):\n+        # MOD should behave like other numeric operators and promote to Decimal\n+        # when either side is Decimal.\n+        if self.connector == self.MOD:\n+            lhs_field = getattr(self.lhs, \"output_field\", None)\n+            rhs_field = getattr(self.rhs, \"output_field\", None)\n+            if isinstance(lhs_field, DecimalField) or isinstance(rhs_field, DecimalField):\n+                max_digits = max(\n+                    getattr(lhs_field, \"max_digits\", None) or 0,\n+                    getattr(rhs_field, \"max_digits\", None) or 0,\n+                ) or None\n+                decimal_places = max(\n+                    getattr(lhs_field, \"decimal_places\", None) or 0,\n+                    getattr(rhs_field, \"decimal_places\", None) or 0,\n+                ) or None\n+                return DecimalField(max_digits=max_digits, decimal_places=decimal_places)\n+        return super()._resolve_output_field()\n \n     def get_source_expressions(self):\n         return [self.lhs, self.rhs]\n \n     def set_source_expressions(self, exprs):\n         self.lhs, self.rhs = exprs",
      "expected_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -533,6 +533,7 @@ def __hash__(self):\n             Combinable.SUB,\n             Combinable.MUL,\n             Combinable.DIV,\n+            Combinable.MOD,\n         )\n     },\n     # Bitwise operators.\n",
      "tokens": 921,
      "success": true,
      "original_instance_id": "django__django-16082",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-13406_mutated_bd49886e",
      "generated_patch": "--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1,6 +1,7 @@\n import copy\n import operator\n import warnings\n+from types import SimpleNamespace\n \n from django.conf import settings\n from django.core import exceptions\n@@ -168,6 +169,7 @@ class QuerySet:\n         self._prefetch_related_lookups = ()\n         self._prefetch_done = False\n         self._known_related_objects = {}  # {rel_field: {pk: rel_obj}}\n+        self._iterable_class = ModelIterable\n \n     def __repr__(self):\n         data = list(self[:REPR_OUTPUT_SIZE + 1])\n@@ -1730,6 +1732,15 @@ class QuerySet:\n     def _clone(self):\n         \"\"\"\n         Return a copy of the current QuerySet. A lightweight alternative\n         to deepcopy().\n         \"\"\"\n         c = self.__class__(model=self.model, query=self.query.chain(), using=self._db, hints=self._hints)\n+        # Preserve the iterable class (e.g. ValuesIterable/ValuesListIterable)\n+        # when cloning. This is required for QuerySet.query assignment from a\n+        # pickled Query, where the QuerySet instance is recreated separately\n+        # from the original QuerySet that configured the iterable.\n+        c._iterable_class = self._iterable_class\n         c._sticky_filter = self._sticky_filter\n         c._for_write = self._for_write\n         c._prefetch_related_lookups = self._prefetch_related_lookups[:]\n@@ -1740,6 +1751,20 @@ class QuerySet:\n         c._known_related_objects = self._known_related_objects\n         return c\n \n+    @property\n+    def query(self):\n+        return self._query\n+\n+    @query.setter\n+    def query(self, value):\n+        self._query = value\n+        # If a Query is assigned (e.g. from a pickle), ensure the iterable\n+        # class matches the query's values()/values_list() state.\n+        if getattr(value, \"values_select\", ()) or getattr(value, \"selected\", None) is not None:\n+            self._iterable_class = ValuesIterable\n+        else:\n+            self._iterable_class = ModelIterable\n+\n     def _fetch_all(self):\n         if self._result_cache is None:\n             self._result_cache = list(self._iterable_class(self))\n@@ -1768,6 +1793,7 @@ class QuerySet:\n     def __deepcopy__(self, memo):\n         obj = self._clone()\n         obj.__dict__.update(copy.deepcopy(self.__dict__, memo))\n+        obj._iterable_class = self._iterable_class\n         return obj\n \n     def __getstate__(self):\n         # Force the cache to be fully populated.\n         self._fetch_all()\n         return {**self.__dict__, '_result_cache': self._result_cache}",
      "expected_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -210,6 +210,8 @@ def query(self):\n \n     @query.setter\n     def query(self, content):\n+        if content.values_select:\n+            self._iterable_class = ValuesIterable\n         self._query = content\n \n     def as_manager(cls):\n",
      "tokens": 1514,
      "success": true,
      "original_instance_id": "django__django-13406",
      "similarity": 0.5
    },
    {
      "instance_id": "django__django-16429_mutated_81ce616f",
      "generated_patch": "--- a/django/utils/timesince.py\n+++ b/django/utils/timesince.py\n@@ -90,11 +90,12 @@\n     if now is None:\n         now = datetime.datetime.now(tz=timezone.utc if is_aware(d) else None)\n     if is_aware(d) and is_naive(now):\n         now = timezone.make_aware(now, d.tzinfo)\n     elif is_naive(d) and is_aware(now):\n         d = timezone.make_aware(d, now.tzinfo)\n \n     # Ignore microseconds.\n     d = d.replace(microsecond=0)\n     now = now.replace(microsecond=0)\n \n     # Get years and months.\n-    pivot = datetime.datetime(d.year, d.month, 1)\n+    pivot = datetime.datetime(d.year, d.month, 1, tzinfo=d.tzinfo)\n     if d.day == 1:\n         pivot = pivot - datetime.timedelta(days=1)\n     else:\n         pivot = pivot + datetime.timedelta(days=31)\n     pivot = pivot.replace(day=1)",
      "expected_patch": "diff --git a/django/utils/timesince.py b/django/utils/timesince.py\n--- a/django/utils/timesince.py\n+++ b/django/utils/timesince.py\n@@ -97,6 +97,7 @@ def timesince(d, now=None, reversed=False, time_strings=None, depth=2):\n             d.hour,\n             d.minute,\n             d.second,\n+            tzinfo=d.tzinfo,\n         )\n     else:\n         pivot = d\n",
      "tokens": 583,
      "success": true,
      "original_instance_id": "django__django-16429",
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-13757_mutated_d3f33258",
      "generated_patch": "--- a/sympy/polys/polytools.py\n+++ b/sympy/polys/polytools.py\n@@ -1,6 +1,7 @@\n \"\"\"User-friendly public interface to polynomial functions. \"\"\"\n \n from __future__ import print_function, division\n+from sympy.core.expr import Expr\n \n from sympy.core import (S, Add, Mul, Pow, sympify, Basic, Tuple,\n     Integer, Rational, Symbol, Dummy, Lambda, Function, Derivative,\n@@ -4310,6 +4311,13 @@ class Poly(Basic):\n     def __rmul__(f, g):\n         return f.mul(g)\n \n+    def __rmatmul__(f, g):\n+        return f.mul(g)\n+\n+    def _sympystr(self, p):\n+        return Expr.__str__(self)\n+\n     def __pow__(f, n):\n         return f.pow(n)\n \n@@ -4466,6 +4474,14 @@ class Poly(Basic):\n     def mul(f, g):\n         \"\"\"Multiply ``f`` by ``g``. \"\"\"\n         g = sympify(g)\n+        # Ensure commutative multiplication with Expr on the left evaluates\n+        # (e.g. x*Poly(x) -> Poly(x**2), S(-2)*Poly(x) -> Poly(-2*x))\n+        if not isinstance(g, Poly):\n+            try:\n+                return g.__mul__(f)\n+            except Exception:\n+                pass\n         if isinstance(g, Poly):\n             return f._mul_poly(g)\n         else:\n             return f._mul_expr(g)",
      "expected_patch": "diff --git a/sympy/polys/polytools.py b/sympy/polys/polytools.py\n--- a/sympy/polys/polytools.py\n+++ b/sympy/polys/polytools.py\n@@ -106,6 +106,7 @@ class Poly(Expr):\n \n     is_commutative = True\n     is_Poly = True\n+    _op_priority = 10.001\n \n     def __new__(cls, rep, *gens, **args):\n         \"\"\"Create a new polynomial instance out of something useful. \"\"\"\n",
      "tokens": 585,
      "success": true,
      "original_instance_id": "sympy__sympy-13757",
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-23534_mutated_96ac3eb6",
      "generated_patch": "--- a/sympy/core/symbol.py\n+++ b/sympy/core/symbol.py\n@@ -1,6 +1,7 @@\n from __future__ import annotations\n \n from collections import defaultdict\n+from collections.abc import Sequence\n from itertools import product\n import re\n from typing import Any\n@@ -650,6 +651,13 @@ def symbols(names, **args):\n     \"\"\"\n     result = []\n \n+    # If names is a sequence of strings (e.g. ('x:2', 'y:2')) then treat it as\n+    # multiple symbol specifications rather than a single iterable of\n+    # characters. This is important for cls=Function where each spec should\n+    # create UndefinedFunction objects.\n+    if isinstance(names, Sequence) and not isinstance(names, (str, bytes)):\n+        if all(isinstance(s, (str, bytes)) for s in names):\n+            return tuple(symbols(s, **args) for s in names)\n+\n     if isinstance(names, str):\n         names = names.strip()\n         as_seq = names.endswith(',')\n@@ -657,7 +665,7 @@ def symbols(names, **args):\n             names = names[:-1]\n         if not names:\n             return ()\n-        names = names.split()\n+        names = names.split()\n         if len(names) == 1:\n             names = names[0]\n     else:\n@@ -665,7 +673,7 @@ def symbols(names, **args):\n         as_seq = True\n \n     if isinstance(names, str):\n         names = [names]\n-    elif not isinstance(names, (tuple, list)):\n+    elif not isinstance(names, (tuple, list)):\n         names = list(names)\n \n     cls = args.pop('cls', Symbol)",
      "expected_patch": "diff --git a/sympy/core/symbol.py b/sympy/core/symbol.py\n--- a/sympy/core/symbol.py\n+++ b/sympy/core/symbol.py\n@@ -791,7 +791,7 @@ def literal(s):\n         return tuple(result)\n     else:\n         for name in names:\n-            result.append(symbols(name, **args))\n+            result.append(symbols(name, cls=cls, **args))\n \n         return type(names)(result)\n \n",
      "tokens": 637,
      "success": true,
      "original_instance_id": "sympy__sympy-23534",
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-19040_mutated_60990cad",
      "generated_patch": "--- a/sympy/polys/polytools.py\n+++ b/sympy/polys/polytools.py\n@@ -1,6 +1,7 @@\n \"\"\"User-friendly public interface to polynomial functions. \"\"\"\n \n from __future__ import annotations\n+from sympy.core.symbol import Symbol\n \n from sympy.core import (Add, Basic, Expr, Mul, S, Symbol as _Symbol, sympify)\n from sympy.core.compatibility import iterable\n@@ -6644,6 +6645,12 @@ def factor(f, *gens, **args):\n     if not isinstance(f, Expr):\n         return f\n \n+    # If extension is requested, ensure that all free symbols are treated as\n+    # generators so that factors depending on \"other\" symbols are not dropped.\n+    if args.get('extension', False) and not gens:\n+        gens = tuple(sorted(f.free_symbols, key=lambda s: s.sort_key()))\n+\n     try:\n         return _generic_factor(f, gens, args, method='factor')\n     except PolynomialError:\n         return f",
      "expected_patch": "diff --git a/sympy/polys/factortools.py b/sympy/polys/factortools.py\n--- a/sympy/polys/factortools.py\n+++ b/sympy/polys/factortools.py\n@@ -1147,7 +1147,7 @@ def dmp_ext_factor(f, u, K):\n         return lc, []\n \n     f, F = dmp_sqf_part(f, u, K), f\n-    s, g, r = dmp_sqf_norm(f, u, K)\n+    s, g, r = dmp_sqf_norm(F, u, K)\n \n     factors = dmp_factor_list_include(r, u, K.dom)\n \n",
      "tokens": 700,
      "success": true,
      "original_instance_id": "sympy__sympy-19040",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-14534_mutated_e349e9f6",
      "generated_patch": "--- a/django/forms/boundfield.py\n+++ b/django/forms/boundfield.py\n@@ -353,8 +353,8 @@ class BoundWidget:\n \tdef __str__(self):\n \t\treturn self.tag(wrap_label=True)\n \n \tdef id_for_label(self):\n-\t\treturn 'id_%s_%s' % (self.payload['name'], self.payload['index'])\n+\t\treturn self.payload['attrs'].get('id') or 'id_%s_%s' % (self.payload['name'], self.payload['index'])\n \n \tdef choice_label(self):\n \t\treturn self.payload['label']",
      "expected_patch": "diff --git a/django/forms/boundfield.py b/django/forms/boundfield.py\n--- a/django/forms/boundfield.py\n+++ b/django/forms/boundfield.py\n@@ -277,7 +277,7 @@ def template_name(self):\n \n     @property\n     def id_for_label(self):\n-        return 'id_%s_%s' % (self.data['name'], self.data['index'])\n+        return self.data['attrs'].get('id')\n \n     @property\n     def choice_label(self):\n",
      "tokens": 590,
      "success": true,
      "original_instance_id": "django__django-14534",
      "similarity": 0.0
    },
    {
      "instance_id": "psf__requests-1921_mutated_10bf7d17",
      "generated_patch": "--- a/requests/models.py\n+++ b/requests/models.py\n@@ -480,7 +480,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         self.prepare_method(method)\n         self.prepare_url(url, params)\n         self.prepare_headers(headers)\n-        self.prepare_cookies(cookies)\n+        self.prepare_cookies(cookies)\n         self.prepare_body(data, files, json)\n         self.prepare_auth(auth, url)\n \n@@ -492,12 +492,20 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         self.headers = CaseInsensitiveDict()\n         if headers:\n             for header in headers.items():\n-                # Raise exception on invalid header value.\n-                check_header_validity(header)\n-                self.headers[to_native_string(header[0])] = to_native_string(header[1])\n+                # Skip headers explicitly set to None (used to remove default headers)\n+                if header[1] is None:\n+                    continue\n+                # Raise exception on invalid header value.\n+                check_header_validity(header)\n+                self.headers[to_native_string(header[0])] = to_native_string(header[1])\n \n     def prepare_body(self, data, files, json=None):\n         \"\"\"Prepares the given HTTP body data.\"\"\"\n         # Check if file, fo, generator, iterator.\n         # If so, pass through. If not, try to encode.\n         body = None",
      "expected_patch": "diff --git a/requests/sessions.py b/requests/sessions.py\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -59,6 +59,8 @@ def merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n         if v is None:\n             del merged_setting[k]\n \n+    merged_setting = dict((k, v) for (k, v) in merged_setting.items() if v is not None)\n+\n     return merged_setting\n \n \n",
      "tokens": 553,
      "success": true,
      "original_instance_id": "psf__requests-1921",
      "similarity": 0.0
    },
    {
      "instance_id": "pallets__flask-5014_mutated_0730a371",
      "generated_patch": "--- a/src/flask/blueprints.py\n+++ b/src/flask/blueprints.py\n@@ -1,6 +1,7 @@\n from __future__ import annotations\n \n from collections.abc import Callable\n+from collections.abc import Sized\n from functools import update_wrapper\n from typing import Any\n from typing import cast\n from typing import TYPE_CHECKING\n@@ -17,6 +18,7 @@\n from .scaffold import _endpoint_from_view_func\n from .scaffold import Scaffold\n from .typing import AfterRequestCallable\n from .typing import BeforeRequestCallable\n+from .typing import t\n from .typing import ErrorHandlerCallable\n from .typing import RouteCallable\n from .typing import TeardownCallable\n from .typing import TemplateContextProcessorCallable\n@@ -18,7 +20,6 @@\n from .scaffold import _endpoint_from_view_func\n from .scaffold import Scaffold\n from .typing import AfterRequestCallable\n from .typing import BeforeRequestCallable\n-from .typing import t\n from .typing import ErrorHandlerCallable\n from .typing import RouteCallable\n from .typing import TeardownCallable\n from .typing import TemplateContextProcessorCallable\n@@ -172,6 +173,9 @@\n     def __init__(\n         self, name: str, import_name: str, static_folder: str | None = None, **kwargs: t.Any\n     ) -> None:\n+        if not name:\n+            raise ValueError(\"Blueprint name must not be empty.\")\n         super().__init__(\n             name,\n             import_name,\n             static_folder=static_folder,\n             **kwargs,\n         )",
      "expected_patch": "diff --git a/src/flask/blueprints.py b/src/flask/blueprints.py\n--- a/src/flask/blueprints.py\n+++ b/src/flask/blueprints.py\n@@ -190,6 +190,9 @@ def __init__(\n             root_path=root_path,\n         )\n \n+        if not name:\n+            raise ValueError(\"'name' may not be empty.\")\n+\n         if \".\" in name:\n             raise ValueError(\"'name' may not contain a dot '.' character.\")\n \n",
      "tokens": 477,
      "success": true,
      "original_instance_id": "pallets__flask-5014",
      "similarity": 0.3333333333333333
    },
    {
      "instance_id": "django__django-14089_mutated_15518597",
      "generated_patch": "--- a/django/utils/datastructures.py\n+++ b/django/utils/datastructures.py\n@@ -1,6 +1,7 @@\n \"\"\"\n Various data structures used by Django.\n \"\"\"\n \n+from __future__ import annotations\n from collections import OrderedDict\n from collections.abc import MutableSet\n \n \n@@ -33,6 +34,9 @@ class OrderedSet(MutableSet):\n     def __iter__(self):\n         return iter(self.dict)\n \n+    def __reversed__(self):\n+        return reversed(self.dict)\n+\n     def __len__(self):\n         return len(self.dict)\n \n     def __contains__(self, item):\n         return item in self.dict",
      "expected_patch": "diff --git a/django/utils/datastructures.py b/django/utils/datastructures.py\n--- a/django/utils/datastructures.py\n+++ b/django/utils/datastructures.py\n@@ -25,6 +25,9 @@ def discard(self, item):\n     def __iter__(self):\n         return iter(self.dict)\n \n+    def __reversed__(self):\n+        return reversed(self.dict)\n+\n     def __contains__(self, item):\n         return item in self.dict\n \n",
      "tokens": 305,
      "success": true,
      "original_instance_id": "django__django-14089",
      "similarity": 1.0
    },
    {
      "instance_id": "sympy__sympy-15875_mutated_e692170e",
      "generated_patch": "--- a/sympy/core/add.py\n+++ b/sympy/core/add.py\n@@ -1,6 +1,7 @@\n from __future__ import annotations\n \n from collections import defaultdict\n+from sympy.core.logic import fuzzy_and\n from itertools import product\n from typing import TYPE_CHECKING\n \n@@ -1,6 +1,7 @@\n from sympy.core.basic import Basic\n from sympy.core.cache import cacheit\n from sympy.core.decorators import _sympifyit\n+from sympy.core.logic import fuzzy_and\n from sympy.core.expr import Expr\n from sympy.core.kind import Kind\n from sympy.core.numbers import Integer, Rational\n@@ -1,6 +1,7 @@\n from sympy.core.singleton import S\n from sympy.core.sorting import default_sort_key\n from sympy.core.sympify import _sympify\n+from sympy.core.logic import fuzzy_and\n from sympy.utilities.iterables import sift, uniq\n \n \n@@ -1,6 +1,7 @@\n class Add(Expr, AssocOp):\n     \"\"\"\n     Expression representing addition.\n@@ -1,6 +1,7 @@\n     \"\"\"\n \n     is_Add = True\n@@ -1,6 +1,7 @@\n     @property\n     def is_zero(self):\n         \"\"\"\n         Returns True if self is zero, False if self is not zero, and None if it\n         cannot be determined.\n         \"\"\"\n-        return self._eval_is_zero()\n+        return self._eval_is_zero()\n \n@@ -1,6 +1,7 @@\n     def _eval_is_zero(self):\n-        if self.is_number:\n-            return self.evalf().is_zero\n+        # Never return False unless we can prove nonzero.\n+        # For numeric Add, avoid evalf-based decisions which can be wrong\n+        # due to cancellation/rounding.\n+        if self.is_number:\n+            z = self.as_real_imag()\n+            return fuzzy_and([z[0].is_zero, z[1].is_zero])\n         if self.is_commutative:\n             # if any term is nonzero then self is nonzero\n             for a in self.args:\n                 if a.is_zero is False:\n                     return False\n             # if all terms are zero then self is zero\n             if all(a.is_zero for a in self.args):\n                 return True",
      "expected_patch": "diff --git a/sympy/core/add.py b/sympy/core/add.py\n--- a/sympy/core/add.py\n+++ b/sympy/core/add.py\n@@ -554,7 +554,7 @@ def _eval_is_zero(self):\n                 return\n         if z == len(self.args):\n             return True\n-        if len(nz) == len(self.args):\n+        if len(nz) == 0 or len(nz) == len(self.args):\n             return None\n         b = self.func(*nz)\n         if b.is_zero:\n",
      "tokens": 742,
      "success": true,
      "original_instance_id": "sympy__sympy-15875",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-16333_mutated_77186720",
      "generated_patch": "--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -260,11 +260,14 @@\n     def save(self, commit=True):\n         user = super().save(commit=False)\n         user.set_password(self.cleaned_data[\"password1\"])\n         if commit:\n             user.save()\n+            if hasattr(self, \"save_m2m\"):\n+                self.save_m2m()\n         return user\n \n \n class UserChangeForm(forms.ModelForm):\n     password = ReadOnlyPasswordHashField(\n         label=_(\"Password\"),",
      "expected_patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -141,6 +141,8 @@ def save(self, commit=True):\n         account.assign_password(self.cleaned_data[\"password1\"])\n         if commit:\n             account.save()\n+            if hasattr(self, \"save_m2m\"):\n+                self.save_m2m()\n         return account\n \n \n",
      "tokens": 343,
      "success": true,
      "original_instance_id": "django__django-16333",
      "similarity": 1.0
    },
    {
      "instance_id": "django__django-12419_mutated_4017189f",
      "generated_patch": "--- a/django/conf/global_settings.py\n+++ b/django/conf/global_settings.py\n@@ -656,7 +656,7 @@\n SECURE_CONTENT_TYPE_NOSNIFF = True\n SECURE_CROSS_ORIGIN_OPENER_POLICY = 'same-origin'\n SECURE_HSTS_INCLUDE_SUBDOMAINS = False\n SECURE_HSTS_PRELOAD = False\n SECURE_HSTS_SECONDS = 0\n-SECURE_REFERRER_POLICY = None\n+SECURE_REFERRER_POLICY = 'same-origin'\n SECURE_SSL_HOST = None\n SECURE_SSL_REDIRECT = False\n SECURE_SSL_REDIRECT_EXEMPT = []\n SECURE_SSL_REDIRECT_HOST = None",
      "expected_patch": "diff --git a/django/conf/global_settings.py b/django/conf/global_settings.py\n--- a/django/conf/global_settings.py\n+++ b/django/conf/global_settings.py\n@@ -637,6 +637,6 @@ def gettext_noop(s):\n SECURE_HSTS_PRELOAD = False\n SECURE_HSTS_SECONDS = 0\n SECURE_REDIRECT_EXEMPT = []\n-SECURE_REFERRER_POLICY = None\n+SECURE_REFERRER_POLICY = 'same-origin'\n SECURE_SSL_HOST = None\n SECURE_SSL_REDIRECT = False\n",
      "tokens": 389,
      "success": true,
      "original_instance_id": "django__django-12419",
      "similarity": 1.0
    },
    {
      "instance_id": "django__django-15098_mutated_d8d7896a",
      "generated_patch": "--- a/django/conf/urls/i18n.py\n+++ b/django/conf/urls/i18n.py\n@@ -1,6 +1,7 @@\n from functools import partial\n \n from django.conf import settings\n+from django.utils.translation import get_supported_language_variant\n from django.urls import LocalePrefixPattern, URLPattern, URLResolver, path\n from django.utils.translation import gettext_lazy as _\n \n@@ -8,6 +9,15 @@\n __all__ = [\"i18n_patterns\", \"is_language_prefix_patterns_used\"]\n \n \n+def _normalized_language_code(code):\n+\t\"\"\"\n+\tNormalize language codes for URL prefixes.\n+\tSupports BCP 47 tags with script/region (e.g. 'en-Latn-US').\n+\t\"\"\"\n+\treturn get_supported_language_variant(code, strict=False)\n+\n+\n def i18n_patterns(*urls, prefix_default_language=True):\n \t\"\"\"\n \tAdd the language code prefix to every URL pattern within this function.\n@@ -20,7 +30,12 @@\n \tif not settings.USE_I18N:\n \t\treturn list(urls)\n \tpattern = LocalePrefixPattern(prefix_default_language=prefix_default_language)\n-\treturn [URLResolver(pattern, list(urls))]\n+\tresolver = URLResolver(pattern, list(urls))\n+\t# Ensure language prefixes match normalized language codes, including\n+\t# those with script and region subtags.\n+\tresolver._urlconf_module = None\n+\treturn [resolver]\n \n@@ -35,7 +50,7 @@\n \t\"\"\"\n \tfor url_pattern in urlpatterns:\n \t\tif isinstance(url_pattern, URLResolver) and isinstance(\n \t\t\turl_pattern.pattern, LocalePrefixPattern\n \t\t):\n \t\t\treturn True\n \treturn False\n--- a/django/urls/resolvers.py\n+++ b/django/urls/resolvers.py\n@@ -1,6 +1,7 @@\n import functools\n import inspect\n import re\n+from django.utils.translation import get_supported_language_variant\n \n from asgiref.local import Local\n \n@@ -383,6 +384,15 @@\n class LocalePrefixPattern:\n \tconverters = {}\n \n+\t@staticmethod\n+\tdef _normalize_language(code):\n+\t\t\"\"\"\n+\t\tNormalize language codes for matching URL prefixes.\n+\t\tSupports BCP 47 tags with script/region (e.g. 'en-Latn-US').\n+\t\t\"\"\"\n+\t\treturn get_supported_language_variant(code, strict=False)\n+\n \tdef __init__(self, prefix_default_language=True):\n \t\tself.prefix_default_language = prefix_default_language\n \n@@ -390,7 +400,7 @@\n \tdef language_prefix(self):\n \t\tlanguage_code = get_language()\n \t\tif language_code == settings.LANGUAGE_CODE and not self.prefix_default_language:\n \t\t\treturn \"\"\n-\t\treturn \"%s/\" % language_code\n+\t\treturn \"%s/\" % self._normalize_language(language_code)\n \n \tdef match(self, path):\n \t\t# Check for the language prefix and strip it from the path.\n@@ -399,7 +409,7 @@\n \t\tif not path.startswith(\"/\"):\n \t\t\traise ValueError(\"path must start with a '/'\")\n \t\tpath = path[1:]\n-\t\tfor language_code, _ in settings.LANGUAGES:\n+\t\tfor language_code, _ in settings.LANGUAGES:\n \t\t\tprefix = \"%s/\" % language_code\n \t\t\tif path.startswith(prefix):\n \t\t\t\treturn path[len(prefix) :], (), {\"language\": language_code}\n@@ -407,6 +417,15 @@\n \t\tif self.prefix_default_language:\n \t\t\treturn path, (), {\"language\": settings.LANGUAGE_CODE}\n \t\treturn None\n+\n+\tdef __getstate__(self):\n+\t\tstate = self.__dict__.copy()\n+\t\treturn state\n+\n+\tdef __setstate__(self, state):\n+\t\tself.__dict__.update(state)\n+\n--- a/django/middleware/locale.py\n+++ b/django/middleware/locale.py\n@@ -1,6 +1,7 @@\n from django.conf import settings\n from django.http import HttpResponseRedirect\n from django.urls import is_valid_path\n+from django.utils.translation import get_supported_language_variant\n from django.utils.translation import (\n \tLANGUAGE_SESSION_KEY,\n \tcheck_for_language,\n@@ -28,6 +29,10 @@\n class LocaleMiddleware(MiddlewareMixin):\n \t\"\"\"\n \tParse a request and decide what translation object to install in the\n \tcurrent thread context. This allows pages to be dynamically translated to\n \tthe language the user desires (if the language is available, of course).\n \t\"\"\"\n \n+\tdef _normalize_language(self, code):\n+\t\treturn get_supported_language_variant(code, strict=False)\n+\n \tdef process_request(self, request):\n \t\turlconf = getattr(request, \"urlconf\", settings.ROOT_URLCONF)\n \t\ti18n_patterns_used, prefixed_default_language = is_language_prefix_patterns_used(\n@@ -44,7 +49,7 @@\n \t\t\tlanguage_from_path = get_language_from_path(request.path_info)\n \t\t\tif language_from_path is not None:\n-\t\t\t\tlanguage = language_from_path\n+\t\t\t\tlanguage = self._normalize_language(language_from_path)\n \t\t\telse:\n \t\t\t\tlanguage = translation.get_language_from_request(request, check_path=False)\n \t\telse:\n \t\t\tlanguage = translation.get_language_from_request(request, check_path=True)\n@@ -52,7 +57,7 @@\n \t\ttranslation.activate(language)\n \t\trequest.LANGUAGE_CODE = translation.get_language()\n \n \tdef process_response(self, request, response):\n \t\t\"\"\"\n \t\tAdd the Content-Language header to the response.\n \t\t\"\"\"\n \t\tlanguage = translation.get_language()\n \t\tresponse.headers.setdefault(\"Content-Language\", language)\n \t\treturn response",
      "expected_patch": "diff --git a/django/utils/translation/trans_real.py b/django/utils/translation/trans_real.py\n--- a/django/utils/translation/trans_real.py\n+++ b/django/utils/translation/trans_real.py\n@@ -43,7 +43,7 @@\n     re.IGNORECASE\n )\n \n-language_code_prefix_re = _lazy_re_compile(r'^/(\\w+([@-]\\w+)?)(/|$)')\n+language_code_prefix_re = _lazy_re_compile(r'^/(\\w+([@-]\\w+){0,2})(/|$)')\n \n \n @receiver(setting_changed)\n",
      "tokens": 2009,
      "success": true,
      "original_instance_id": "django__django-15098",
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-14711_mutated_c1634f4b",
      "generated_patch": "--- a/sympy/physics/vector/vector.py\n+++ b/sympy/physics/vector/vector.py\n@@ -56,12 +56,14 @@\n     def __add__(self, other):\n         \"\"\"The add operator for Vector. \"\"\"\n-        #if other == 0: return self\n+        if other == 0:\n+            return self\n         other = _check_vector(other)\n         return Vector(self.args + other.args)\n \n     def __radd__(self, other):\n         \"\"\"The right add operator for Vector. \"\"\"\n+        if other == 0:\n+            return self\n         return self.__add__(other)\n \n     def __sub__(self, other):\n         \"\"\"The subtraction operator for Vector. \"\"\"\n         other = _check_vector(other)",
      "expected_patch": "diff --git a/sympy/physics/vector/vector.py b/sympy/physics/vector/vector.py\n--- a/sympy/physics/vector/vector.py\n+++ b/sympy/physics/vector/vector.py\n@@ -57,6 +57,8 @@ def __hash__(self):\n \n     def __add__(self, other):\n         \"\"\"The add operator for Vector. \"\"\"\n+        if other == 0:\n+            return self\n         other = _check_vector(other)\n         return Vector(self.args + other.args)\n \n",
      "tokens": 529,
      "success": true,
      "original_instance_id": "sympy__sympy-14711",
      "similarity": 1.0
    },
    {
      "instance_id": "sympy__sympy-17139_mutated_e5aad570",
      "generated_patch": "--- a/sympy/simplify/fu.py\n+++ b/sympy/simplify/fu.py\n@@ -501,7 +501,7 @@\n     def _f(rv):\n         if not rv.is_Pow:\n             return rv\n-        if (rv.exp < 0) == True:\n+        if rv.exp.is_negative:\n             return rv.func(pow(rv.base, max(-rv.exp, 1)), -1)\n         return rv\n     return bottom_up(rv, _f)",
      "expected_patch": "diff --git a/sympy/simplify/fu.py b/sympy/simplify/fu.py\n--- a/sympy/simplify/fu.py\n+++ b/sympy/simplify/fu.py\n@@ -500,6 +500,8 @@ def _f(rv):\n         # change is not going to allow a simplification as far as I can tell.\n         if not (rv.is_Pow and rv.base.func == f):\n             return rv\n+        if not rv.exp.is_real:\n+            return rv\n \n         if (rv.exp < 0) == True:\n             return rv\n",
      "tokens": 841,
      "success": true,
      "original_instance_id": "sympy__sympy-17139",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-14915_mutated_82b75985",
      "generated_patch": "--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -1413,6 +1413,9 @@ class ModelChoiceIteratorValue:\n     def __str__(self):\n         return str(self.value)\n \n+    def __hash__(self):\n+        return hash(self.value)\n+\n \n class ModelChoiceIterator:\n     def __init__(self, field):",
      "expected_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -1166,6 +1166,9 @@ def __init__(self, content, instance):\n     def __str__(self):\n         return str(self.content)\n \n+    def __hash__(self):\n+        return hash(self.content)\n+\n     def __eq__(self, other):\n         if isinstance(other, ModelChoiceIteratorValue):\n             other = other.content\n",
      "tokens": 426,
      "success": true,
      "original_instance_id": "django__django-14915",
      "similarity": 1.0
    },
    {
      "instance_id": "pylint-dev__pylint-7080_mutated_bc41b968",
      "generated_patch": "--- a/pylint/lint/pylinter.py\n+++ b/pylint/lint/pylinter.py\n@@ -1,6 +1,7 @@\n \"\"\"Main pylint checker.\"\"\"\n \n from __future__ import annotations\n \n+import os\n import sys\n from collections.abc import Iterable, Iterator, Sequence\n from pathlib import Path\n@@ -38,6 +39,7 @@\n from pylint.utils import (\n     ASTWalker,\n     FileState,\n     LinterStats,\n     MessagesStore,\n     PyLintASTWalker,\n     fix_import_path,\n )\n@@ -1200,6 +1202,33 @@\n         self._check_files(\n             files_or_modules,\n             extra_packages_paths=extra_packages_paths,\n         )\n \n+    def _ignore_path(self, path: str) -> bool:\n+        \"\"\"Return True if path should be ignored based on ignore/ignore-paths.\"\"\"\n+        # Normalize to forward slashes so ignore-paths regexes work cross-platform.\n+        normalized = os.path.normpath(path).replace(os.sep, \"/\")\n+        # ignore-paths are regex patterns\n+        for pattern in self.config.ignore_paths:\n+            if pattern.search(normalized):\n+                return True\n+        # ignore are base names\n+        basename = os.path.basename(path)\n+        if basename in self.config.ignore:\n+            return True\n+        return False\n+\n     def _discover_files(self, files_or_modules: Sequence[str]) -> list[str]:\n         \"\"\"Discover python modules and packages from a list of paths.\"\"\"\n         result: list[str] = []\n         for something in files_or_modules:\n             path = Path(something)\n             if path.is_dir():\n                 if self.config.recursive:\n-                    result.extend(_discover_python_files(path))\n+                    for filename in _discover_python_files(path):\n+                        if not self._ignore_path(filename):\n+                            result.append(filename)\n                 else:\n                     result.append(str(path))\n             else:\n-                result.append(str(path))\n+                filename = str(path)\n+                if not self._ignore_path(filename):\n+                    result.append(filename)\n         return result",
      "expected_patch": "diff --git a/pylint/lint/expand_modules.py b/pylint/lint/expand_modules.py\n--- a/pylint/lint/expand_modules.py\n+++ b/pylint/lint/expand_modules.py\n@@ -52,6 +52,7 @@ def _is_ignored_file(\n     ignore_list_re: list[Pattern[str]],\n     ignore_list_paths_re: list[Pattern[str]],\n ) -> bool:\n+    element = os.path.normpath(element)\n     basename = os.path.basename(element)\n     return (\n         basename in ignore_list\n",
      "tokens": 7460,
      "success": true,
      "original_instance_id": "pylint-dev__pylint-7080",
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-20428_mutated_fe773298",
      "generated_patch": "--- a/sympy/polys/polytools.py\n+++ b/sympy/polys/polytools.py\n@@ -1,6 +1,7 @@\n \"\"\"Tools for polynomial manipulation. \"\"\"\n \n from __future__ import annotations\n+from sympy.polys.densebasic import dmp_strip\n from sympy.core import (Add, Basic, Expr, Mul, S, Symbol, Tuple, sympify,\n     expand_mul, expand_multinomial, expand_power_base, expand_power_exp,\n     expand_log, expand_func, expand_trig, expand_complex, expand, igcd,\n@@ -5650,7 +5651,12 @@ class Poly(Basic):\n         \"\"\"\n         f = self\n \n-        coeff, F = f.rep.clear_denoms()\n+        coeff, F = f.rep.clear_denoms()\n+        # clear_denoms can return an unstripped DMP (e.g. [0] instead of [])\n+        # which prints as zero but behaves inconsistently (is_zero False, etc).\n+        # Ensure canonical (stripped) representation.\n+        F = F.per(dmp_strip(F.rep, F.lev, F.dom))\n \n         if convert:\n             coeff = f.domain.to_sympy(coeff)\n         else:\n             coeff = f.domain.to_sympy(coeff)\n \n         return coeff, f.per(F)",
      "expected_patch": "diff --git a/sympy/polys/domains/expressiondomain.py b/sympy/polys/domains/expressiondomain.py\n--- a/sympy/polys/domains/expressiondomain.py\n+++ b/sympy/polys/domains/expressiondomain.py\n@@ -120,7 +120,7 @@ def __ne__(f, g):\n             return not f == g\n \n         def __bool__(f):\n-            return f.ex != 0\n+            return not f.ex.is_zero\n \n         def gcd(f, g):\n             from sympy.polys import gcd\n",
      "tokens": 1630,
      "success": true,
      "original_instance_id": "sympy__sympy-20428",
      "similarity": 0.0
    },
    {
      "instance_id": "matplotlib__matplotlib-23314_mutated_df3ec47c",
      "generated_patch": "--- a/lib/mpl_toolkits/mplot3d/axes3d.py\n+++ b/lib/mpl_toolkits/mplot3d/axes3d.py\n@@ -1,6 +1,7 @@\n import functools\n import itertools\n import math\n+import matplotlib.artist as martist\n \n import numpy as np\n \n@@ -412,6 +413,10 @@ class Axes3D(Axes):\n         self._axis3don = True\n         self._projection_init = projection\n \n+    def set_visible(self, b):\n+        super().set_visible(b)\n+        martist.setp(self._axis_map.values(), visible=b)\n \n     def set_axis_off(self):\n         \"\"\"\n@@ -454,6 +459,7 @@ class Axes3D(Axes):\n         \"\"\"\n         self._axis3don = False\n         super().set_axis_off()\n+        martist.setp(self._axis_map.values(), visible=False)\n \n     def set_axis_on(self):\n         \"\"\"\n@@ -463,6 +469,7 @@ class Axes3D(Axes):\n         \"\"\"\n         self._axis3don = True\n         super().set_axis_on()\n+        martist.setp(self._axis_map.values(), visible=True)\n \n     def get_axis_position(self):\n         \"\"\"Return the axis position.\"\"\"",
      "expected_patch": "diff --git a/lib/mpl_toolkits/mplot3d/axes3d.py b/lib/mpl_toolkits/mplot3d/axes3d.py\n--- a/lib/mpl_toolkits/mplot3d/axes3d.py\n+++ b/lib/mpl_toolkits/mplot3d/axes3d.py\n@@ -387,6 +387,8 @@ def apply_aspect(self, position=None):\n \n     @martist.allow_rasterization\n     def draw(self, renderer):\n+        if not self.get_visible():\n+            return\n         self._unstale_viewLim()\n \n         # draw the background patch\n",
      "tokens": 600,
      "success": true,
      "original_instance_id": "matplotlib__matplotlib-23314",
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-19637_mutated_ae70d2b3",
      "generated_patch": "--- a/sympy/core/sympify.py\n+++ b/sympy/core/sympify.py\n@@ -1,6 +1,7 @@\n from __future__ import annotations\n \n import ast\n+import re\n import builtins\n import inspect\n import keyword\n@@ -420,6 +421,7 @@ def kernS(s):\n     \"\"\"\n     # kernS is used by sympify and parse_expr\n     # It is a helper function to remove kernel strings from input\n+    kern = None\n     if not isinstance(s, str):\n         return s\n     if not s:\n@@ -427,7 +429,7 @@ def kernS(s):\n     # if there is no kernel string, return\n     # (kern is a string like 'Symbol' or 'Function' etc.)\n-    hit = kern in s\n+    hit = bool(kern) and (kern in s)\n     if not hit:\n         return s\n     # remove kernel strings",
      "expected_patch": "diff --git a/sympy/core/sympify.py b/sympy/core/sympify.py\n--- a/sympy/core/sympify.py\n+++ b/sympy/core/sympify.py\n@@ -513,7 +513,9 @@ def kernS(s):\n             while kern in s:\n                 kern += choice(string.ascii_letters + string.digits)\n             s = s.replace(' ', kern)\n-        hit = kern in s\n+            hit = kern in s\n+        else:\n+            hit = False\n \n     for i in range(2):\n         try:\n",
      "tokens": 364,
      "success": true,
      "original_instance_id": "sympy__sympy-19637",
      "similarity": 0.3333333333333333
    },
    {
      "instance_id": "pydata__xarray-3677_mutated_71fd180d",
      "generated_patch": "--- a/xarray/core/merge.py\n+++ b/xarray/core/merge.py\n@@ -820,6 +820,8 @@ def dataset_merge_method(\n     \"\"\"\n     if priority_arg is None:\n         priority_arg = 1\n+    if isinstance(other, DataArray):\n+        other = other.to_dataset()\n     return merge_core(\n         [dataset, other],\n         compat=compat,\n         join=join,\n         priority_arg=priority_arg,\n         fill_value=fill_value,\n     )",
      "expected_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -3604,6 +3604,7 @@ def merge(\n             If any variables conflict (see ``compat``).\n         \"\"\"\n         _check_inplace(inplace)\n+        other = other.to_dataset() if isinstance(other, xr.DataArray) else other\n         merge_result = dataset_merge_method(\n             self,\n             other,\n",
      "tokens": 605,
      "success": true,
      "original_instance_id": "pydata__xarray-3677",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-17029_mutated_1c81bd11",
      "generated_patch": "--- a/django/apps/registry.py\n+++ b/django/apps/registry.py\n@@ -370,6 +370,7 @@ class Apps:\n         This is mostly used in tests.\n         \"\"\"\n         self.get_models.cache_clear()\n+        self.get_swappable_settings_name.cache_clear()\n         # Call expire cache on each model's _meta.\n         # This will clear the cache for related objects and fields.\n         for app_config in self.app_configs.values():",
      "expected_patch": "diff --git a/django/apps/registry.py b/django/apps/registry.py\n--- a/django/apps/registry.py\n+++ b/django/apps/registry.py\n@@ -373,6 +373,7 @@ def clear_cache(self):\n \n         This is mostly used in tests.\n         \"\"\"\n+        self.get_swappable_settings_name.cache_clear()\n         # Call expire buffer on each schema. This will purge\n         # the relation tree and the fields buffer.\n         self.get_models.cache_clear()\n",
      "tokens": 424,
      "success": true,
      "original_instance_id": "django__django-17029",
      "similarity": 1.0
    },
    {
      "instance_id": "django__django-11880_mutated_b1a5c8fd",
      "generated_patch": "--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -1,6 +1,7 @@\n import copy\n import datetime\n import decimal\n+from copy import deepcopy\n \n from django.core import validators\n from django.core.exceptions import ValidationError\n@@ -197,9 +198,12 @@\n     def __deepcopy__(self, memo):\n         result = copy.copy(self)\n         memo[id(self)] = result\n+        # Ensure error_messages is not shared between field copies.\n+        # It may contain lazy objects or other mutable values.\n+        result.error_messages = deepcopy(self.error_messages, memo)\n         result.widget = copy.deepcopy(self.widget, memo)\n         result.validators = self.validators[:]\n         result._bound_field_class = self._bound_field_class\n         return result",
      "expected_patch": "diff --git a/django/forms/fields.py b/django/forms/fields.py\n--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -199,6 +199,7 @@ def __deepcopy__(self, memo):\n         result = copy.copy(self)\n         memo[id(self)] = result\n         result.widget = copy.deepcopy(self.widget, memo)\n+        result.error_messages = self.error_messages.copy()\n         result.validators = self.validators[:]\n         return result\n \n",
      "tokens": 523,
      "success": true,
      "original_instance_id": "django__django-11880",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-15863_mutated_6fe307f9",
      "generated_patch": "--- a/django/template/defaultfilters.py\n+++ b/django/template/defaultfilters.py\n@@ -1,12 +1,13 @@\n import datetime\n import decimal\n import json\n import re\n from collections import defaultdict\n from decimal import Decimal, InvalidOperation\n from functools import wraps\n from operator import itemgetter\n \n from django.conf import settings\n from django.template import Library\n from django.template.defaultfilters import stringfilter\n from django.utils import formats\n from django.utils.dateformat import format as date_format\n from django.utils.encoding import force_str\n from django.utils.html import conditional_escape, escape\n from django.utils.safestring import SafeData, mark_safe\n from django.utils.text import Truncator, normalize_newlines\n from django.utils.timezone import is_aware, make_naive, template_localtime\n from django.utils.translation import gettext, ngettext\n \n register = Library()\n \n@@ -206,7 +207,7 @@ def floatformat(text, arg=-1):\n     try:\n         input_val = force_str(text)\n     except (TypeError, ValueError):\n         return \"\"\n \n-    try:\n-        d = Decimal(input_val)\n+    try:\n+        d = text if isinstance(text, Decimal) else Decimal(input_val)\n     except (ValueError, InvalidOperation, TypeError):\n         return \"\"\n \n     try:\n         p = int(arg)\n     except (TypeError, ValueError):\n         return input_val",
      "expected_patch": "diff --git a/django/template/defaultfilters.py b/django/template/defaultfilters.py\n--- a/django/template/defaultfilters.py\n+++ b/django/template/defaultfilters.py\n@@ -149,7 +149,7 @@ def floatformat(text, arg=-1):\n             use_l10n = False\n             arg = arg[:-1] or -1\n     try:\n-        input_val = repr(text)\n+        input_val = str(text)\n         d = Decimal(input_val)\n     except InvalidOperation:\n         try:\n",
      "tokens": 577,
      "success": true,
      "original_instance_id": "django__django-15863",
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-16886_mutated_13e61225",
      "generated_patch": "--- a/sympy/crypto/crypto.py\n+++ b/sympy/crypto/crypto.py\n@@ -52,7 +52,7 @@\n     \".--.\": \"P\", \"--.-\": \"Q\", \".-.\": \"R\", \"...\": \"S\", \"-\": \"T\",\n     \"..-\": \"U\", \"...-\": \"V\", \".--\": \"W\", \"-..-\": \"X\", \"-.--\": \"Y\",\n     \"--..\": \"Z\", \"-----\": \"0\", \"----\": \"1\", \"..---\": \"2\", \"...--\": \"3\",\n     \"....-\": \"4\", \".....\": \"5\", \"-....\": \"6\", \"--...\": \"7\", \"---..\": \"8\",\n     \"----.\": \"9\", \".-.-.-\": \".\", \"--..--\": \",\", \"..--..\": \"?\", \".----.\": \"'\",\n     \"-.-.--\": \"!\", \"-..-.\": \"/\", \"-.--.\": \"(\", \"-.--.-\": \")\", \".-...\": \"&\",\n     \"---...\": \":\", \"-.-.-.\": \";\", \"-...-\": \"=\", \".-.-.\": \"+\", \"-....-\": \"-\",\n     \"..--.-\": \"_\", \".-..-.\": \"\\\"\", \"...-..-\": \"$\", \".--.-.\": \"@\"\n }\n+MORSE_CODE_DICT[\".----\"] = MORSE_CODE_DICT.pop(\"----\")",
      "expected_patch": "diff --git a/sympy/crypto/crypto.py b/sympy/crypto/crypto.py\n--- a/sympy/crypto/crypto.py\n+++ b/sympy/crypto/crypto.py\n@@ -1520,7 +1520,7 @@ def decipher_kid_rsa(msg, identifier):\n     \"..-\": \"U\", \"...-\": \"V\",\n     \".--\": \"W\", \"-..-\": \"X\",\n     \"-.--\": \"Y\", \"--..\": \"Z\",\n-    \"-----\": \"0\", \"----\": \"1\",\n+    \"-----\": \"0\", \".----\": \"1\",\n     \"..---\": \"2\", \"...--\": \"3\",\n     \"....-\": \"4\", \".....\": \"5\",\n     \"-....\": \"6\", \"--...\": \"7\",\n",
      "tokens": 444,
      "success": true,
      "original_instance_id": "sympy__sympy-16886",
      "similarity": 0.0
    },
    {
      "instance_id": "pytest-dev__pytest-6202_mutated_de06a9ea",
      "generated_patch": "--- a/src/_pytest/python.py\n+++ b/src/_pytest/python.py\n@@ -271,7 +271,7 @@\n     def getmodpath(self, stopatmodule: bool = True) -> str:\n         \"\"\"Return python path relative to the module.\"\"\"\n         s = self.nodeid\n-        return s.replace(\".[\", \"[\")\n+        return s",
      "expected_patch": "diff --git a/src/_pytest/python.py b/src/_pytest/python.py\n--- a/src/_pytest/python.py\n+++ b/src/_pytest/python.py\n@@ -285,8 +285,7 @@ def getmodpath(self, stopatmodule=True, includemodule=False):\n                     break\n             parts.append(name)\n         parts.reverse()\n-        s = \".\".join(parts)\n-        return s.replace(\".[\", \"[\")\n+        return \".\".join(parts)\n \n     def reportinfo(self):\n         # XXX caching?\n",
      "tokens": 826,
      "success": true,
      "original_instance_id": "pytest-dev__pytest-6202",
      "similarity": 0.3333333333333333
    },
    {
      "instance_id": "pytest-dev__pytest-5262_mutated_eb176280",
      "generated_patch": "--- a/src/_pytest/capture.py\n+++ b/src/_pytest/capture.py\n@@ -404,6 +404,12 @@ class EncodedFile(object):\n     def __init__(self, buffer, encoding):\n         self.buffer = buffer\n         self.encoding = encoding\n+        # Expose a text-mode \"mode\" attribute even if the underlying buffer is\n+        # opened in binary mode. Some libraries (e.g. youtube-dl) inspect\n+        # `out.mode` to decide whether to write bytes or str.\n+        # EncodedFile.write() only accepts text on Python 3.\n+        self.mode = getattr(buffer, \"mode\", \"\").replace(\"b\", \"\")\n \n     def write(self, obj):\n         if isinstance(obj, six.text_type):\n             obj = obj.encode(self.encoding, \"replace\")",
      "expected_patch": "diff --git a/src/_pytest/capture.py b/src/_pytest/capture.py\n--- a/src/_pytest/capture.py\n+++ b/src/_pytest/capture.py\n@@ -447,6 +447,10 @@ def name(self):\n         \"\"\"Ensure that file.name is a string.\"\"\"\n         return repr(self.buffer)\n \n+    @property\n+    def mode(self):\n+        return self.buffer.mode.replace(\"b\", \"\")\n+\n     def __getattr__(self, name):\n         return getattr(object.__getattribute__(self, \"buffer\"), name)\n \n",
      "tokens": 1453,
      "success": true,
      "original_instance_id": "pytest-dev__pytest-5262",
      "similarity": 0.0
    },
    {
      "instance_id": "pytest-dev__pytest-7982_mutated_390d5806",
      "generated_patch": "--- a/src/_pytest/pathlib.py\n+++ b/src/_pytest/pathlib.py\n@@ -1,6 +1,7 @@\n from __future__ import annotations\n \n import fnmatch\n+import os\n import os.path\n from pathlib import Path\n from typing import Callable\n@@ -120,7 +121,7 @@ def visit(\n     entries = []\n     try:\n         with os.scandir(path) as scandir_it:\n-            entries = [entry for entry in scandir_it if entry.is_dir(follow_symlinks=False)]\n+            entries = [entry for entry in scandir_it if entry.is_dir()]\n     except OSError:\n         return\n \n@@ -128,7 +129,7 @@ def visit(\n     for entry in entries:\n         entry_path = Path(entry.path)\n         if rec is not None:\n-            if not rec(entry_path):\n+            if not rec(entry_path):\n                 continue\n         yield entry_path\n         yield from visit(entry_path, rec=rec)",
      "expected_patch": "diff --git a/src/_pytest/pathlib.py b/src/_pytest/pathlib.py\n--- a/src/_pytest/pathlib.py\n+++ b/src/_pytest/pathlib.py\n@@ -558,7 +558,7 @@ def visit(\n     entries = sorted(os.scandir(path), key=lambda entry: entry.name)\n     yield from entries\n     for entry in entries:\n-        if entry.is_dir(follow_symlinks=False) and recurse(entry):\n+        if entry.is_dir() and recurse(entry):\n             yield from visit(entry.path, recurse)\n \n \n",
      "tokens": 427,
      "success": true,
      "original_instance_id": "pytest-dev__pytest-7982",
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-15349_mutated_bad3726f",
      "generated_patch": "--- a/sympy/algebras/quaternion.py\n+++ b/sympy/algebras/quaternion.py\n@@ -486,7 +486,7 @@ class Quaternion(Expr):\n         m21 = 2*(q2*q3 + q0*q1)\n         m22 = q0**2 - q1**2 + q2**2 - q3**2\n-        m23 = 2*(q2*q1 + q0*q3)\n+        m23 = 2*(q2*q1 - q0*q3)\n         m31 = 2*(q1*q3 - q0*q2)\n         m32 = 2*(q2*q3 - q0*q1)\n         m33 = q0**2 - q1**2 - q2**2 + q3**2",
      "expected_patch": "diff --git a/sympy/algebras/quaternion.py b/sympy/algebras/quaternion.py\n--- a/sympy/algebras/quaternion.py\n+++ b/sympy/algebras/quaternion.py\n@@ -529,7 +529,7 @@ def to_rotation_matrix(self, v=None):\n \n         m10 = 2*s*(q.b*q.c + q.d*q.a)\n         m11 = 1 - 2*s*(q.b**2 + q.d**2)\n-        m12 = 2*s*(q.c*q.d + q.b*q.a)\n+        m12 = 2*s*(q.c*q.d - q.b*q.a)\n \n         m20 = 2*s*(q.b*q.d - q.c*q.a)\n         m21 = 2*s*(q.c*q.d + q.b*q.a)\n",
      "tokens": 494,
      "success": true,
      "original_instance_id": "sympy__sympy-15349",
      "similarity": 0.0
    },
    {
      "instance_id": "pytest-dev__pytest-7521_mutated_237e2383",
      "generated_patch": "--- a/src/_pytest/capture.py\n+++ b/src/_pytest/capture.py\n@@ -1,6 +1,7 @@\n # mypy: allow-untyped-defs\n from __future__ import annotations\n \n+import io\n import os\n import sys\n from contextlib import contextmanager\n@@ -470,12 +471,18 @@\n class CaptureIO(io.TextIOWrapper):\n     def __init__(self, buffer, encoding=None):\n-        super().__init__(buffer, encoding=encoding)\n+        # Ensure we don't translate newlines (\\r -> \\n) when capturing.\n+        # This preserves exact output written by the code under test.\n+        super().__init__(buffer, encoding=encoding, newline=\"\")\n \n     def getvalue(self):\n         return self.buffer.getvalue().decode(self.encoding, errors=self.errors)\n \n     def write(self, s):\n         super().write(s)\n         self.flush()\n@@ -485,7 +492,7 @@\n class TeeCaptureIO(CaptureIO):\n     def __init__(self, buffer, tee, encoding=None):\n-        super().__init__(buffer, encoding=encoding)\n+        super().__init__(buffer, encoding=encoding)\n         self._tee = tee\n \n     def write(self, s):\n         super().write(s)\n         self._tee.write(s)\n         self._tee.flush()",
      "expected_patch": "diff --git a/src/_pytest/capture.py b/src/_pytest/capture.py\n--- a/src/_pytest/capture.py\n+++ b/src/_pytest/capture.py\n@@ -388,6 +388,7 @@ def __init__(self, targetfd: int) -> None:\n                 TemporaryFile(buffering=0),  # type: ignore[arg-type]\n                 encoding=\"utf-8\",\n                 errors=\"replace\",\n+                newline=\"\",\n                 write_through=True,\n             )\n             if targetfd in patchsysdict:\n",
      "tokens": 1451,
      "success": true,
      "original_instance_id": "pytest-dev__pytest-7521",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-16485_mutated_10fe7573",
      "generated_patch": "--- a/django/template/defaultfilters.py\n+++ b/django/template/defaultfilters.py\n@@ -1,6 +1,7 @@\n import datetime\n import re\n from decimal import Decimal, InvalidOperation, ROUND_HALF_UP\n+from decimal import localcontext\n \n from django.utils import formats\n from django.utils.dateparse import parse_date, parse_datetime, parse_time\n@@ -188,7 +189,7 @@ def floatformat(text, arg=-1):\n     try:\n         input_val = Decimal(str(text))\n     except InvalidOperation:\n         return \"\"\n-    if not input_val.is_finite():\n+    if not input_val.is_finite():\n         return str(text)\n \n     try:\n@@ -199,7 +200,7 @@ def floatformat(text, arg=-1):\n     except (ValueError, TypeError):\n         return \"\"\n \n-    if input_val == 0:\n+    if input_val == 0:\n         return \"0\" if p <= 0 else \"0.\" + \"0\" * p\n \n     # If the argument is negative, we want to keep trailing zeros only if\n@@ -207,10 +208,14 @@ def floatformat(text, arg=-1):\n     # If the argument is positive, we always want to keep trailing zeros.\n     m = abs(p)\n \n-    # Set precision to the number of digits we need.\n-    prec = input_val.adjusted() + m + 1\n-    input_val = input_val.quantize(Decimal(1).scaleb(-m), rounding=ROUND_HALF_UP, context=Decimal(1).as_tuple())\n+    # Set precision to the number of digits we need.\n+    prec = input_val.adjusted() + m + 1\n+    if prec < 1:\n+        prec = 1\n+    with localcontext() as ctx:\n+        ctx.prec = prec\n+        input_val = input_val.quantize(Decimal(1).scaleb(-m), rounding=ROUND_HALF_UP)\n \n     # Convert to string and strip off any trailing zeros if needed.\n     s = format(input_val, \"f\")",
      "expected_patch": "diff --git a/django/template/defaultfilters.py b/django/template/defaultfilters.py\n--- a/django/template/defaultfilters.py\n+++ b/django/template/defaultfilters.py\n@@ -168,7 +168,7 @@ def floatformat(text, arg=-1):\n     except (ValueError, OverflowError, InvalidOperation):\n         return input_val\n \n-    if not m and p < 0:\n+    if not m and p <= 0:\n         return mark_safe(\n             formats.number_format(\n                 \"%d\" % (int(d)),\n",
      "tokens": 603,
      "success": true,
      "original_instance_id": "django__django-16485",
      "similarity": 0.0
    },
    {
      "instance_id": "pydata__xarray-6721_mutated_e319ebb1",
      "generated_patch": "--- a/xarray/core/common.py\n+++ b/xarray/core/common.py\n@@ -1806,16 +1806,22 @@ def get_chunksizes(variables):\n     \"\"\"\n     chunks: dict[Any, tuple[int, ...]] = {}\n     for v in variables:\n-        if hasattr(v.data, \"chunks\"):\n+        # Avoid triggering materialization of non-dask backend arrays (e.g. zarr)\n+        # by accessing Variable.data, which may coerce to numpy.\n+        data = v._data\n+        if hasattr(data, \"chunks\"):\n             for dim, c in v.chunksizes.items():\n                 if dim in chunks and c != chunks[dim]:\n                     raise ValueError(\n                         \"Object has inconsistent chunks along dimension %s. \"\n                         \"This can be fixed by calling unify_chunks().\" % dim\n                     )\n                 chunks[dim] = c\n     return chunks",
      "expected_patch": "diff --git a/xarray/core/common.py b/xarray/core/common.py\n--- a/xarray/core/common.py\n+++ b/xarray/core/common.py\n@@ -2023,7 +2023,7 @@ def fetch_chunksizes(\n \n     chunks: dict[Any, tuple[int, ...]] = {}\n     for v in variables:\n-        if hasattr(v.payload, \"chunks\"):\n+        if hasattr(v._data, \"chunks\"):\n             for dim, c in v.chunksizes.items():\n                 if dim in chunks and c != chunks[dim]:\n                     raise ValueError(\n",
      "tokens": 2986,
      "success": true,
      "original_instance_id": "pydata__xarray-6721",
      "similarity": 0.5
    },
    {
      "instance_id": "psf__requests-6028_mutated_d506a40b",
      "generated_patch": "--- a/requests/adapters.py\n+++ b/requests/adapters.py\n@@ -1,6 +1,7 @@\n import os.path\n import socket  # noqa: F401\n import typing\n+import urllib.parse\n \n from urllib3.exceptions import ClosedPoolError\n from urllib3.exceptions import ConnectTimeoutError\n@@ -1,6 +1,7 @@\n from urllib3.exceptions import InvalidHeader\n from urllib3.exceptions import LocationParseError\n from urllib3.exceptions import MaxRetryError\n+from urllib3.util import make_headers\n from urllib3.exceptions import NewConnectionError\n from urllib3.exceptions import ProtocolError\n from urllib3.exceptions import ProxyError as _ProxyError\n@@ -1,6 +1,7 @@\n from urllib3.exceptions import ReadTimeoutError\n from urllib3.exceptions import ResponseError\n from urllib3.exceptions import SSLError as _SSLError\n+from urllib3.util.url import parse_url\n from urllib3.exceptions import TimeoutError\n from urllib3.exceptions import UnrewindableBodyError\n from urllib3.exceptions import _ProxyError as __ProxyError\n@@ -1,6 +1,7 @@\n from urllib3.poolmanager import PoolManager, proxy_from_url\n from urllib3.response import HTTPResponse\n from urllib3.util import Retry\n+from urllib3.util.url import Url\n \n from .auth import _basic_auth_str\n from .compat import basestring, urlparse\n@@ -1,6 +1,7 @@\n from .exceptions import (\n     ConnectionError,\n     ConnectTimeout,\n+    ProxyError,\n     InvalidHeader,\n     InvalidProxyURL,\n     InvalidSchema,\n@@ -1,6 +1,7 @@\n     ReadTimeout,\n     RetryError,\n     SSLError,\n+    TooManyRedirects,\n )\n from .models import Response\n from .packages.urllib3._collections import HTTPHeaderDict\n@@ -1,6 +1,7 @@\n from .structures import CaseInsensitiveDict\n from .utils import (\n     DEFAULT_CA_BUNDLE_PATH,\n+    get_auth_from_url,\n     extract_zipped_paths,\n     get_encoding_from_headers,\n     prepend_scheme_if_needed,\n@@ -1,6 +1,7 @@\n     select_proxy,\n     should_bypass_proxies,\n     urldefragauth,\n+    urlunparse,\n )\n \n DEFAULT_POOLBLOCK = False\n@@ -1,6 +1,7 @@\n DEFAULT_POOLSIZE = 10\n DEFAULT_RETRIES = 0\n DEFAULT_POOL_TIMEOUT = None\n+_PROXY_AUTH_HEADER = \"Proxy-Authorization\"\n \n try:\n     import ssl\n@@ -1,6 +1,7 @@\n class HTTPAdapter(BaseAdapter):\n     \"\"\"The built-in HTTP Adapter for urllib3.\"\"\"\n \n+    # NOTE: Proxy auth handling is implemented here to work around CPython 3.8.12\n     def __init__(\n         self,\n         pool_connections=DEFAULT_POOLSIZE,\n@@ -1,6 +1,55 @@\n         self._pool_connections = pool_connections\n         self._pool_maxsize = pool_maxsize\n         self._pool_block = pool_block\n+\n+    def _set_proxy_auth(self, proxy, headers):\n+        \"\"\"Ensure Proxy-Authorization is set for HTTPS proxy CONNECT.\n+\n+        urllib3 only sends proxy auth for CONNECT when proxy_headers are set on\n+        the ProxyManager. In some environments (notably CPython 3.8.12) relying\n+        on implicit behavior can fail, resulting in 407 responses.\n+        \"\"\"\n+        if not proxy:\n+            return None\n+        try:\n+            proxy_url = parse_url(proxy)\n+        except Exception:\n+            return None\n+        if not proxy_url:\n+            return None\n+        if proxy_url.auth is None:\n+            return None\n+        # Respect explicit header if user already set it.\n+        if headers is not None:\n+            for k in headers:\n+                if k.lower() == _PROXY_AUTH_HEADER.lower():\n+                    return None\n+        username, password = get_auth_from_url(proxy)\n+        if username is None:\n+            return None\n+        proxy_headers = make_headers(proxy_basic_auth=f\"{username}:{password}\")\n+        return proxy_headers\n \n     def init_poolmanager(\n         self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs\n@@ -1,6 +1,7 @@\n         self.poolmanager = PoolManager(\n             num_pools=connections, maxsize=maxsize, block=block, **pool_kwargs\n         )\n+        self.proxy_manager = {}\n \n     def proxy_manager_for(self, proxy, **proxy_kwargs):\n         \"\"\"Return urllib3 ProxyManager for the given proxy.\n@@ -1,14 +1,33 @@\n         if proxy in self.proxy_manager:\n             manager = self.proxy_manager[proxy]\n         elif proxy is not None:\n+            # Ensure proxy auth is passed via proxy_headers so CONNECT includes it.\n+            headers = proxy_kwargs.get(\"proxy_headers\")\n+            proxy_headers = self._set_proxy_auth(proxy, headers)\n+            if proxy_headers:\n+                if headers:\n+                    merged = dict(headers)\n+                    merged.update(proxy_headers)\n+                    proxy_headers = merged\n+                proxy_kwargs[\"proxy_headers\"] = proxy_headers\n             manager = proxy_from_url(\n                 proxy,\n                 proxy_kwargs=proxy_kwargs,\n                 num_pools=self._pool_connections,\n                 maxsize=self._pool_maxsize,\n                 block=self._pool_block,\n                 **self.poolmanager.connection_pool_kw,\n             )\n             self.proxy_manager[proxy] = manager\n         else:\n             manager = self.poolmanager\n         return manager",
      "expected_patch": "diff --git a/requests/utils.py b/requests/utils.py\n--- a/requests/utils.py\n+++ b/requests/utils.py\n@@ -974,6 +974,10 @@ def prepend_scheme_if_needed(url, new_scheme):\n     if not netloc:\n         netloc, path = path, netloc\n \n+    if auth:\n+        # parse_url doesn't provide the netloc with auth\n+        # so we'll add it ourselves.\n+        netloc = '@'.join([auth, netloc])\n     if scheme is None:\n         scheme = new_scheme\n     if path is None:\n",
      "tokens": 1643,
      "success": true,
      "original_instance_id": "psf__requests-6028",
      "similarity": 0.0
    },
    {
      "instance_id": "pytest-dev__pytest-7432_mutated_78b81c93",
      "generated_patch": "--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -1,6 +1,7 @@\n from __future__ import annotations\n \n from dataclasses import dataclass\n+import os\n from typing import Any\n from typing import cast\n from typing import Final\n@@ -235,6 +236,16 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]) -> None:\n     if not rep.skipped:\n         return\n \n+    # When --runxfail is used, we may have created a new skip exception during\n+    # report generation (e.g. for xfail(strict) failures). In that case, the\n+    # location points to this file. Don't override the original skip location\n+    # coming from @pytest.mark.skip/skipif.\n+    try:\n+        if os.path.normcase(rep.longrepr[0]) != os.path.normcase(__file__):\n+            return\n+    except Exception:\n+        pass\n+\n     # If we are skipping because of a skip marker, we want to report the location\n     # of the test item, not the location of the skip marker.\n     if rep.longrepr is not None and isinstance(rep.longrepr, tuple):",
      "expected_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -291,7 +291,8 @@ def pytest_runtest_makereport(element: Item, call: CallInfo[None]):\n             else:\n                 rep.outcome = \"passed\"\n                 rep.wasxfail = xfailed.reason\n-    elif (\n+\n+    if (\n         element._store.get(skipped_by_mark_key, True)\n         and rep.skipped\n         and type(rep.longrepr) is tuple\n",
      "tokens": 567,
      "success": true,
      "original_instance_id": "pytest-dev__pytest-7432",
      "similarity": 0.3333333333333333
    },
    {
      "instance_id": "django__django-15741_mutated_406b4d5a",
      "generated_patch": "--- a/django/utils/formats.py\n+++ b/django/utils/formats.py\n@@ -1,6 +1,7 @@\n from __future__ import unicode_literals\n \n import datetime\n+from django.utils.encoding import force_str\n \n from django.conf import settings\n from django.utils import dateformat, numberformat\n@@ -78,6 +79,7 @@ def get_format(format_type, lang=None, use_l10n=None):\n     \"\"\"\n     if use_l10n is None:\n         use_l10n = True\n+    format_type = force_str(format_type)\n     if use_l10n and lang is None:\n         lang = get_language()\n     cache_key = (format_type, lang)",
      "expected_patch": "diff --git a/django/utils/formats.py b/django/utils/formats.py\n--- a/django/utils/formats.py\n+++ b/django/utils/formats.py\n@@ -113,6 +113,7 @@ def fetch_format(format_type, lang=None, use_l10n=None):\n             use_l10n = settings.USE_L10N\n     if use_l10n and lang is None:\n         lang = fetch_language()\n+    format_type = str(format_type)  # format_type may be lazy.\n     cache_key = (format_type, lang)\n     try:\n         return _format_cache[cache_key]\n",
      "tokens": 324,
      "success": true,
      "original_instance_id": "django__django-15741",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-12209_mutated_5f22de4a",
      "generated_patch": "--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -1040,7 +1040,7 @@ class Model(metaclass=ModelBase):\n         if not meta.auto_created:\n             pre_save.send(\n                 sender=origin,\n                 instance=self,\n                 raw=raw,\n                 using=using,\n                 update_fields=update_fields,\n             )\n \n         # A transaction isn't needed if one query is issued.\n         if meta.parents:\n             context_manager = transaction.atomic(using=using, savepoint=False)\n         else:\n             context_manager = transaction.mark_for_rollback_on_error(using=using)\n         with context_manager:\n             parent_inserted = False\n             if not raw:\n                 force_insert = self._validate_force_insert(force_insert)\n                 parent_inserted = self._save_parents(\n                     cls, using, update_fields, force_insert\n                 )\n-            updated = self._save_table(\n+            updated = self._save_table(\n                 raw,\n                 cls,\n                 force_insert or parent_inserted,\n                 force_update,\n                 using,\n                 update_fields,\n             )\n         # Store the database on which the object was saved\n         self._state.db = using\n         # Once saved, this is no longer a to-be-added instance.\n         self._state.adding = False\n \n         # Signal that the save is complete\n         if not meta.auto_created:\n             post_save.send(\n                 sender=origin,\n                 instance=self,\n                 created=(not updated),\n                 update_fields=update_fields,\n                 raw=raw,\n                 using=using,\n             )\n \n     def _save_table(\n         self,\n         raw,\n         cls,\n         force_insert,\n         force_update,\n         using,\n         update_fields,\n     ):\n         \"\"\"\n         Do the heavy-lifting involved in saving. Update or insert the data\n         for a single table.\n         \"\"\"\n         meta = cls._meta\n         non_pks_non_generated = [\n             f\n             for f in meta.local_concrete_fields\n             if f is not meta.pk and not f.generated\n         ]\n         if update_fields:\n             non_pks_non_generated = [\n                 f\n                 for f in non_pks_non_generated\n                 if f.name in update_fields or f.attname in update_fields\n             ]\n \n         pk_val = self._get_pk_val(meta)\n         if pk_val is None:\n             pk_val = meta.pk.get_pk_value_on_save(self)\n             setattr(self, meta.pk.attname, pk_val)\n-        pk_set = pk_val is not None\n+        pk_set = pk_val is not None\n \n         if not pk_set and (force_update or update_fields):\n             raise ValueError(\"Cannot force an update in save() with no primary key.\")\n-        updated = False\n+        # If the primary key is set, prefer an UPDATE over an INSERT unless\n+        # force_insert is explicitly requested. This preserves historical\n+        # behavior for explicit primary keys, including when the PK field has\n+        # a default.\n+        if pk_set and self._state.adding and not force_insert:\n+            force_update = True\n+        updated = False\n         # If possible, try an UPDATE. If that doesn't update anything, do an INSERT.\n         if pk_set and not force_insert:\n             base_qs = cls._base_manager.using(using)\n             values = [\n                 (\n                     f,\n                     None,\n                     (getattr(self, f.attname) if raw else f.pre_save(self, False)),\n                 )\n                 for f in non_pks_non_generated\n             ]\n             forced_update = update_fields or force_update\n             updated = self._do_update(\n                 base_qs, using, pk_val, values, update_fields, forced_update\n             )\n             if force_update and not updated:\n                 raise DatabaseError(\"Forced update did not affect any rows.\")\n             if update_fields and not updated:\n                 raise DatabaseError(\"Save with update_fields did not affect any rows.\")\n         if not updated:\n             if meta.order_with_respect_to:\n                 # If this is a model with an order_with_respect_to\n                 # autopopulate the _order field\n                 field = meta.order_with_respect_to\n                 filter_args = field.get_filter_kwargs_for_object(self)\n                 order_value = (\n                     cls._base_manager.using(using)\n                     .filter(**filter_args)\n                     .aggregate(\n                         _order__max=Coalesce(\n                             Max(\"_order\"), Value(-1), output_field=IntegerField()\n                         )\n                     )[\"_order__max\"]\n                     + 1\n                 )\n                 setattr(self, \"_order\", order_value)\n \n             fields = [\n                 f\n                 for f in meta.local_concrete_fields\n                 if not f.generated and (pk_set or f is not meta.auto_field)\n             ]\n             returning_fields = meta.db_returning_fields\n             results = self._do_insert(\n                 cls._base_manager, using, fields, returning_fields, raw\n             )\n             if results:\n                 for value, field in zip(results[0], returning_fields):\n                     setattr(self, field.attname, value)\n         return updated",
      "expected_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -849,6 +849,7 @@ def _save_table(self, raw=False, cls=None, force_insert=False,\n         updated = False\n         # Skip an UPDATE when adding an instance and primary key has a default.\n         if (\n+            not raw and\n             not force_insert and\n             self._state.adding and\n             self._meta.pk.default and\n",
      "tokens": 1422,
      "success": true,
      "original_instance_id": "django__django-12209",
      "similarity": 0.0
    },
    {
      "instance_id": "astropy__astropy-12907_mutated_072f7b98",
      "generated_patch": "--- a/astropy/modeling/separable.py\n+++ b/astropy/modeling/separable.py\n@@ -1,6 +1,7 @@\n # Licensed under a 3-clause BSD style license - see LICENSE.rst\n \n import numpy as np\n+from astropy.modeling.core import CompoundModel\n \n __all__ = [\"separability_matrix\"]\n \n@@ -44,6 +45,16 @@ def separability_matrix(transform):\n     \"\"\"\n     if transform is None:\n         raise TypeError(\"transform must be a Model instance\")\n+\n+    # For nested CompoundModels, ensure separability is computed on the fully\n+    # expanded model tree. Otherwise, nested compound nodes can be treated as\n+    # opaque blocks and incorrectly marked as non-separable.\n+    if isinstance(transform, CompoundModel):\n+        try:\n+            transform = transform.flatten()\n+        except Exception:\n+            pass\n \n     n_inputs = transform.n_inputs\n     n_outputs = transform.n_outputs",
      "expected_patch": "diff --git a/astropy/modeling/separable.py b/astropy/modeling/separable.py\n--- a/astropy/modeling/separable.py\n+++ b/astropy/modeling/separable.py\n@@ -242,7 +242,7 @@ def _cstack(left, right):\n         cright = _coord_matrix(right, 'right', noutp)\n     else:\n         cright = np.zeros((noutp, right.shape[1]))\n-        cright[-right.shape[0]:, -right.shape[1]:] = 1\n+        cright[-right.shape[0]:, -right.shape[1]:] = right\n \n     return np.hstack([cleft, cright])\n \n",
      "tokens": 622,
      "success": true,
      "original_instance_id": "astropy__astropy-12907",
      "similarity": 0.0
    },
    {
      "instance_id": "pydata__xarray-4629_mutated_bdb897cc",
      "generated_patch": "--- a/xarray/core/merge.py\n+++ b/xarray/core/merge.py\n@@ -501,7 +501,7 @@\n     if combine_attrs == \"drop\":\n         return {}\n     elif combine_attrs == \"override\":\n-        return variable_attrs[0]\n+        return dict(variable_attrs[0])\n     elif combine_attrs == \"no_conflicts\":\n         result = dict(variable_attrs[0])\n         for attrs in variable_attrs[1:]:",
      "expected_patch": "diff --git a/xarray/core/merge.py b/xarray/core/merge.py\n--- a/xarray/core/merge.py\n+++ b/xarray/core/merge.py\n@@ -501,7 +501,7 @@ def merge_attrs(variable_attrs, combine_attrs):\n     if combine_attrs == \"drop\":\n         return {}\n     elif combine_attrs == \"override\":\n-        return variable_attrs[0]\n+        return dict(variable_attrs[0])\n     elif combine_attrs == \"no_conflicts\":\n         result = dict(variable_attrs[0])\n         for attrs in variable_attrs[1:]:\n",
      "tokens": 1062,
      "success": true,
      "original_instance_id": "pydata__xarray-4629",
      "similarity": 1.0
    },
    {
      "instance_id": "django__django-13516_mutated_c4e8be19",
      "generated_patch": "--- a/django/core/management/base.py\n+++ b/django/core/management/base.py\n@@ -1,6 +1,7 @@\n import argparse\n import os\n import sys\n+import functools\n import warnings\n from argparse import ArgumentParser\n from io import TextIOBase\n \n@@ -145,6 +146,28 @@ class OutputWrapper(TextIOBase):\n     def __init__(self, out, ending=\"\\n\"):\n         self._out = out\n         self.ending = ending\n+\n+    def __getattr__(self, name):\n+        \"\"\"\n+        Proxy unknown attributes/methods to the underlying stream.\n+\n+        This ensures methods like flush() work when called on\n+        self.stdout/self.stderr in management commands.\n+        \"\"\"\n+        return getattr(self._out, name)\n+\n+    @functools.wraps(getattr(sys.stdout, \"flush\", lambda: None))\n+    def flush(self):\n+        \"\"\"\n+        Flush the underlying stream.\n+        \"\"\"\n+        flush = getattr(self._out, \"flush\", None)\n+        if flush is not None:\n+            flush()\n \n     def isatty(self):\n         return hasattr(self._out, \"isatty\") and self._out.isatty()\n \n     def write(self, msg, style_func=None):\n         if msg and not msg.endswith(self.ending):\n             msg += self.ending\n         if style_func:\n             msg = style_func(msg)\n         self._out.write(msg)",
      "expected_patch": "diff --git a/django/core/management/base.py b/django/core/management/base.py\n--- a/django/core/management/base.py\n+++ b/django/core/management/base.py\n@@ -140,6 +140,10 @@ def __init__(self, out, ending='\\n'):\n     def __getattr__(self, name):\n         return getattr(self._out, name)\n \n+    def flush(self):\n+        if hasattr(self._out, 'flush'):\n+            self._out.flush()\n+\n     def isatty(self):\n         return hasattr(self._out, 'isatty') and self._out.isatty()\n \n",
      "tokens": 542,
      "success": true,
      "original_instance_id": "django__django-13516",
      "similarity": 0.5
    },
    {
      "instance_id": "django__django-13670_mutated_873560c5",
      "generated_patch": "--- a/django/utils/dateformat.py\n+++ b/django/utils/dateformat.py\n@@ -1,6 +1,7 @@\n \"\"\"\n PHP date() style date formatting\n See https://www.php.net/date for format strings\n \"\"\"\n \n+from datetime import date, datetime\n from django.utils.dates import MONTHS, MONTHS_3, WEEKDAYS, WEEKDAYS_ABBR\n from django.utils.timezone import is_aware, make_naive\n \n@@ -248,7 +249,7 @@ class DateFormat(TimeFormat):\n         return self.data.year\n \n     def y(self):\n-        return self.data.year % 100\n+        return \"%02d\" % (self.data.year % 100)\n \n     def z(self):\n         \"\"\"Day of the year, 0-365.\"\"\"",
      "expected_patch": "diff --git a/django/utils/dateformat.py b/django/utils/dateformat.py\n--- a/django/utils/dateformat.py\n+++ b/django/utils/dateformat.py\n@@ -325,8 +325,8 @@ def W(self):\n         return self.data.isocalendar()[1]\n \n     def y(self):\n-        \"Year, 2 digits; e.g. '99'\"\n-        return str(self.data.year)[2:]\n+        \"\"\"Year, 2 digits with leading zeros; e.g. '99'.\"\"\"\n+        return '%02d' % (self.data.year % 100)\n \n     def Y(self):\n         \"Year, 4 digits; e.g. '1999'\"\n",
      "tokens": 484,
      "success": true,
      "original_instance_id": "django__django-13670",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-14373_mutated_babf3ded",
      "generated_patch": "--- a/django/utils/dateformat.py\n+++ b/django/utils/dateformat.py\n@@ -1,6 +1,7 @@\n \"\"\"\n PHP date() style date formatting\n See https://www.php.net/date for format strings\n \"\"\"\n \n from datetime import date, datetime, time\n@@ -246,7 +247,7 @@ class DateFormat(TimeFormat):\n     def y(self):\n         return str(self.data.year)[2:]\n \n     def Y(self):\n-        return str(self.data.year)\n+        return f\"{self.data.year:04d}\"\n \n     def z(self):\n         \"\"\"Day of the year, 0-365.\"\"\"\n         return str(self.data.timetuple().tm_yday - 1)",
      "expected_patch": "diff --git a/django/utils/dateformat.py b/django/utils/dateformat.py\n--- a/django/utils/dateformat.py\n+++ b/django/utils/dateformat.py\n@@ -313,8 +313,8 @@ def y(self):\n         return '%02d' % (self.payload.year % 100)\n \n     def Y(self):\n-        \"Year, 4 digits; e.g. '1999'\"\n-        return self.payload.year\n+        \"\"\"Year, 4 digits with leading zeros; e.g. '1999'.\"\"\"\n+        return '%04d' % self.payload.year\n \n     def z(self):\n         \"\"\"Day of the year, i.e. 1 to 366.\"\"\"\n",
      "tokens": 293,
      "success": true,
      "original_instance_id": "django__django-14373",
      "similarity": 0.0
    },
    {
      "instance_id": "astropy__astropy-14539_mutated_6402b350",
      "generated_patch": "--- a/astropy/io/fits/diff.py\n+++ b/astropy/io/fits/diff.py\n@@ -1,6 +1,7 @@\n # Licensed under a 3-clause BSD style license - see LICENSE.rst\n \n import difflib\n+import numpy as np\n import os\n import re\n import sys\n@@ -1108,6 +1109,29 @@\n         return self._diff\n \n \n+def _vla_equal(a, b):\n+    \"\"\"\n+    Compare two VLA (variable-length array) elements for equality.\n+\n+    VLA elements may be returned as object arrays containing ndarrays/lists.\n+    FITSDiff should treat two empty VLAs as equal even if their shapes differ\n+    (e.g., (0,) vs (0,0)), and compare non-empty VLAs by value.\n+    \"\"\"\n+    if a is b:\n+        return True\n+    aa = np.asarray(a)\n+    bb = np.asarray(b)\n+    if aa.size == 0 and bb.size == 0:\n+        return True\n+    if aa.shape != bb.shape:\n+        return False\n+    return np.array_equal(aa, bb)\n+\n+\n class FITSDiff:\n     \"\"\"\n     Diff two FITS files and report differences.\n@@ -1968,6 +1992,25 @@\n                 if self.ignore_fields and colname in self.ignore_fields:\n                     continue\n \n+                # Special-case VLA columns: elements are variable-length and may\n+                # be represented as object arrays. Comparing via generic array\n+                # logic can spuriously report differences for empty VLAs due to\n+                # shape differences (e.g., (0,) vs (0,0)) even for identical\n+                # files.\n+                if getattr(col, \"format\", None) is not None and getattr(\n+                    col.format, \"is_vla\", False\n+                ):\n+                    for i in range(nrows):\n+                        if not _vla_equal(a[i], b[i]):\n+                            self._diff = True\n+                            self._report_table_value_difference(\n+                                colname, i, a[i], b[i]\n+                            )\n+                            if self._diff_count_reached():\n+                                return\n+                    continue\n+\n                 # Compare column arrays\n                 if isinstance(a, np.ndarray) and isinstance(b, np.ndarray):\n                     if a.dtype.kind in (\"f\", \"c\") or b.dtype.kind in (\"f\", \"c\"):\n                         # Floating point comparison with tolerances\n                         self._diff = self._diff or not self._compare_floating(\n                             a, b, colname, nrows\n                         )\n                     else:\n                         self._diff = self._diff or not self._compare_array(\n                             a, b, colname, nrows\n                         )\n                 else:\n                     # Compare element by element\n                     for i in range(nrows):\n                         if a[i] != b[i]:\n                             self._diff = True\n                             self._report_table_value_difference(\n                                 colname, i, a[i], b[i]\n                             )\n                             if self._diff_count_reached():\n                                 return",
      "expected_patch": "diff --git a/astropy/io/fits/diff.py b/astropy/io/fits/diff.py\n--- a/astropy/io/fits/diff.py\n+++ b/astropy/io/fits/diff.py\n@@ -1449,7 +1449,7 @@ def _diff(self):\n                 arrb.dtype, np.floating\n             ):\n                 diffs = where_not_allclose(arra, arrb, rtol=self.rtol, atol=self.atol)\n-            elif \"P\" in col.format:\n+            elif \"P\" in col.format or \"Q\" in col.format:\n                 diffs = (\n                     [\n                         idx\n",
      "tokens": 1204,
      "success": true,
      "original_instance_id": "astropy__astropy-14539",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-15569_mutated_05b60cd6",
      "generated_patch": "--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -209,11 +209,12 @@\n     def _unregister_lookup(cls, lookup, lookup_name=None):\n         if lookup_name is None:\n             lookup_name = lookup.lookup_name\n         if lookup_name in cls.class_lookups:\n             del cls.class_lookups[lookup_name]\n+            cls._clear_cached_lookups()\n \n     @classmethod\n     def get_lookup(cls, lookup_name):\n         return cls.get_lookups().get(lookup_name, None)\n--- a/tests/schema/tests.py\n+++ b/tests/schema/tests.py\n@@ -3618,7 +3618,7 @@\n         with connection.schema_editor() as editor:\n             editor.create_model(Author)\n         self.addCleanup(Author._meta.apps.unregister_model, \"schema\", \"author\")\n \n-        with register_lookup(Func, UniqueConstraintLookup):\n+        with register_lookup(Func, UniqueConstraintLookup), register_lookup(Func, UniqueConstraintLookup):\n             with connection.schema_editor() as editor:\n                 editor.add_constraint(\n                     Author,\n                     models.UniqueConstraint(\n                         Func(\"name\"),\n                         name=\"func_unique_constraint\",\n                     ),\n                 )",
      "expected_patch": "diff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -217,6 +217,7 @@ def _unregister_lookup(cls, lookup, lookup_name=None):\n         if lookup_name is None:\n             lookup_name = lookup.lookup_name\n         del cls.class_lookups[lookup_name]\n+        cls._clear_cached_lookups()\n \n \n def select_related_descend(field, restricted, requested, load_fields, reverse=False):\n",
      "tokens": 499,
      "success": true,
      "original_instance_id": "django__django-15569",
      "similarity": 1.0
    },
    {
      "instance_id": "django__django-14792_mutated_bf61970a",
      "generated_patch": "--- a/django/db/backends/postgresql/operations.py\n+++ b/django/db/backends/postgresql/operations.py\n@@ -1,6 +1,7 @@\n import datetime\n import json\n import re\n+from zoneinfo import ZoneInfo\n \n from django.conf import settings\n from django.db.backends.base.operations import BaseDatabaseOperations\n@@ -97,6 +98,19 @@ class DatabaseOperations(BaseDatabaseOperations):\n     def _prepare_tzname_delta(self, tzname):\n         \"\"\"\n         Convert a timezone name into the format required by PostgreSQL.\n         \"\"\"\n+        # Handle reversed-sign \"Etc/GMT\u00b1X\" zones (POSIX convention).\n+        # E.g. \"Etc/GMT-10\" means UTC+10, but PostgreSQL interprets it as UTC-10.\n+        # Convert these to a numeric offset so PostgreSQL applies the correct sign.\n+        m = re.match(r\"^Etc/GMT(?P<sign>[+-])(?P<hours>\\d{1,2})$\", tzname)\n+        if m:\n+            sign = m.group(\"sign\")\n+            hours = int(m.group(\"hours\"))\n+            if 0 <= hours <= 14:\n+                # Reverse sign: Etc/GMT-10 -> +10, Etc/GMT+10 -> -10\n+                return f\"{'+' if sign == '-' else '-'}{hours}\"\n         if tzname.startswith((\"+\", \"-\")):\n             return tzname\n         return tzname.replace(\":\", \"\")",
      "expected_patch": "diff --git a/django/utils/timezone.py b/django/utils/timezone.py\n--- a/django/utils/timezone.py\n+++ b/django/utils/timezone.py\n@@ -72,8 +72,11 @@ def fetch_current_timezone_name():\n \n \n def _fetch_timezone_name(timezone):\n-    \"\"\"Return the name of ``timezone``.\"\"\"\n-    return str(timezone)\n+    \"\"\"\n+    Return the offset for fixed offset timezones, or the name of timezone if\n+    not set.\n+    \"\"\"\n+    return timezone.tzname(None) or str(timezone)\n \n # Timezone selection functions.\n \n",
      "tokens": 837,
      "success": true,
      "original_instance_id": "django__django-14792",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-11119_mutated_40bf3e14",
      "generated_patch": "--- a/django/template/engine.py\n+++ b/django/template/engine.py\n@@ -183,7 +183,7 @@ class Engine:\n     def render_to_string(self, template_name, context=None):\n         \"\"\"\n         Render the template specified by template_name with the given context.\n         \"\"\"\n-        if isinstance(context, Context):\n+        if isinstance(context, Context):\n             context = context.flatten()\n-        context = Context(context or {})\n+        context = Context(context or {}, autoescape=self.autoescape)\n         template = self.get_template(template_name)\n         return template.render(context)",
      "expected_patch": "diff --git a/django/template/engine.py b/django/template/engine.py\n--- a/django/template/engine.py\n+++ b/django/template/engine.py\n@@ -160,7 +160,7 @@ def render_to_string(self, template_name, context=None):\n         if isinstance(context, Context):\n             return t.render(context)\n         else:\n-            return t.render(Context(context))\n+            return t.render(Context(context, autoescape=self.autoescape))\n \n     def select_template(self, template_name_list):\n         \"\"\"\n",
      "tokens": 295,
      "success": true,
      "original_instance_id": "django__django-11119",
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-13647_mutated_1fe3f9ef",
      "generated_patch": "--- a/sympy/matrices/common.py\n+++ b/sympy/matrices/common.py\n@@ -1,6 +1,7 @@\n from __future__ import print_function, division\n \n from sympy.core.compatibility import is_sequence\n+from sympy.core.numbers import Integer\n from sympy.core.sympify import sympify\n from sympy.core.singleton import S\n from sympy.core.basic import Basic\n@@ -1972,20 +1973,27 @@\n         return self._eval_col_del(col)\n \n     def col_insert(self, pos, other):\n-        \"\"\"Insert one or more columns at the given column position.\n+        \"\"\"Insert one or more columns at the given column position.\n \n         Examples\n         ========\n \n         >>> from sympy import Matrix, eye\n         >>> M = eye(3)\n         >>> V = Matrix([[1, 2], [3, 4], [5, 6]])\n         >>> M.col_insert(1, V)\n         Matrix([\n         [1, 1, 2, 0, 0],\n         [0, 3, 4, 1, 0],\n         [0, 5, 6, 0, 1]])\n \n         \"\"\"\n-        other = self._new(other)\n-        if self.rows != other.rows:\n+        pos = Integer(pos)\n+        other = self._new(other)\n+        if self.rows != other.rows:\n             raise ShapeError(\"The matrices have incompatible number of rows (%s and %s)\" % (self.rows, other.rows))\n-        return self._new(self.rows, self.cols + other.cols,\n-            lambda i, j: self[i, j] if j < pos else\n-            other[i, j - pos] if j < pos + other.cols else\n-            self[i, j - other.cols])\n+        cols = self.cols\n+        ocols = other.cols\n+        return self._new(self.rows, cols + ocols,\n+            lambda i, j: self[i, j] if j < pos else\n+            other[i, j - pos] if j < pos + ocols else\n+            self[i, j - ocols])",
      "expected_patch": "diff --git a/sympy/matrices/common.py b/sympy/matrices/common.py\n--- a/sympy/matrices/common.py\n+++ b/sympy/matrices/common.py\n@@ -86,7 +86,7 @@ def entry(i, j):\n                 return self[i, j]\n             elif pos <= j < pos + other.cols:\n                 return other[i, j - pos]\n-            return self[i, j - pos - other.cols]\n+            return self[i, j - other.cols]\n \n         return self._new(self.rows, self.cols + other.cols,\n                          lambda i, j: entry(i, j))\n",
      "tokens": 1222,
      "success": true,
      "original_instance_id": "sympy__sympy-13647",
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-15809_mutated_67c7ed4b",
      "generated_patch": "--- a/sympy/functions/elementary/miscellaneous.py\n+++ b/sympy/functions/elementary/miscellaneous.py\n@@ -1,6 +1,7 @@\n from __future__ import annotations\n \n from sympy.core import S, sympify\n+from sympy.core.numbers import Infinity, NegativeInfinity\n from sympy.core.add import Add\n from sympy.core.basic import Basic\n from sympy.core.cache import cacheit\n@@ -546,10 +547,14 @@ class MinMaxBase(Expr):\n     def __new__(cls, *args, **assumptions):\n         args = (sympify(arg) for arg in args)\n         args = frozenset(args)\n-        if not args:\n-            raise ValueError(\"The Max/Min functions must have arguments.\")\n+        if not args:\n+            if cls.__name__ == 'Min':\n+                return Infinity()\n+            if cls.__name__ == 'Max':\n+                return NegativeInfinity()\n+            raise ValueError(\"The Max/Min functions must have arguments.\")\n         if len(args) == 1:\n             return args.pop()\n         args = cls._find_localzeros(args)\n         return Expr.__new__(cls, *ordered(args), **assumptions)",
      "expected_patch": "diff --git a/sympy/functions/elementary/miscellaneous.py b/sympy/functions/elementary/miscellaneous.py\n--- a/sympy/functions/elementary/miscellaneous.py\n+++ b/sympy/functions/elementary/miscellaneous.py\n@@ -339,8 +339,6 @@ def real_root(arg, n=None, evaluate=None):\n \n class MinMaxBase(Expr, LatticeOp):\n     def __new__(cls, *args, **assumptions):\n-        if not args:\n-            raise ValueError(\"The Max/Min functions must have arguments.\")\n \n         args = (sympify(arg) for arg in args)\n \n",
      "tokens": 441,
      "success": true,
      "original_instance_id": "sympy__sympy-15809",
      "similarity": 1.0
    },
    {
      "instance_id": "sphinx-doc__sphinx-8621_mutated_f2dd67f6",
      "generated_patch": "--- a/sphinx/roles.py\n+++ b/sphinx/roles.py\n@@ -1,6 +1,7 @@\n \"\"\"Sphinx roles.\"\"\"\n \n from __future__ import annotations\n \n+import re\n from typing import TYPE_CHECKING\n \n from docutils import nodes\n from docutils.parsers.rst import roles\n \n@@ -260,6 +261,38 @@ def abbr_role(typ: str, rawtext: str, text: str, lineno: int,\n     return [node], []\n \n \n+_kbd_sep_re = re.compile(r'(?<!\\\\)([-+^])')\n+\n+\n+def _parse_kbd(text: str) -> list[str]:\n+    \"\"\"Parse :kbd: role content into tokens.\n+\n+    Separators are '-', '+' and '^' unless escaped with a backslash.\n+    Escaped separators are treated as literal keystrokes.\n+    \"\"\"\n+    parts = _kbd_sep_re.split(text)\n+    if len(parts) == 1:\n+        return [text.replace(r'\\-', '-').replace(r'\\+', '+').replace(r'\\^', '^')]\n+\n+    tokens: list[str] = []\n+    for i, part in enumerate(parts):\n+        if i % 2 == 0:\n+            if part:\n+                tokens.append(part.replace(r'\\-', '-').replace(r'\\+', '+').replace(r'\\^', '^'))\n+        else:\n+            tokens.append(part)\n+\n+    # If the input is exactly a single separator (e.g. \"-\" or \"+\"), treat it as a key.\n+    if tokens == ['-'] or tokens == ['+'] or tokens == ['^']:\n+        return tokens\n+\n+    return tokens\n+\n+\n def kbd_role(typ: str, rawtext: str, text: str, lineno: int,\n              inliner: Inliner, options: dict = {}, content: list[str] = []) -> tuple[list[Node], list[system_message]]:\n     r\"\"\"Role for keyboard shortcuts.\n@@ -268,20 +301,21 @@ def kbd_role(typ: str, rawtext: str, text: str, lineno: int,\n     \"\"\"\n     options.setdefault('classes', []).append('kbd')\n \n-    parts = re.split(r'([-+^])', text)\n-    if len(parts) == 1:\n-        return [nodes.literal(rawtext, text, **options)], []\n-\n     node = nodes.literal(rawtext, '', **options)\n-    for part in parts:\n-        if part in ('-', '+', '^'):\n-            node += nodes.Text(part)\n-        else:\n-            node += nodes.literal(part, part, classes=['kbd'])\n+    tokens = _parse_kbd(text)\n+    if len(tokens) == 1 and tokens[0] in ('-', '+', '^'):\n+        return [nodes.literal(rawtext, tokens[0], **options)], []\n+\n+    for tok in tokens:\n+        if tok in ('-', '+', '^'):\n+            node += nodes.Text(tok)\n+        else:\n+            node += nodes.literal(tok, tok, classes=['kbd'])\n \n     return [node], []\n \n",
      "expected_patch": "diff --git a/sphinx/builders/html/transforms.py b/sphinx/builders/html/transforms.py\n--- a/sphinx/builders/html/transforms.py\n+++ b/sphinx/builders/html/transforms.py\n@@ -37,7 +37,7 @@ class KeyboardTransform(SphinxPostTransform):\n     \"\"\"\n     default_priority = 400\n     builders = ('html',)\n-    pattern = re.compile(r'(-|\\+|\\^|\\s+)')\n+    pattern = re.compile(r'(?<=.)(-|\\+|\\^|\\s+)(?=.)')\n \n     def run(self, **kwargs: Any) -> None:\n         matcher = NodeMatcher(nodes.literal, classes=[\"kbd\"])\n",
      "tokens": 1319,
      "success": true,
      "original_instance_id": "sphinx-doc__sphinx-8621",
      "similarity": 0.0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-13439_mutated_0fe72848",
      "generated_patch": "--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1,6 +1,7 @@\n \"\"\"Utilities to build a composite estimator as a chain of transforms and estimators.\"\"\"\n \n # Author: Edouard Duchesnay\n+#         scikit-learn developers\n # License: BSD\n \n from collections import defaultdict\n@@ -214,6 +215,9 @@ class Pipeline(_BaseComposition):\n     def __getitem__(self, ind):\n         return self._getitem(ind)\n \n+    def __len__(self):\n+        return len(self.steps)\n+\n     @property\n     def _estimator_type(self):\n         return self.steps[-1][1]._estimator_type",
      "expected_patch": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -199,6 +199,12 @@ def _iter(self, with_final=True):\n             if trans is not None and trans != 'passthrough':\n                 yield idx, name, trans\n \n+    def __len__(self):\n+        \"\"\"\n+        Returns the length of the Pipeline\n+        \"\"\"\n+        return len(self.steps)\n+\n     def __getitem__(self, ind):\n         \"\"\"Returns a sub-pipeline or a single esimtator in the pipeline\n \n",
      "tokens": 627,
      "success": true,
      "original_instance_id": "scikit-learn__scikit-learn-13439",
      "similarity": 0.6
    },
    {
      "instance_id": "matplotlib__matplotlib-13989_mutated_ce2deedc",
      "generated_patch": "--- a/lib/matplotlib/axes/_axes.py\n+++ b/lib/matplotlib/axes/_axes.py\n@@ -7040,6 +7040,7 @@\n         if np.isscalar(x):\n             x = [x]\n \n+        hist_range = range\n         # We need to do to 'weights' what was done to 'x'\n         if weights is not None:\n             w = cbook._reshape_2D(weights, 'weights')\n@@ -7047,6 +7048,7 @@\n                 raise ValueError('weights should have the same shape as x')\n         else:\n             w = [None] * nx\n+        range = hist_range\n \n         if color is None:\n             color = [self._get_lines.get_next_color() for i in range(nx)]\n@@ -7086,7 +7088,7 @@\n             # this will automatically overwrite bins,\n             # so that each histogram uses the same bins\n             if bins == 'auto':\n-                bins = np.histogram_bin_edges(np.concatenate(x), bins=bins,\n+                bins = np.histogram_bin_edges(np.concatenate(x), bins=bins, range=range,\n                                               weights=np.concatenate(w)\n                                               if w[0] is not None else None)\n             else:",
      "expected_patch": "diff --git a/lib/matplotlib/axes/_axes.py b/lib/matplotlib/axes/_axes.py\n--- a/lib/matplotlib/axes/_axes.py\n+++ b/lib/matplotlib/axes/_axes.py\n@@ -6686,7 +6686,7 @@ def hist(self, x, bins=None, range=None, density=None, weights=None,\n \n         density = bool(density) or bool(normed)\n         if density and not stacked:\n-            hist_kwargs = dict(density=density)\n+            hist_kwargs['density'] = density\n \n         # List to store all the top coordinates of the histograms\n         tops = []\n",
      "tokens": 799,
      "success": true,
      "original_instance_id": "matplotlib__matplotlib-13989",
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-12096_mutated_98dabd86",
      "generated_patch": "--- a/sympy/core/function.py\n+++ b/sympy/core/function.py\n@@ -2280,11 +2280,12 @@\n     def _eval_evalf(self, prec):\n         if hasattr(self, '_imp_') and self._imp_ is not None:\n             args = [i.evalf(prec) for i in self.args]\n             try:\n-                return self._imp_(*args)\n+                return self._imp_(*args).evalf(prec)\n             except (TypeError, ValueError):\n                 return None\n         return None",
      "expected_patch": "diff --git a/sympy/core/function.py b/sympy/core/function.py\n--- a/sympy/core/function.py\n+++ b/sympy/core/function.py\n@@ -507,7 +507,7 @@ def _eval_evalf(self, prec):\n             func = getattr(mpmath, fname)\n         except (AttributeError, KeyError):\n             try:\n-                return Float(self._imp_(*self.args), prec)\n+                return Float(self._imp_(*[i.evalf(prec) for i in self.args]), prec)\n             except (AttributeError, TypeError, ValueError):\n                 return\n \n",
      "tokens": 389,
      "success": true,
      "original_instance_id": "sympy__sympy-12096",
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-17655_mutated_4af1aa62",
      "generated_patch": "--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -1,6 +1,7 @@\n from __future__ import annotations\n \n from sympy.core import S, sympify\n+from sympy.core.mul import Mul\n from sympy.core.add import Add\n from sympy.core.numbers import Float\n from sympy.core.relational import Eq\n@@ -206,6 +207,10 @@ class Point(GeometryEntity):\n     def __add__(self, other):\n         \"\"\"Add other to self by adding their coordinates.\"\"\"\n         if isinstance(other, Point):\n             s, o = Point._normalize_dimension(self, other)\n             coords = [simplify(a + b) for a, b in zip(s, o)]\n             return Point(coords, evaluate=False)\n+        if isinstance(other, Mul) and len(other.args) == 2:\n+            a0, a1 = other.args\n+            if isinstance(a0, Point) and not isinstance(a1, Point):\n+                return self + (a1 * a0)\n+            if isinstance(a1, Point) and not isinstance(a0, Point):\n+                return self + (a0 * a1)\n         try:\n             s, o = Point._normalize_dimension(self, Point(other, evaluate=False))\n         except TypeError:\n             raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))",
      "expected_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -278,6 +278,10 @@ def __mul__(self, factor):\n         coords = [simplify(x*factor) for x in self.args]\n         return Point(coords, evaluate=False)\n \n+    def __rmul__(self, factor):\n+        \"\"\"Multiply a factor by point's coordinates.\"\"\"\n+        return self.__mul__(factor)\n+\n     def __neg__(self):\n         \"\"\"Negate the point.\"\"\"\n         coords = [-x for x in self.args]\n",
      "tokens": 885,
      "success": true,
      "original_instance_id": "sympy__sympy-17655",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-12304_mutated_7446e759",
      "generated_patch": "--- a/django/db/models/enums.py\n+++ b/django/db/models/enums.py\n@@ -1,6 +1,7 @@\n from enum import Enum, IntEnum\n \n from django.utils.functional import Promise\n+from django.utils.translation import gettext_lazy as _\n \n \n class ChoicesMeta(Enum.__class__):\n@@ -54,6 +55,8 @@ class ChoicesMeta(Enum.__class__):\n \n \n class Choices(Enum, metaclass=ChoicesMeta):\n+    do_not_call_in_templates = True\n+\n     @classmethod\n     def choices(cls):\n         return [(member.value, member.label) for member in cls]\n@@ -79,6 +82,8 @@ class Choices(Enum, metaclass=ChoicesMeta):\n \n \n class IntegerChoices(int, Choices, IntEnum):\n+    do_not_call_in_templates = True\n+\n     pass\n \n \n@@ -86,6 +91,8 @@ class TextChoices(str, Choices):\n+    do_not_call_in_templates = True\n+\n     @staticmethod\n     def _generate_next_value_(name, start, count, last_values):\n         return name",
      "expected_patch": "diff --git a/django/db/models/enums.py b/django/db/models/enums.py\n--- a/django/db/models/enums.py\n+++ b/django/db/models/enums.py\n@@ -31,6 +31,7 @@ def __new__(metacls, classname, bases, classdict):\n         # that is passed in as \"self\" as the value to use when looking up the\n         # label in the choices.\n         cls.label = property(lambda self: cls._value2label_map_.get(self.value))\n+        cls.do_not_call_in_templates = True\n         return enum.unique(cls)\n \n     def __contains__(cls, member):\n",
      "tokens": 440,
      "success": true,
      "original_instance_id": "django__django-12304",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-13012_mutated_b0d04be3",
      "generated_patch": "--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -1485,6 +1485,9 @@ class ExpressionWrapper(SQLiteNumericMixin, Expression):\n     def get_group_by_cols(self):\n         if isinstance(self.expression, Expression):\n             expression = self.expression.copy()\n+            # Preserve \"constant\" status of wrapped expressions so they don't\n+            # get incorrectly added to GROUP BY.\n+            expression.contains_aggregate = self.contains_aggregate\n             expression.output_field = self.output_field\n             return expression.get_group_by_cols()\n         return super().get_group_by_cols()",
      "expected_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -863,6 +863,9 @@ def set_source_expressions(self, exprs):\n     def fetch_source_expressions(self):\n         return [self.expression]\n \n+    def fetch_group_by_cols(self, alias=None):\n+        return self.expression.fetch_group_by_cols(alias=alias)\n+\n     def as_sql(self, compiler, connection):\n         return self.expression.as_sql(compiler, connection)\n \n",
      "tokens": 554,
      "success": true,
      "original_instance_id": "django__django-13012",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-14672_mutated_5803286e",
      "generated_patch": "--- a/django/db/models/fields/reverse_related.py\n+++ b/django/db/models/fields/reverse_related.py\n@@ -340,12 +340,12 @@\n class ManyToManyRel(ForeignObjectRel):\n     def __init__(\n         self,\n         field,\n         to,\n         related_name=None,\n         related_query_name=None,\n         limit_choices_to=None,\n         symmetrical=True,\n         through=None,\n         through_fields=None,\n         db_constraint=True,\n     ):\n         super().__init__(\n             field,\n             to,\n             related_name=related_name,\n             related_query_name=related_query_name,\n             limit_choices_to=limit_choices_to,\n         )\n         self.symmetrical = symmetrical\n         self.through = through\n         self.through_fields = through_fields\n         self.db_constraint = db_constraint\n \n     @property\n     def identity(self):\n         return super().identity + (\n             self.symmetrical,\n             self.through,\n-            self.through_fields,\n+            make_hashable(self.through_fields),\n             self.db_constraint,\n         )",
      "expected_patch": "diff --git a/django/db/models/fields/reverse_related.py b/django/db/models/fields/reverse_related.py\n--- a/django/db/models/fields/reverse_related.py\n+++ b/django/db/models/fields/reverse_related.py\n@@ -310,7 +310,7 @@ def __init__(self, field, to, related_name=None, related_query_name=None,\n     def identity(self):\n         return super().identity + (\n             self.through,\n-            self.through_fields,\n+            make_hashable(self.through_fields),\n             self.db_constraint,\n         )\n \n",
      "tokens": 2096,
      "success": true,
      "original_instance_id": "django__django-14672",
      "similarity": 1.0
    },
    {
      "instance_id": "psf__requests-5414_mutated_8f0420ac",
      "generated_patch": "--- a/requests/models.py\n+++ b/requests/models.py\n@@ -1,6 +1,7 @@\n # -*- coding: utf-8 -*-\n \n import datetime\n+import codecs\n import encodings.idna\n import os\n import re\n@@ -395,12 +396,18 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         if not host:\n             raise InvalidURL(\"Invalid URL %r: No host supplied\" % url)\n \n-        try:\n-            host = host.encode(\"idna\").decode(\"utf-8\")\n-        except UnicodeError:\n-            raise InvalidURL(\"URL has an invalid label.\")\n+        try:\n+            host = host.encode(\"idna\").decode(\"utf-8\")\n+        except (UnicodeError, codecs.CodecError):\n+            raise InvalidURL(\"URL has an invalid label.\")\n \n         return host",
      "expected_patch": "diff --git a/requests/models.py b/requests/models.py\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -403,7 +403,7 @@ def prepare_url(self, url, params):\n                 host = self._fetch_idna_encoded_host(host)\n             except UnicodeError:\n                 raise InvalidURL('URL has an invalid label.')\n-        elif host.startswith(u'*'):\n+        elif host.startswith((u'*', u'.')):\n             raise InvalidURL('URL has an invalid label.')\n \n         # Carefully reconstruct the network location\n",
      "tokens": 707,
      "success": true,
      "original_instance_id": "psf__requests-5414",
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-16450_mutated_6529b11a",
      "generated_patch": "--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -1,6 +1,7 @@\n from __future__ import annotations\n \n from collections import defaultdict\n+from sympy.core.assumptions import StdFactKB\n from sympy.core import (Add, Basic, Derivative, Dummy, Expr, Function,\n     Mul, Pow, S, Symbol, Wild, cacheit, expand, expand_mul, factor_terms,\n     sympify)\n@@ -225,6 +226,20 @@ def posify(eq):\n     >>> posify(x + y)\n     (_x + _y, {_x: x, _y: y})\n     \"\"\"\n+    def _copy_assumptions(sym):\n+        # Preserve explicit assumptions from the original symbol.\n+        # Symbol assumptions are stored in a StdFactKB; copy its facts.\n+        a = getattr(sym, '_assumptions', None)\n+        if isinstance(a, StdFactKB):\n+            return dict(a)\n+        if isinstance(a, dict):\n+            return dict(a)\n+        return {}\n+\n     eq = sympify(eq)\n     reps = {}\n     for s in eq.free_symbols:\n@@ -233,7 +248,8 @@ def posify(eq):\n             continue\n         if s.is_positive:\n             continue\n-        reps[s] = Symbol(s.name, positive=True, real=True)\n+        assumps = _copy_assumptions(s)\n+        reps[s] = Symbol(s.name, positive=True, real=True, **assumps)\n     eq = eq.xreplace(reps)\n     return eq, {v: k for k, v in reps.items()}",
      "expected_patch": "diff --git a/sympy/simplify/simplify.py b/sympy/simplify/simplify.py\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -251,7 +251,7 @@ def posify(eq):\n             eq[i] = e.subs(reps)\n         return f(eq), {r: s for s, r in reps.items()}\n \n-    reps = {s: Dummy(s.name, positive=True)\n+    reps = {s: Dummy(s.name, positive=True, **s.assumptions0)\n                  for s in eq.free_symbols if s.is_positive is None}\n     eq = eq.subs(reps)\n     return eq, {r: s for s, r in reps.items()}\n",
      "tokens": 701,
      "success": true,
      "original_instance_id": "sympy__sympy-16450",
      "similarity": 0.0
    },
    {
      "instance_id": "astropy__astropy-13453_mutated_0b9ad114",
      "generated_patch": "--- a/astropy/io/ascii/html.py\n+++ b/astropy/io/ascii/html.py\n@@ -1,6 +1,7 @@\n # Licensed under a 3-clause BSD style license - see LICENSE.rst\n \n import re\n+from .core import _apply_include_exclude_names\n \n from astropy.utils.xml.writer import XMLWriter\n \n@@ -235,6 +236,15 @@ class HTML(core.BaseOutputter):\n         self.html = html\n         self.css = css\n \n+    def _apply_formats(self, cols):\n+        \"\"\"Apply user-supplied formats to columns (in-place).\"\"\"\n+        if getattr(self, \"formats\", None):\n+            for col in cols:\n+                fmt = self.formats.get(col.info.name)\n+                if fmt is not None:\n+                    col.info.format = fmt\n+\n     def write(self, table):\n         \"\"\"\n         Write the ``table`` as list of strings.\n@@ -242,7 +252,12 @@ class HTML(core.BaseOutputter):\n         Parameters\n         ----------\n         table : `~astropy.table.Table`\n             Input table data.\n         \"\"\"\n-        cols = list(table.columns.values())\n+        cols = list(table.columns.values())\n+        # Ensure include/exclude_names are applied consistently with other writers\n+        cols = _apply_include_exclude_names(\n+            cols, getattr(self, \"names\", None), getattr(self, \"include_names\", None), getattr(self, \"exclude_names\", None)\n+        )\n+        self._apply_formats(cols)\n \n         w = XMLWriter()\n         with w.tag(\"html\"):\n@@ -270,7 +285,7 @@ class HTML(core.BaseOutputter):\n                         for col in cols:\n                             w.start(\"th\")\n                             w.data(col.info.name)\n                             w.end(indent=False)\n                     w.end()\n \n                 for i in range(len(cols[0])):\n                     w.start(\"tr\")\n                     for col in cols:\n                         w.start(\"td\")\n-                        w.data(str(col[i]))\n+                        w.data(col.info.format_value(col[i]))\n                         w.end(indent=False)\n                     w.end()\n \n         return w.getvalue().splitlines()",
      "expected_patch": "diff --git a/astropy/io/ascii/html.py b/astropy/io/ascii/html.py\n--- a/astropy/io/ascii/html.py\n+++ b/astropy/io/ascii/html.py\n@@ -349,11 +349,13 @@ def write(self, table):\n         cols = array(table.columns.values())\n \n         self.data.header.cols = cols\n+        self.data.cols = cols\n \n         if isinstance(self.data.fill_values, tuple):\n             self.data.fill_values = [self.data.fill_values]\n \n         self.data._set_fill_values(cols)\n+        self.data._set_col_formats()\n \n         lines = []\n \n",
      "tokens": 2738,
      "success": true,
      "original_instance_id": "astropy__astropy-13453",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-15851_mutated_de21eabb",
      "generated_patch": "--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -1,6 +1,7 @@\n import os\n import signal\n import subprocess\n+import sys\n \n from django.db.backends.base.client import BaseDatabaseClient\n \n@@ -33,7 +34,7 @@ class DatabaseClient(BaseDatabaseClient):\n         env = os.environ.copy()\n         env.update(self.settings_to_cmd_args_env(settings_dict, parameters))\n         args = [self.executable_name]\n-        args += self.settings_to_cmd_args(settings_dict)\n+        args += self.settings_to_cmd_args(settings_dict, parameters)\n         if env:\n             env = {key: str(value) for key, value in env.items()}\n         return args, env\n@@ -41,7 +42,7 @@ class DatabaseClient(BaseDatabaseClient):\n     def settings_to_cmd_args_env(self, settings_dict, parameters):\n         env = {}\n         if settings_dict[\"NAME\"]:\n-            env[\"PGDATABASE\"] = settings_dict[\"NAME\"]\n+            env[\"PGDATABASE\"] = settings_dict[\"NAME\"]\n         if settings_dict[\"USER\"]:\n             env[\"PGUSER\"] = settings_dict[\"USER\"]\n         if settings_dict[\"PASSWORD\"]:\n@@ -63,7 +64,7 @@ class DatabaseClient(BaseDatabaseClient):\n         return env\n \n-    def settings_to_cmd_args(self, settings_dict):\n+    def settings_to_cmd_args(self, settings_dict, parameters=None):\n         args = []\n         options = settings_dict[\"OPTIONS\"]\n         if options and \"service\" in options:\n@@ -78,6 +79,12 @@ class DatabaseClient(BaseDatabaseClient):\n         if settings_dict[\"PORT\"]:\n             args += [\"-p\", str(settings_dict[\"PORT\"])]\n         args += [\"-U\", settings_dict[\"USER\"]] if settings_dict[\"USER\"] else []\n+        # psql expects all options to precede the database name.\n+        if parameters:\n+            args += parameters\n+        # If a database name is provided, pass it as the final argument.\n+        if settings_dict[\"NAME\"]:\n+            args += [settings_dict[\"NAME\"]]\n         return args",
      "expected_patch": "diff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -32,9 +32,9 @@ def settings_to_cmd_args_env(cls, settings_dict, parameters):\n             args += [\"-h\", host]\n         if port:\n             args += [\"-p\", str(port)]\n+        args.extend(parameters)\n         if dbname:\n             args += [dbname]\n-        args.extend(parameters)\n \n         env = {}\n         if passwd:\n",
      "tokens": 690,
      "success": true,
      "original_instance_id": "django__django-15851",
      "similarity": 0.0
    },
    {
      "instance_id": "pydata__xarray-4094_mutated_e3a9d9ca",
      "generated_patch": "--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -1,6 +1,7 @@\n from __future__ import annotations\n \n from collections.abc import Hashable, Iterable, Mapping, Sequence\n+from typing import Any\n from datetime import datetime, timedelta\n from functools import partial\n from numbers import Number\n@@ -1,6 +1,7 @@\n import numpy as np\n import pandas as pd\n \n+from xarray.core.merge import merge\n from xarray.core import dtypes, duck_array_ops, formatting, indexing, ops, utils\n from xarray.core.alignment import align\n from xarray.core.arithmetic import DataArrayArithmetic\n@@ -1,6 +1,7 @@\n from xarray.core.coordinates import Coordinates\n from xarray.core.dataset import Dataset\n from xarray.core.indexes import Index, Indexes\n+from xarray.core.merge import merge\n from xarray.core.options import OPTIONS\n from xarray.core.utils import (\n     Default,\n@@ -1,6 +1,7 @@\n from xarray.core.variable import (\n     IndexVariable,\n     Variable,\n     as_variable,\n )\n@@ -1,6 +1,7 @@\n from xarray.namedarray.pycompat import is_duck_array\n from xarray.namedarray.utils import is_dict_like\n \n \n@@ -3080,7 +3081,7 @@ class DataArray(\n         if dim not in self.dims:\n             raise ValueError(f\"'{dim}' is not a dimension of this array\")\n \n-        datasets = []\n+        datasets: list[Dataset] = []\n         for label in self.get_index(dim):\n             subset = self.sel({dim: label})\n             if label in subset.coords:\n@@ -3088,7 +3089,15 @@ class DataArray(\n             datasets.append(subset.to_dataset(dim))\n \n-        return Dataset.merge(*datasets)\n+        # Avoid MergeError when the stacked dimension coordinate is identical\n+        # across all datasets (e.g. single-dimension variables stacked via\n+        # to_stacked_array). In that case, merging should keep one copy.\n+        return merge(datasets, compat=\"override\")",
      "expected_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -1961,7 +1961,7 @@ def to_unstacked_dataset(self, dim, level=0):\n         # pull variables out of datarray\n         data_dict = {}\n         for k in variables:\n-            data_dict[k] = self.sel({variable_dim: k}).squeeze(drop=True)\n+            data_dict[k] = self.sel({variable_dim: k}, drop=True).squeeze(drop=True)\n \n         # unstacked dataset\n         return Dataset(data_dict)\n",
      "tokens": 1124,
      "success": true,
      "original_instance_id": "pydata__xarray-4094",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-13569_mutated_48a04e3d",
      "generated_patch": "--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -1,6 +1,7 @@\n from itertools import chain\n \n from django.core.exceptions import EmptyResultSet, FieldError\n+from django.db.models.functions import Random\n from django.db.models.sql.constants import (\n     CURSOR, GET_ITERATOR_CHUNK_SIZE, MULTI, NO_RESULTS, ORDER_DIR, SINGLE,\n )\n@@ -170,6 +171,7 @@ class SQLCompiler:\n         return expressions\n \n     def get_group_by(self, select, order_by):\n         \"\"\"\n         Return a list of 2-tuples of (sql, params) for the GROUP BY clause.\n@@ -228,12 +230,18 @@ class SQLCompiler:\n         # Add any expressions used in ORDER BY that are not already in the\n         # GROUP BY clause.\n         for expr, (sql, params, is_ref) in order_by:\n             if expr.contains_aggregate:\n                 continue\n             if is_ref:\n                 continue\n-            expressions.extend(expr.get_source_expressions())\n+            # Random ordering (order_by('?')) shouldn't affect grouping.\n+            # Avoid adding RANDOM() to GROUP BY as it breaks aggregation.\n+            expressions.extend(\n+                exp\n+                for exp in expr.get_source_expressions()\n+                if not isinstance(exp, Random)\n+            )\n         return expressions",
      "expected_patch": "diff --git a/django/db/models/functions/math.py b/django/db/models/functions/math.py\n--- a/django/db/models/functions/math.py\n+++ b/django/db/models/functions/math.py\n@@ -154,6 +154,9 @@ def as_oracle(self, compiler, connection, **extra_context):\n     def as_sqlite(self, compiler, connection, **extra_context):\n         return super().as_sql(compiler, connection, function='RAND', **extra_context)\n \n+    def get_group_by_cols(self, alias=None):\n+        return []\n+\n \n class Round(Transform):\n     function = 'ROUND'\n",
      "tokens": 886,
      "success": true,
      "original_instance_id": "django__django-13569",
      "similarity": 0.0
    },
    {
      "instance_id": "matplotlib__matplotlib-23476_mutated_e7e94137",
      "generated_patch": "--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -2900,16 +2900,22 @@\n     def __setstate__(self, state):\n         # re-initialise some things that are not pickled\n         self.__dict__ = state\n         # re-initialise the canvas and manager\n         import matplotlib.pyplot as plt\n+        dpi = self._dpi\n         num = self.number\n         mgr = plt._backend_mod.new_figure_manager_given_figure(num, self)\n         self.canvas = mgr.canvas\n         self._cachedRenderer = None\n+        # Some backends (notably macosx on HiDPI) may adjust the figure dpi when\n+        # creating the canvas/manager.  Preserve the pickled dpi.\n+        self._dpi = dpi\n+        self.dpi_scale_trans.clear().scale(dpi)\n         self.stale = True\n         self._axobservers = cbook.CallbackRegistry()\n         self._button_pick_id = self.canvas.mpl_connect('button_press_event',\n                                                       self.pick)",
      "expected_patch": "diff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -3023,6 +3023,9 @@ def __getstate__(self):\n         # Set cached renderer to None -- it can't be pickled.\n         state[\"_cachedRenderer\"] = None\n \n+        # discard any changes to the dpi due to pixel ratio changes\n+        state[\"_dpi\"] = state.get('_original_dpi', state['_dpi'])\n+\n         # add version information to the state\n         state['__mpl_version__'] = mpl.__version__\n \n",
      "tokens": 1418,
      "success": true,
      "original_instance_id": "matplotlib__matplotlib-23476",
      "similarity": 0.0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-12585_mutated_e093c550",
      "generated_patch": "--- a/sklearn/base.py\n+++ b/sklearn/base.py\n@@ -48,7 +48,7 @@ def clone(estimator, safe=True):\n     if estimator is None:\n         return None\n-    elif not hasattr(estimator, 'get_params'):\n+    elif not hasattr(estimator, 'get_params') or isinstance(estimator, type):\n         if not safe:\n             return copy.deepcopy(estimator)\n         else:\n             raise TypeError(\"Cannot clone object '%s' (type %s): \"\n                             \"it does not seem to be a scikit-learn estimator \"\n                             \"as it does not implement a 'get_params' method.\"\n                             % (repr(estimator), type(estimator)))",
      "expected_patch": "diff --git a/sklearn/base.py b/sklearn/base.py\n--- a/sklearn/base.py\n+++ b/sklearn/base.py\n@@ -48,7 +48,7 @@ def clone(estimator, safe=True):\n     # XXX: not handling dictionaries\n     if estimator_type in (list, tuple, set, frozenset):\n         return estimator_type([clone(e, safe=safe) for e in estimator])\n-    elif not hasattr(estimator, 'get_params'):\n+    elif not hasattr(estimator, 'get_params') or isinstance(estimator, type):\n         if not safe:\n             return copy.deepcopy(estimator)\n         else:\n",
      "tokens": 567,
      "success": true,
      "original_instance_id": "scikit-learn__scikit-learn-12585",
      "similarity": 1.0
    },
    {
      "instance_id": "django__django-10999_mutated_093bff8c",
      "generated_patch": "--- a/django/utils/dateparse.py\n+++ b/django/utils/dateparse.py\n@@ -1,20 +1,20 @@\n import datetime\n import re\n \n from django.utils.regex_helper import _lazy_re_compile\n \n \n standard_date_re = _lazy_re_compile(r'^\\d{4}-\\d{1,2}-\\d{1,2}$')\n standard_time_re = _lazy_re_compile(r'^\\d{1,2}:\\d{2}(:\\d{2}(\\.\\d{1,6})?)?$')\n standard_datetime_re = _lazy_re_compile(\n     r'^\\d{4}-\\d{1,2}-\\d{1,2}[T ]\\d{1,2}:\\d{2}(:\\d{2}(\\.\\d{1,6})?)?$'\n )\n standard_duration_re = _lazy_re_compile(\n     r'^'\n     r'(?:(?P<days>-?\\d+) (days?, )?)?'\n-    r'((?:(?P<hours>-?\\d+):)(?=\\d+:\\d+))?'\n+    r'((?:(?P<hours>-?\\d+):)(?=-?\\d+:-?\\d+))?'\n     r'(?:(?P<minutes>-?\\d+):)?'\n     r'(?P<seconds>-?\\d+)'\n     r'(?:\\.(?P<microseconds>\\d{1,6})\\d{0,6})?'\n     r'$'\n )",
      "expected_patch": "diff --git a/django/utils/dateparse.py b/django/utils/dateparse.py\n--- a/django/utils/dateparse.py\n+++ b/django/utils/dateparse.py\n@@ -29,9 +29,10 @@\n standard_duration_re = re.compile(\n     r'^'\n     r'(?:(?P<days>-?\\d+) (days?, )?)?'\n-    r'((?:(?P<hours>-?\\d+):)(?=\\d+:\\d+))?'\n-    r'(?:(?P<minutes>-?\\d+):)?'\n-    r'(?P<seconds>-?\\d+)'\n+    r'(?P<sign>-?)'\n+    r'((?:(?P<hours>\\d+):)(?=\\d+:\\d+))?'\n+    r'(?:(?P<minutes>\\d+):)?'\n+    r'(?P<seconds>\\d+)'\n     r'(?:\\.(?P<microseconds>\\d{1,6})\\d{0,6})?'\n     r'$'\n )\n",
      "tokens": 639,
      "success": true,
      "original_instance_id": "django__django-10999",
      "similarity": 0.14285714285714285
    },
    {
      "instance_id": "pylint-dev__pylint-4970_mutated_2c7de2c7",
      "generated_patch": "--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -1,6 +1,7 @@\n # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html\n # For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE\n # Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt\n \n+from __future__ import annotations\n+\n from collections import defaultdict\n from collections.abc import Iterable, Iterator\n from dataclasses import dataclass\n from difflib import SequenceMatcher\n from pathlib import Path\n@@ -430,6 +431,10 @@ class SimilaritiesChecker(BaseChecker):\n     def close(self) -> None:\n         \"\"\"Called after visiting project (i.e set of modules).\"\"\"\n         if not self.linter.is_message_enabled(\"duplicate-code\"):\n             return\n+        # A value of 0 disables the duplicate code check.\n+        # This mirrors the behavior of other linters where 0 disables a numeric threshold.\n+        if self.config.min_similarity_lines <= 0:\n+            return\n         self._display = self.linter.reporter\n         self._compute_sims()\n         if self._sims:\n             self._display_sims()",
      "expected_patch": "diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -390,6 +390,8 @@ def append_stream(self, streamid: str, stream: TextIO, encoding=None) -> None:\n \n     def run(self) -> None:\n         \"\"\"start looking for similarities and display results on stdout\"\"\"\n+        if self.min_lines == 0:\n+            return\n         self._display_sims(self._compute_sims())\n \n     def _compute_sims(self) -> List[Tuple[int, Set[LinesChunkLimits_T]]]:\n",
      "tokens": 523,
      "success": true,
      "original_instance_id": "pylint-dev__pylint-4970",
      "similarity": 0.5
    },
    {
      "instance_id": "django__django-12965_mutated_e2688b2b",
      "generated_patch": "--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -1990,6 +1990,10 @@\n         # If we have a single table and no where clause, we can use a simple\n         # delete query.\n         if (\n+            # Avoid generating a self-referencing subquery for unconditional\n+            # deletes, which is a performance regression on MySQL/MariaDB and\n+            # breaks LOCK TABLES usage.\n+            not self.query.where\n+            and\n             self.query.can_filter()\n             and not self.query.distinct\n             and not self.query.select_for_update\n             and not self.query.select_related\n             and not self.query.extra_select\n             and not self.query.annotation_select\n             and not self.query.combinator\n             and not self.query.subquery\n             and not self.query.has_select_fields\n             and not self.query.has_select_related\n             and not self.query.has_filters\n             and not self.query.has_aggregates\n             and not self.query.has_group_by\n             and not self.query.has_ordering\n             and not self.query.has_limits\n             and not self.query.has_distinct_fields\n             and not self.query.has_select_for_update\n             and not self.query.has_select_related\n             and not self.query.has_extra_select\n             and not self.query.has_annotation_select\n             and not self.query.has_combinator\n             and not self.query.has_subquery\n             and not self.query.has_select_fields\n         ):\n             return self._as_sql(self.query.get_meta().db_table, self.query.where)\n \n         # Otherwise, we need to use a subquery to select the primary keys of\n         # the objects to delete.\n         return self._as_sql(self.query.get_meta().db_table, self.query.where, self.query)",
      "expected_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -1407,6 +1407,8 @@ def execute_sql(self, returning_fields=None):\n class SQLDeleteCompiler(SQLCompiler):\n     @cached_property\n     def single_alias(self):\n+        # Ensure base table is in aliases.\n+        self.query.get_initial_alias()\n         return sum(self.query.alias_refcount[t] > 0 for t in self.query.alias_map) == 1\n \n     def _as_sql(self, query):\n",
      "tokens": 1146,
      "success": true,
      "original_instance_id": "django__django-12965",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-9296_mutated_9bb61827",
      "generated_patch": "--- a/django/core/paginator.py\n+++ b/django/core/paginator.py\n@@ -1,6 +1,7 @@\n \"\"\"\n Pagination utilities.\n \"\"\"\n \n from math import ceil\n \n from django.utils.functional import cached_property\n@@ -55,6 +56,10 @@ class Paginator:\n         self.orphans = int(orphans)\n         self.allow_empty_first_page = allow_empty_first_page\n \n+    def __iter__(self):\n+        for page_num in self.page_range:\n+            yield self.page(page_num)\n+\n     def validate_number(self, number):\n         \"\"\"Validate the given 1-based page number.\"\"\"\n         try:",
      "expected_patch": "diff --git a/django/core/paginator.py b/django/core/paginator.py\n--- a/django/core/paginator.py\n+++ b/django/core/paginator.py\n@@ -34,6 +34,10 @@ def __init__(self, object_list, per_page, orphans=0,\n         self.orphans = int(orphans)\n         self.allow_empty_first_page = allow_empty_first_page\n \n+    def __iter__(self):\n+        for page_number in self.page_range:\n+            yield self.page(page_number)\n+\n     def validate_number(self, number):\n         \"\"\"Validate the given 1-based page number.\"\"\"\n         try:\n",
      "tokens": 319,
      "success": true,
      "original_instance_id": "django__django-9296",
      "similarity": 0.5
    },
    {
      "instance_id": "django__django-12193_mutated_adb3ef05",
      "generated_patch": "--- a/django/contrib/postgres/forms/array.py\n+++ b/django/contrib/postgres/forms/array.py\n@@ -1,6 +1,7 @@\n from django import forms\n from django.core.exceptions import ValidationError\n from django.forms.utils import ErrorList\n+from django.utils.datastructures import MultiValueDict\n from django.utils.translation import gettext_lazy as _\n \n \n@@ -198,7 +199,7 @@ class SplitArrayWidget(forms.Widget):\n     def get_context(self, name, value, attrs):\n         context = super().get_context(name, value, attrs)\n         if value is None:\n             value = []\n-        final_attrs = context[\"widget\"][\"attrs\"]\n+        final_attrs = MultiValueDict(context[\"widget\"][\"attrs\"])\n         id_ = final_attrs.get(\"id\")\n         context[\"widget\"][\"subwidgets\"] = []\n         for i in range(max(len(value), self.size)):",
      "expected_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -522,9 +522,7 @@ def format_value(self, content):\n \n     def fetch_context(self, name, content, attrs):\n         if self.check_test(content):\n-            if attrs is None:\n-                attrs = {}\n-            attrs['checked'] = True\n+            attrs = {**(attrs or {}), 'checked': True}\n         return super().fetch_context(name, content, attrs)\n \n     def value_from_datadict(self, payload, files, name):\n",
      "tokens": 438,
      "success": true,
      "original_instance_id": "django__django-12193",
      "similarity": 0.0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-10908_mutated_f0722510",
      "generated_patch": "--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -1458,11 +1458,13 @@ class CountVectorizer(_VectorizerMixin, BaseEstimator):\n         return X\n \n     def get_feature_names_out(self, input_features=None):\n-        check_is_fitted(self, \"vocabulary_\")\n+        # If a fixed vocabulary was provided at init time, allow feature name\n+        # retrieval without calling fit/transform first.\n+        self._validate_vocabulary()\n \n         if input_features is not None:\n             raise ValueError(\"input_features is not supported.\")\n \n         return np.asarray(\n             [t for t, i in sorted(self.vocabulary_.items(), key=itemgetter(1))],\n             dtype=object,\n         )",
      "expected_patch": "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -971,6 +971,9 @@ def inverse_transform(self, X):\n \n     def get_feature_names(self):\n         \"\"\"Array mapping from feature integer indices to feature name\"\"\"\n+        if not hasattr(self, 'vocabulary_'):\n+            self._check_vocabulary()\n+\n         self._check_vocabulary()\n \n         return [t for t, i in sorted(six.iteritems(self.vocabulary_),\n",
      "tokens": 774,
      "success": true,
      "original_instance_id": "scikit-learn__scikit-learn-10908",
      "similarity": 0.3333333333333333
    },
    {
      "instance_id": "django__django-11211_mutated_d7df05fd",
      "generated_patch": "--- a/django/contrib/contenttypes/fields.py\n+++ b/django/contrib/contenttypes/fields.py\n@@ -1,6 +1,7 @@\n from collections import defaultdict\n \n from django.apps import apps\n+from django.db import models\n from django.contrib.contenttypes.models import ContentType\n from django.core import checks\n from django.core.exceptions import FieldDoesNotExist\n@@ -160,6 +161,18 @@ class GenericForeignKey(FieldCacheMixin, Field):\n     def get_content_type(self, obj=None, id=None, using=None):\n         return ContentType.objects.db_manager(using).get_for_id(id)\n \n+    def _convert_object_id(self, ct, object_id):\n+        \"\"\"\n+        Convert the stored object_id value to the correct Python type for the\n+        related model's primary key.\n+        \"\"\"\n+        if object_id is None:\n+            return None\n+        try:\n+            pk_field = ct.model_class()._meta.pk\n+        except Exception:\n+            return object_id\n+        return pk_field.to_python(object_id)\n+\n     def get_prefetch_queryset(self, instances, queryset=None):\n         if queryset is not None:\n             raise ValueError(\"Custom queryset can't be used for this lookup.\")\n@@ -170,7 +183,7 @@ class GenericForeignKey(FieldCacheMixin, Field):\n         # For efficiency, group the instances by content type and then do one\n         # query per model.\n         fk_dict = defaultdict(set)\n-        for instance in instances:\n+        for instance in instances:\n             ct_id = getattr(instance, self.ct_field)\n             if ct_id is not None:\n                 fk_val = getattr(instance, self.fk_field)\n@@ -178,7 +191,7 @@ class GenericForeignKey(FieldCacheMixin, Field):\n                     fk_dict[ct_id].add(fk_val)\n \n         ret = []\n-        for ct_id, fkeys in fk_dict.items():\n+        for ct_id, fkeys in fk_dict.items():\n             ct = self.get_content_type(id=ct_id, using=using)\n             model = ct.model_class()\n             if model is None:\n@@ -186,7 +199,12 @@ class GenericForeignKey(FieldCacheMixin, Field):\n             # Use the base manager so that the query is not filtered by default\n             # manager.\n             qs = model._base_manager.db_manager(using).all()\n-            ret.extend(qs.filter(pk__in=fkeys))\n+            converted_fkeys = []\n+            for fk in fkeys:\n+                try:\n+                    converted_fkeys.append(self._convert_object_id(ct, fk))\n+                except (ValidationError, ValueError, TypeError):\n+                    continue\n+            ret.extend(qs.filter(pk__in=converted_fkeys))\n \n         def rel_obj_attr(rel_obj):\n             return (rel_obj._meta.pk.get_prep_value(rel_obj.pk), rel_obj._meta.model)\n@@ -194,7 +212,11 @@ class GenericForeignKey(FieldCacheMixin, Field):\n         def instance_attr(instance):\n             ct_id = getattr(instance, self.ct_field)\n             if ct_id is None:\n                 return None\n             ct = self.get_content_type(id=ct_id, using=using)\n-            return (getattr(instance, self.fk_field), ct.model_class())\n+            try:\n+                obj_id = self._convert_object_id(ct, getattr(instance, self.fk_field))\n+            except (ValidationError, ValueError, TypeError):\n+                obj_id = getattr(instance, self.fk_field)\n+            return (obj_id, ct.model_class())\n \n         return (\n             ret,\n             rel_obj_attr,\n             instance_attr,\n             False,\n             self.name,\n         )",
      "expected_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -2325,6 +2325,10 @@ def deconstruct(self):\n     def fetch_internal_type(self):\n         return \"UUIDField\"\n \n+    def fetch_prep_value(self, content):\n+        content = super().fetch_prep_value(content)\n+        return self.to_python(content)\n+\n     def fetch_db_prep_value(self, content, connection, prepared=False):\n         if content is None:\n             return None\n",
      "tokens": 1088,
      "success": true,
      "original_instance_id": "django__django-11211",
      "similarity": 0.25
    },
    {
      "instance_id": "django__django-16667_mutated_dcbd8af9",
      "generated_patch": "--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -1154,7 +1154,10 @@ class SelectDateWidget(Widget):\n         if y and m and d:\n             input_format = get_format(\"DATE_INPUT_FORMATS\")[0]\n             try:\n-                date_value = datetime.date(int(y), int(m), int(d))\n+                date_value = datetime.date(int(y), int(m), int(d))\n             except ValueError:\n                 return data.get(name)\n+            except OverflowError:\n+                return data.get(name)\n             return date_value.strftime(input_format)\n         return data.get(name)",
      "expected_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -1161,6 +1161,8 @@ def value_from_datadict(self, data, files, name):\n                 # Return pseudo-ISO dates with zeros for any unselected values,\n                 # e.g. '2017-0-23'.\n                 return \"%s-%s-%s\" % (y or 0, m or 0, d or 0)\n+            except OverflowError:\n+                return \"0-0-0\"\n             return date_value.strftime(input_format)\n         return data.get(name)\n \n",
      "tokens": 651,
      "success": true,
      "original_instance_id": "django__django-16667",
      "similarity": 0.5
    },
    {
      "instance_id": "pydata__xarray-2905_mutated_fa30f2ac",
      "generated_patch": "--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -1,6 +1,7 @@\n from __future__ import annotations\n \n import functools\n+import numpy as np\n import operator\n import warnings\n from collections.abc import Hashable, Iterable, Mapping, Sequence\n from typing import TYPE_CHECKING, Any, Callable, Generic, NoReturn, TypeVar, cast\n@@ -638,12 +639,22 @@ class Variable(NamedArray, AbstractArray, VariableArithmetic):\n         if isinstance(value, Variable):\n             value = value.data\n \n-        # convert value to ndarray\n-        value = as_compatible_data(value)\n+        # convert value to ndarray\n+        # NOTE: for object arrays, avoid coercing arbitrary Python objects that\n+        # happen to define a `.values` attribute (e.g. lmfit ModelResult).\n+        # Only coerce to `.values` for array-like objects; otherwise preserve\n+        # the object itself.\n+        if self.dtype == object and not isinstance(value, (np.ndarray, Variable)):\n+            values_attr = getattr(value, \"values\", None)\n+            if values_attr is not None and not isinstance(values_attr, (np.ndarray, list, tuple)):\n+                value = np.asarray(value, dtype=object)\n+            else:\n+                value = as_compatible_data(value)\n+        else:\n+            value = as_compatible_data(value)\n \n         # broadcast value to the shape of the indexed result\n         if value.ndim > 0:\n             value = broadcast_to(value, self._broadcast_indexes(key).shape)",
      "expected_patch": "diff --git a/xarray/core/variable.py b/xarray/core/variable.py\n--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -218,7 +218,8 @@ def as_compatible_data(data, fastpath=False):\n         data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n \n     # we don't want nested self-described arrays\n-    data = getattr(data, \"values\", data)\n+    if isinstance(data, (pd.Series, pd.Index, pd.DataFrame)):\n+        data = data.values\n \n     if isinstance(data, np.ma.MaskedArray):\n         mask = np.ma.getmaskarray(data)\n",
      "tokens": 1094,
      "success": true,
      "original_instance_id": "pydata__xarray-2905",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-14493_mutated_2f52c3d9",
      "generated_patch": "--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -235,6 +235,7 @@\n         # Post process the files to update the references to the hashed files.\n         hashed_files = {}\n         processed_files = set()\n+        substitutions = False\n         for i in range(self.max_post_process_passes):\n             substitutions = False\n             for name, hashed_name, processed in super().post_process(\n                 paths, dry_run=dry_run, **options\n             ):\n                 yield name, hashed_name, processed\n                 processed_files.add(name)\n                 if not processed:\n                     continue\n                 hashed_files[name] = hashed_name\n                 substitutions = True\n             if not substitutions:\n                 break\n         if substitutions:\n             raise RuntimeError(\n                 \"Max post-process passes exceeded. \"\n                 \"This may be due to circular references in your CSS files.\"\n             )",
      "expected_patch": "diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py\n--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -260,6 +260,7 @@ def post_process(self, paths, dry_run=False, **options):\n                 processed_adjustable_paths[name] = (name, hashed_name, processed)\n \n         paths = {path: paths[path] for path in adjustable_paths}\n+        substitutions = False\n \n         for i in range(self.max_post_process_passes):\n             substitutions = False\n",
      "tokens": 644,
      "success": true,
      "original_instance_id": "django__django-14493",
      "similarity": 1.0
    },
    {
      "instance_id": "sphinx-doc__sphinx-9230_mutated_b67f6248",
      "generated_patch": "--- a/sphinx/util/docfields.py\n+++ b/sphinx/util/docfields.py\n@@ -1,6 +1,7 @@\n \"\"\"Docfields utilities.\"\"\"\n \n from __future__ import annotations\n+import re\n \n from collections import defaultdict\n from typing import TYPE_CHECKING, Any, NamedTuple\n \n@@ -34,6 +35,17 @@ if TYPE_CHECKING:\n     from sphinx.environment import BuildEnvironment\n \n \n+_param_type_re = re.compile(r'^(.+?)\\s+([A-Za-z_]\\w*)$')\n+\n+\n+def _split_param_type_and_name(arg: str) -> tuple[str, str] | None:\n+    arg = arg.strip()\n+    m = _param_type_re.match(arg)\n+    if m:\n+        return m.group(1).strip(), m.group(2).strip()\n+    return None\n+\n+\n class Field(NamedTuple):\n     name: str\n     label: str\n@@ -276,10 +288,17 @@ class TypedField(Field):\n             # type and name are given in the same field\n             # e.g. :param int foo: description\n             arg = fieldarg.strip()\n-            if ' ' in arg:\n-                typ, name = arg.split(None, 1)\n-                types[name] = [typ]\n-                fieldarg = name\n+            split = _split_param_type_and_name(arg)\n+            if split:\n+                typ, name = split\n+                # Only treat the first token as a type if it looks like a simple\n+                # identifier. This avoids breaking types containing spaces, e.g.\n+                # \"dict(str, str) opc_meta\".\n+                if typ.isidentifier():\n+                    types[name] = [typ]\n+                    fieldarg = name\n \n         # collect the content, trying not to keep unnecessary paragraphs\n         content = nodes.inline()",
      "expected_patch": "diff --git a/sphinx/util/docfields.py b/sphinx/util/docfields.py\n--- a/sphinx/util/docfields.py\n+++ b/sphinx/util/docfields.py\n@@ -298,7 +298,7 @@ def transform(self, node: nodes.field_list) -> None:\n             # also support syntax like ``:param type name:``\n             if typedesc.is_typed:\n                 try:\n-                    argtype, argname = fieldarg.split(None, 1)\n+                    argtype, argname = fieldarg.rsplit(None, 1)\n                 except ValueError:\n                     pass\n                 else:\n",
      "tokens": 855,
      "success": true,
      "original_instance_id": "sphinx-doc__sphinx-9230",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-11163_mutated_8e35b7e2",
      "generated_patch": "--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -98,7 +98,7 @@ def model_to_dict(instance, fields=None, exclude=None):\n     for f in chain(opts.concrete_fields, opts.private_fields, opts.many_to_many):\n         if not getattr(f, 'editable', False):\n             continue\n-        if fields and f.name not in fields:\n+        if fields is not None and f.name not in fields:\n             continue\n         if exclude and f.name in exclude:\n             continue\n         data[f.name] = f.value_from_object(instance)",
      "expected_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -83,7 +83,7 @@ def model_to_dict(instance, fields=None, exclude=None):\n     for f in chain(opts.concrete_fields, opts.private_fields, opts.many_to_many):\n         if not getattr(f, 'editable', False):\n             continue\n-        if fields and f.name not in fields:\n+        if fields is not None and f.name not in fields:\n             continue\n         if exclude and f.name in exclude:\n             continue\n",
      "tokens": 313,
      "success": true,
      "original_instance_id": "django__django-11163",
      "similarity": 1.0
    },
    {
      "instance_id": "django__django-14580_mutated_3adb2e45",
      "generated_patch": "--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -1,6 +1,7 @@\n import datetime\n import os\n import re\n+import django.db.models\n from importlib import import_module\n \n from django.apps import apps\n@@ -150,6 +151,8 @@ class MigrationWriter:\n         self.needs_manual_porting = False\n         self.imports = set()\n         self.from_imports = {}\n+        # Always import models to support references like models.Foo in bases.\n+        self.imports.add(\"from django.db import models\")\n         self.indentation = indentation\n \n     def as_string(self):",
      "expected_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -273,7 +273,7 @@ def _format(self):\n class TypeSerializer(BaseSerializer):\n     def serialize(self):\n         special_cases = [\n-            (models.Model, \"models.Model\", []),\n+            (models.Model, \"models.Model\", ['from django.db import models']),\n             (type(None), 'type(None)', []),\n         ]\n         for case, string, imports in special_cases:\n",
      "tokens": 620,
      "success": true,
      "original_instance_id": "django__django-14580",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-16255_mutated_1a2a6b86",
      "generated_patch": "--- a/django/contrib/sitemaps/__init__.py\n+++ b/django/contrib/sitemaps/__init__.py\n@@ -167,7 +167,7 @@\n \t\tif callable(self.lastmod):\n \t\t\ttry:\n \t\t\t\treturn max([self.lastmod(item) for item in self.items()])\n-\t\t\texcept TypeError:\n+\t\t\texcept (TypeError, ValueError):\n \t\t\t\treturn None\n \t\telse:\n \t\t\treturn self.lastmod",
      "expected_patch": "diff --git a/django/contrib/sitemaps/__init__.py b/django/contrib/sitemaps/__init__.py\n--- a/django/contrib/sitemaps/__init__.py\n+++ b/django/contrib/sitemaps/__init__.py\n@@ -167,7 +167,7 @@ def fetch_latest_lastmod(self):\n             return None\n         if callable(self.lastmod):\n             try:\n-                return max([self.lastmod(item) for item in self.items()])\n+                return max([self.lastmod(item) for item in self.items()], default=None)\n             except TypeError:\n                 return None\n         else:\n",
      "tokens": 583,
      "success": true,
      "original_instance_id": "django__django-16255",
      "similarity": 0.0
    },
    {
      "instance_id": "sphinx-doc__sphinx-9591_mutated_00c611d4",
      "generated_patch": "--- a/sphinx/ext/autodoc/typehints.py\n+++ b/sphinx/ext/autodoc/typehints.py\n@@ -1,6 +1,7 @@\n \"\"\"Utilities for type hints.\"\"\"\n \n from __future__ import annotations\n+from typing import Any\n \n from sphinx.application import Sphinx\n from sphinx.util import inspect\n@@ -160,6 +161,20 @@ def record_typehints(app: Sphinx, objtype: str, name: str, obj: Any,\n     except (AttributeError, TypeError):\n         return\n \n+    # For properties, the return annotation is stored on the fget function.\n+    # record_typehints() is called with the property object itself, so we need\n+    # to unwrap it to access the type hints.\n+    if isinstance(obj, property):\n+        try:\n+            obj = obj.fget  # type: ignore[assignment]\n+        except Exception:\n+            return\n+        if obj is None:\n+            return\n+\n     try:\n         if objtype == 'class':\n             annotations = app.env.temp_data.setdefault('annotations', {})\n             annotations[name] = stringify_annotation(obj)  # type: ignore[arg-type]\n         else:\n             annotations = app.env.temp_data.setdefault('annotations', {})\n             for key, value in get_type_hints(obj, None, None).items():\n                 if key == 'return':\n                     annotations[name] = stringify_annotation(value)\n                 else:\n                     annotations['%s.%s' % (name, key)] = stringify_annotation(value)\n     except (AttributeError, TypeError, KeyError):\n         pass",
      "expected_patch": "diff --git a/sphinx/domains/python.py b/sphinx/domains/python.py\n--- a/sphinx/domains/python.py\n+++ b/sphinx/domains/python.py\n@@ -861,7 +861,8 @@ def handle_signature(self, sig: str, signode: desc_signature) -> Tuple[str, str]\n \n         typ = self.options.get('type')\n         if typ:\n-            signode += addnodes.desc_annotation(typ, ': ' + typ)\n+            annotations = _analyze_annotation(typ, self.env)\n+            signode += addnodes.desc_annotation(typ, '', nodes.Text(': '), *annotations)\n \n         return fullname, prefix\n \n",
      "tokens": 905,
      "success": true,
      "original_instance_id": "sphinx-doc__sphinx-9591",
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-21612_mutated_69abc603",
      "generated_patch": "--- a/sympy/parsing/latex/_parse_latex_antlr.py\n+++ b/sympy/parsing/latex/_parse_latex_antlr.py\n@@ -1,6 +1,7 @@\n from __future__ import print_function, division\n \n from sympy import (Add, Mul, Pow, Symbol, Integer, Rational, Float, I, E, pi,\n                    oo, zoo, nan, S, Function, factorial, sqrt, sin, cos, tan,\n                    asin, acos, atan, sinh, cosh, tanh, log, exp, Abs, Matrix,\n                    ImmutableMatrix, MatrixSymbol, Derivative, Integral, Sum,\n                    Product, Limit, Eq, Ne, Lt, Le, Gt, Ge, And, Or, Not, Xor,\n                    Implies, Equivalent, Piecewise, Interval, Union, Intersection,\n                    Complement, FiniteSet, EmptySet, ImageSet, Lambda, Tuple,\n                    KroneckerDelta, DiracDelta, Heaviside, floor, ceiling, Mod,\n                    factorial2, binomial, gamma, lowergamma, uppergamma, polygamma,\n                    digamma, trigamma, zeta, polylog, erf, erfc, erfi, Ei, Si, Ci,\n                    Shi, Chi, li, Li, fresnels, fresnelc, expint, E1, E2, E3, E4,\n                    E5, E6, E7, E8, E9, E10, E11, E12, E13, E14, E15, E16, E17,\n                    E18, E19, E20, E21, E22, E23, E24, E25, E26, E27, E28, E29,\n                    E30, E31, E32, E33, E34, E35, E36, E37, E38, E39, E40, E41,\n                    E42, E43, E44, E45, E46, E47, E48, E49, E50, E51, E52, E53,\n                    E54, E55, E56, E57, E58, E59, E60, E61, E62, E63, E64, E65,\n                    E66, E67, E68, E69, E70, E71, E72, E73, E74, E75, E76, E77,\n                    E78, E79, E80, E81, E82, E83, E84, E85, E86, E87, E88, E89,\n                    E90, E91, E92, E93, E94, E95, E96, E97, E98, E99, E100)\n+from sympy.core.expr import Expr\n \n \n class _LatexParser(object):\n@@ -1042,7 +1043,12 @@\n         return self._convert_relation(ctx.relation())\n \n     def convertFrac(self, ctx):\n-        return self._convert_expr(ctx.expr(0)) / self._convert_expr(ctx.expr(1))\n+        num = self._convert_expr(ctx.expr(0))\n+        den = self._convert_expr(ctx.expr(1))\n+        # Ensure denominator stays grouped (e.g. \\frac{...}{\\frac{1}{c^2}})\n+        if isinstance(den, Expr) and den.is_Mul:\n+            den = den.parenthesize()\n+        return num / den\n \n     def convertSqrt(self, ctx):\n         if ctx.expr() is None:\n             return sqrt(self._convert_expr(ctx.group()))",
      "expected_patch": "diff --git a/sympy/printing/str.py b/sympy/printing/str.py\n--- a/sympy/printing/str.py\n+++ b/sympy/printing/str.py\n@@ -333,7 +333,7 @@ def apow(i):\n                     b.append(apow(item))\n                 else:\n                     if (len(item.args[0].args) != 1 and\n-                            isinstance(item.base, Mul)):\n+                            isinstance(item.base, (Mul, Pow))):\n                         # To avoid situations like #14160\n                         pow_paren.append(item)\n                     b.append(item.base)\n",
      "tokens": 1113,
      "success": true,
      "original_instance_id": "sympy__sympy-21612",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-12125_mutated_faf4113b",
      "generated_patch": "--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -1,6 +1,7 @@\n import builtins\n import collections.abc\n import datetime\n+import inspect\n import decimal\n import enum\n import functools\n import importlib\n@@ -268,6 +269,12 @@ class DeconstructableSerializer(BaseSerializer):\n         return self.serialize_deconstructed(path, args, kwargs)\n \n \n+def _qualname(obj):\n+    return getattr(obj, \"__qualname__\", getattr(obj, \"__name__\", obj.__class__.__name__))\n+\n+\n class FunctionTypeSerializer(BaseSerializer):\n     def serialize(self):\n         return self.serialize_deconstructed(*self.value.deconstruct())\n@@ -313,7 +320,7 @@ class TypeSerializer(BaseSerializer):\n     def serialize(self):\n         special_cases = [\n             (models.Choices, \"models.Choices\"),\n         ]\n         for case, string in special_cases:\n             if issubclass(self.value, case):\n                 return string, {\"import\": \"from django.db import models\"}\n-        return \"%s.%s\" % (self.value.__module__, self.value.__name__), {\n+        return \"%s.%s\" % (self.value.__module__, _qualname(self.value)), {\n             \"import\": \"import %s\" % self.value.__module__\n         }\n \n@@ -337,7 +344,7 @@ class ModelFieldSerializer(DeconstructableSerializer):\n class EnumSerializer(BaseSerializer):\n     def serialize(self):\n-        enum_class = self.value.__class__\n+        enum_class = self.value.__class__\n         if enum_class.__module__ == \"builtins\":\n             return repr(self.value), {}\n-        return \"%s.%s[%r]\" % (enum_class.__module__, enum_class.__name__, self.value.name), {\n+        return \"%s.%s[%r]\" % (enum_class.__module__, _qualname(enum_class), self.value.name), {\n             \"import\": \"import %s\" % enum_class.__module__\n         }\n \n@@ -345,7 +352,7 @@ class EnumSerializer(BaseSerializer):\n class EnumTypeSerializer(BaseSerializer):\n     def serialize(self):\n-        return \"%s.%s\" % (self.value.__module__, self.value.__name__), {\n+        return \"%s.%s\" % (self.value.__module__, _qualname(self.value)), {\n             \"import\": \"import %s\" % self.value.__module__\n         }\n \n@@ -353,7 +360,7 @@ class UUIDSerializer(BaseSerializer):\n class UUIDSerializer(BaseSerializer):\n     def serialize(self):\n         return \"uuid.UUID(%r)\" % str(self.value), {\"import\": \"import uuid\"}\n \n@@ -361,7 +368,7 @@ class PathSerializer(BaseSerializer):\n class PathSerializer(BaseSerializer):\n     def serialize(self):\n         return \"pathlib.%s(%r)\" % (self.value.__class__.__name__, str(self.value)), {\n             \"import\": \"import pathlib\"\n         }\n \n@@ -369,7 +376,7 @@ class RegexSerializer(BaseSerializer):\n class RegexSerializer(BaseSerializer):\n     def serialize(self):\n         return \"re.compile(%r)\" % self.value.pattern, {\"import\": \"import re\"}\n \n@@ -377,7 +384,7 @@ class LazyObjectSerializer(BaseSerializer):\n class LazyObjectSerializer(BaseSerializer):\n     def serialize(self):\n         return \"django.utils.functional.lazy(%s)\" % self.value, {\n             \"import\": \"from django.utils.functional import lazy\"\n         }",
      "expected_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -269,7 +269,7 @@ def serialize(self):\n             if module == builtins.__name__:\n                 return self.value.__name__, set()\n             else:\n-                return \"%s.%s\" % (module, self.value.__name__), {\"import %s\" % module}\n+                return \"%s.%s\" % (module, self.value.__qualname__), {\"import %s\" % module}\n \n \n class UUIDSerializer(BaseSerializer):\n",
      "tokens": 1186,
      "success": true,
      "original_instance_id": "django__django-12125",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-17087_mutated_09a54c32",
      "generated_patch": "--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -1,6 +1,7 @@\n import builtins\n import collections.abc\n import datetime\n+import inspect\n import decimal\n import enum\n import functools\n import importlib\n@@ -1,6 +1,7 @@\n import math\n import os\n import pathlib\n+import types\n import re\n import uuid\n \n@@ -1,6 +1,7 @@\n from django.conf import SettingsReference\n from django.db.migrations.utils import COMPILED_REGEX_TYPE, RegexObject\n from django.utils.functional import LazyObject, Promise\n+from django.utils.module_loading import import_string\n \n \n class BaseSerializer:\n@@ -1,6 +1,7 @@\n class FunctionTypeSerializer(BaseSerializer):\n     def serialize(self):\n         return self.serialize_deconstructed(self.value)\n \n@@ -1,6 +1,44 @@\n class FunctionTypeSerializer(BaseSerializer):\n     def serialize(self):\n-        return self.serialize_deconstructed(self.value)\n+        # Handle classmethods/staticmethods defined on nested classes.\n+        # In such cases, the function's __module__ and __qualname__ include the\n+        # full path (e.g. \"Profile.Capability.default\"), but the function's\n+        # __name__ alone (\"default\") isn't enough to reconstruct the correct\n+        # dotted path for migrations.\n+        if isinstance(self.value, (types.FunctionType, types.BuiltinFunctionType)):\n+            module = getattr(self.value, \"__module__\", None)\n+            qualname = getattr(self.value, \"__qualname__\", None)\n+            if module and qualname and \".\" in qualname:\n+                dotted_path = f\"{module}.{qualname}\"\n+                try:\n+                    if import_string(dotted_path) is self.value:\n+                        return dotted_path, {\"imports\": {f\"import {module}\"}}\n+                except Exception:\n+                    pass\n+        return self.serialize_deconstructed(self.value)\n \n@@ -1,6 +1,7 @@\n class MethodTypeSerializer(BaseSerializer):\n     def serialize(self):\n         method = self.value\n         module = method.__module__\n-        return \"%s.%s\" % (module, method.__qualname__), {\"imports\": {\"import %s\" % module}}\n+        return \"%s.%s\" % (module, method.__qualname__), {\"imports\": {\"import %s\" % module}}",
      "expected_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -168,7 +168,7 @@ def serialize(self):\n         ):\n             klass = self.value.__self__\n             module = klass.__module__\n-            return \"%s.%s.%s\" % (module, klass.__name__, self.value.__name__), {\n+            return \"%s.%s.%s\" % (module, klass.__qualname__, self.value.__name__), {\n                 \"import %s\" % module\n             }\n         # Further issue checking\n",
      "tokens": 880,
      "success": true,
      "original_instance_id": "django__django-17087",
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-13480_mutated_42f09e10",
      "generated_patch": "--- a/sympy/functions/elementary/hyperbolic.py\n+++ b/sympy/functions/elementary/hyperbolic.py\n@@ -587,7 +587,7 @@\n         if arg is S.ComplexInfinity:\n             return S.NaN\n \n-        cotm = cot(arg)\n-        if cotm is S.ComplexInfinity:\n+        cotm = cot(arg)\n+        if cotm is S.ComplexInfinity:\n             return S.NaN\n         if cotm.is_zero:\n             return S.Zero\n@@ -590,7 +590,7 @@\n         if cotm.is_infinite:\n             return S.NaN\n \n-        if cotm.is_number:\n+        if cotm.is_number:\n             return coth(log(cotm))\n \n         # coth(log(tan(x))) -> coth(log(tan(x))) (no change)\n@@ -587,7 +587,7 @@\n         if arg is S.ComplexInfinity:\n             return S.NaN\n \n-        cotm = cot(arg)\n-        if cotm is S.ComplexInfinity:\n+        cotm = cot(arg)\n+        if cotm is S.ComplexInfinity:\n             return S.NaN\n         if cotm.is_zero:\n             return S.Zero\n@@ -587,7 +587,7 @@\n         if arg is S.ComplexInfinity:\n             return S.NaN\n \n-        cotm = cot(arg)\n-        if cotm is S.ComplexInfinity:\n+        cot_arg = cot(arg)\n+        if cot_arg is S.ComplexInfinity:\n             return S.NaN\n-        if cotm.is_zero:\n+        if cot_arg.is_zero:\n             return S.Zero\n-        if cotm.is_infinite:\n+        if cot_arg.is_infinite:\n             return S.NaN\n \n-        if cotm.is_number:\n-            return coth(log(cotm))\n+        if cot_arg.is_number:\n+            return coth(log(cot_arg))\n \n         # coth(log(tan(x))) -> coth(log(tan(x))) (no change)",
      "expected_patch": "diff --git a/sympy/functions/elementary/hyperbolic.py b/sympy/functions/elementary/hyperbolic.py\n--- a/sympy/functions/elementary/hyperbolic.py\n+++ b/sympy/functions/elementary/hyperbolic.py\n@@ -587,7 +587,7 @@ def eval(cls, arg):\n                 x, m = _peeloff_ipi(arg)\n                 if m:\n                     cothm = coth(m)\n-                    if cotm is S.ComplexInfinity:\n+                    if cothm is S.ComplexInfinity:\n                         return coth(x)\n                     else: # cothm == 0\n                         return tanh(x)\n",
      "tokens": 676,
      "success": true,
      "original_instance_id": "sympy__sympy-13480",
      "similarity": 0.5
    },
    {
      "instance_id": "pylint-dev__pylint-6903_mutated_7ba38388",
      "generated_patch": "--- a/pylint/lint/run.py\n+++ b/pylint/lint/run.py\n@@ -49,16 +49,16 @@\n def _query_cpu() -> int:\n     \"\"\"Determine number of CPUs in the system.\"\"\"\n     try:\n         with open(\"/sys/fs/cgroup/cpu/cpu.cfs_quota_us\", encoding=\"utf-8\") as file:\n             quota = int(file.read())\n         with open(\"/sys/fs/cgroup/cpu/cpu.cfs_period_us\", encoding=\"utf-8\") as file:\n             period = int(file.read())\n         if quota != -1 and period != -1:\n-            return int(quota / period)\n+            return max(1, int(quota / period))\n         with open(\"/sys/fs/cgroup/cpu/cpu.shares\", encoding=\"utf-8\") as file:\n             shares = int(file.read())\n-        return int(shares / 1024)\n+        return max(1, int(shares / 1024))\n     except OSError:\n         return multiprocessing.cpu_count()",
      "expected_patch": "diff --git a/pylint/lint/run.py b/pylint/lint/run.py\n--- a/pylint/lint/run.py\n+++ b/pylint/lint/run.py\n@@ -58,6 +58,13 @@ def _query_cpu() -> int | None:\n             cpu_shares = int(file.read().rstrip())\n         # For AWS, gives correct content * 1024.\n         avail_cpu = int(cpu_shares / 1024)\n+\n+    # In K8s Pods also a fraction of a single core could be available\n+    # As multiprocessing is not able to run only a \"fraction\" of process\n+    # assume we have 1 CPU available\n+    if avail_cpu == 0:\n+        avail_cpu = 1\n+\n     return avail_cpu\n \n \n",
      "tokens": 1158,
      "success": true,
      "original_instance_id": "pylint-dev__pylint-6903",
      "similarity": 0.0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-14053_mutated_3391e668",
      "generated_patch": "--- a/sklearn/tree/export.py\n+++ b/sklearn/tree/export.py\n@@ -1,6 +1,7 @@\n \"\"\"Utilities to export decision trees.\"\"\"\n \n # Authors: The scikit-learn developers\n+# SPDX-License-Identifier: BSD-3-Clause\n \n import numpy as np\n \n@@ -840,10 +841,12 @@ def export_text(decision_tree, feature_names=None, max_depth=10,\n     if feature_names is not None:\n         if len(feature_names) != n_features:\n             raise ValueError(\"feature_names must contain %d elements, got %d\"\n                              % (n_features, len(feature_names)))\n-        feature_names_ = feature_names\n+        feature_names_ = list(feature_names)\n     else:\n-        feature_names_ = [\"feature_%d\" % i for i in range(n_features)]\n+        feature_names_ = [\"feature_%d\" % i for i in range(n_features)]\n+    if len(feature_names_) == 1:\n+        feature_names_.append(feature_names_[0])\n \n     # Build the tree representation\n     tree_ = decision_tree.tree_\n     feature = tree_.feature\n     threshold = tree_.threshold",
      "expected_patch": "diff --git a/sklearn/tree/export.py b/sklearn/tree/export.py\n--- a/sklearn/tree/export.py\n+++ b/sklearn/tree/export.py\n@@ -890,7 +890,8 @@ def export_text(decision_tree, feature_names=None, max_depth=10,\n         value_fmt = \"{}{} value: {}\\n\"\n \n     if feature_names:\n-        feature_names_ = [feature_names[i] for i in tree_.feature]\n+        feature_names_ = [feature_names[i] if i != _tree.TREE_UNDEFINED\n+                          else None for i in tree_.feature]\n     else:\n         feature_names_ = [\"feature_{}\".format(i) for i in tree_.feature]\n \n",
      "tokens": 1163,
      "success": true,
      "original_instance_id": "scikit-learn__scikit-learn-14053",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-11964_mutated_8a1fb84b",
      "generated_patch": "--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -1,6 +1,7 @@\n import copy\n import datetime\n import decimal\n+import enum\n import operator\n import uuid\n import warnings\n@@ -1048,6 +1049,8 @@ class Field(RegisterLookupMixin):\n         return value\n \n     def get_prep_value(self, value):\n+        if isinstance(value, enum.Enum):\n+            value = value.value\n         value = super().get_prep_value(value)\n         if value is None:\n             return None",
      "expected_patch": "diff --git a/django/db/models/enums.py b/django/db/models/enums.py\n--- a/django/db/models/enums.py\n+++ b/django/db/models/enums.py\n@@ -60,7 +60,13 @@ def values(cls):\n \n class Choices(enum.Enum, metaclass=ChoicesMeta):\n     \"\"\"Class for creating enumerated choices.\"\"\"\n-    pass\n+\n+    def __str__(self):\n+        \"\"\"\n+        Use content when cast to str, so that Choices set as schema instance\n+        attributes are rendered as expected in templates and similar contexts.\n+        \"\"\"\n+        return str(self.content)\n \n \n class IntegerChoices(int, Choices):\n",
      "tokens": 735,
      "success": true,
      "original_instance_id": "django__django-11964",
      "similarity": 0.0
    },
    {
      "instance_id": "pydata__xarray-4695_mutated_8511b152",
      "generated_patch": "--- a/xarray/core/indexing.py\n+++ b/xarray/core/indexing.py\n@@ -1,6 +1,7 @@\n from __future__ import annotations\n \n from collections.abc import Hashable, Mapping\n+from typing import Any\n \n import numpy as np\n \n@@ -520,13 +521,20 @@ class _LocIndexer:\n     def __getitem__(self, key):\n         if not isinstance(key, Mapping):\n             raise TypeError(\"can only lookup dictionaries from .loc\")\n-        return self.data_array.sel(**key)\n+        # Avoid passing dimension names that collide with keyword-only\n+        # arguments of DataArray.sel (e.g. \"method\", \"tolerance\", \"drop\").\n+        # Using a dict for indexers ensures all keys are treated as indexers.\n+        return self.data_array.sel(indexers=dict(key))\n \n     def __setitem__(self, key, value):\n         if not isinstance(key, Mapping):\n             raise TypeError(\"can only set dictionaries from .loc\")\n-        self.data_array.loc[key] = value\n+        self.data_array.loc[dict(key)] = value",
      "expected_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -196,7 +196,7 @@ def __getitem__(self, identifier) -> \"DataArray\":\n             # expand the indexer so we can handle Ellipsis\n             labels = indexing.expanded_indexer(identifier, self.data_array.ndim)\n             identifier = dict(zip(self.data_array.dims, labels))\n-        return self.data_array.sel(**identifier)\n+        return self.data_array.sel(identifier)\n \n     def __setitem__(self, identifier, value) -> None:\n         if not utils.is_dict_like(identifier):\n",
      "tokens": 1610,
      "success": true,
      "original_instance_id": "pydata__xarray-4695",
      "similarity": 0.5
    },
    {
      "instance_id": "django__django-10097_mutated_0f9c4847",
      "generated_patch": "--- a/django/core/validators.py\n+++ b/django/core/validators.py\n@@ -1,6 +1,7 @@\n import ipaddress\n import re\n from pathlib import Path\n+from urllib.parse import unquote\n \n from django.core.exceptions import ValidationError\n from django.utils.deconstruct import deconstructible\n@@ -88,6 +89,7 @@ class URLValidator(RegexValidator):\n     ul = '\\u00a1-\\uffff'  # Unicode letters range (must not be a raw string).\n \n     # IP patterns\n     ipv4_re = r'(?:25[0-5]|2[0-4]\\d|[0-1]?\\d?\\d)(?:\\.(?:25[0-5]|2[0-4]\\d|[0-1]?\\d?\\d)){3}'\n@@ -112,7 +114,7 @@ class URLValidator(RegexValidator):\n     # Host patterns\n     hostname_re = r'[a-z' + ul + r'0-9](?:[a-z' + ul + r'0-9-]{0,61}[a-z' + ul + r'0-9])?'\n     # Max length for domain name labels is 63 characters per RFC 1034 sec. 3.1.\n     domain_re = r'(?:\\.(?!-)[a-z' + ul + r'0-9-]{1,63}(?<!-))*'\n     tld_re = (\n         r'\\.'                                # dot\n         r'(?!-)'                             # can't start with a dash\n         r'(?:[a-z' + ul + r'-]{2,63}'         # domain label\n         r'|xn--[a-z0-9]{1,59})'               # or punycode label\n         r'(?<!-)'                             # can't end with a dash\n         r'\\.?'                                # may have a trailing dot\n     )\n     host_re = '(' + hostname_re + domain_re + tld_re + '|localhost)'\n \n     regex = re.compile(\n         r'^(?:[a-z0-9.+-]*)://'  # scheme is validated separately\n-        r'(?:[^\\s:@/]+(?::[^\\s:@/]*)?@)?'  # user:pass authentication\n+        r'(?:[^\\s:@/]+(?::[^\\s:@/]*)?@)?'  # user:pass authentication (validated further in __call__)\n         r'(?:' + ipv4_re + '|' + ipv6_re + '|' + host_re + ')'\n         r'(?::\\d{2,5})?'  # port\n         r'(?:[/?#][^\\s]*)?'  # resource path\n         r'\\Z', re.IGNORECASE)\n@@ -152,6 +154,22 @@ class URLValidator(RegexValidator):\n         if not scheme:\n             raise ValidationError(self.message, code=self.code, params={'value': value})\n         if scheme not in self.schemes:\n             raise ValidationError(self.message, code=self.code, params={'value': value})\n+        # RFC 1738 section 3.1: within user and password, any \":\", \"@\", or \"/\"\n+        # must be percent-encoded. Reject unencoded occurrences.\n+        if '://' in value:\n+            rest = value.split('://', 1)[1]\n+            if '@' in rest:\n+                userinfo = rest.split('@', 1)[0]\n+                decoded = unquote(userinfo)\n+                if any(c in decoded for c in (':', '@', '/')):\n+                    raise ValidationError(self.message, code=self.code, params={'value': value})\n         super().__call__(value)",
      "expected_patch": "diff --git a/django/core/validators.py b/django/core/validators.py\n--- a/django/core/validators.py\n+++ b/django/core/validators.py\n@@ -94,7 +94,7 @@ class URLValidator(RegexValidator):\n \n     regex = _lazy_re_compile(\n         r'^(?:[a-z0-9\\.\\-\\+]*)://'  # scheme is validated separately\n-        r'(?:\\S+(?::\\S*)?@)?'  # account:pass authentication\n+        r'(?:[^\\s:@/]+(?::[^\\s:@/]*)?@)?'  # account:pass authentication\n         r'(?:' + ipv4_re + '|' + ipv6_re + '|' + host_re + ')'\n         r'(?::\\d{2,5})?'  # port\n         r'(?:[/?#][^\\s]*)?'  # resource path\n",
      "tokens": 1453,
      "success": true,
      "original_instance_id": "django__django-10097",
      "similarity": 0.5
    },
    {
      "instance_id": "django__django-12273_mutated_d43898db",
      "generated_patch": "--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -1,6 +1,7 @@\n import copy\n import inspect\n import itertools\n+import warnings\n import operator\n import sys\n import threading\n@@ -1040,6 +1041,14 @@ class Model(metaclass=ModelBase):\n         \"\"\"\n         self._prepare_related_fields_for_save(operation_name=\"save\")\n \n+        # If the primary key is reset on a multi-table inherited child instance,\n+        # ensure the parent link field is also reset so the save creates a new\n+        # parent row instead of overwriting the existing one.\n+        if self._meta.parents and self.pk is None:\n+            for parent, parent_link in self._meta.parents.items():\n+                setattr(self, parent_link.attname, None)\n+\n         using = using or router.db_for_write(self.__class__, instance=self)\n         if force_insert and (force_update or update_fields):\n             raise ValueError(\"Cannot force both insert and updating in model saving.\")\n@@ -1096,6 +1105,9 @@ class Model(metaclass=ModelBase):\n         if not meta.auto_created:\n             pre_save.send(sender=origin, instance=self, raw=raw, using=using,\n                           update_fields=update_fields)\n+        if meta.parents and self.pk is None:\n+            for parent, parent_link in meta.parents.items():\n+                setattr(self, parent_link.attname, None)\n \n         # A transaction isn't needed if one query is issued.\n         if meta.parents:\n             context_manager = transaction.atomic(using=using, savepoint=False)",
      "expected_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -569,6 +569,9 @@ def _get_pk_val(self, meta=None):\n         return getattr(self, meta.pk.attname)\n \n     def _assign_pk_val(self, value):\n+        for parent_link in self._meta.parents.values():\n+            if parent_link and parent_link != self._meta.pk:\n+                setattr(self, parent_link.target_field.attname, value)\n         return setattr(self, self._meta.pk.attname, value)\n \n     pk = property(_get_pk_val, _assign_pk_val)\n",
      "tokens": 657,
      "success": true,
      "original_instance_id": "django__django-12273",
      "similarity": 0.0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-13779_mutated_937292f8",
      "generated_patch": "--- a/sklearn/ensemble/_voting.py\n+++ b/sklearn/ensemble/_voting.py\n@@ -1,6 +1,7 @@\n \"\"\"Voting Classifier and Regressor.\"\"\"\n \n # Authors: The scikit-learn developers\n+# SPDX-License-Identifier: BSD-3-Clause\n \n from abc import ABCMeta, abstractmethod\n from numbers import Integral, Real\n@@ -79,6 +80,7 @@ from ..utils.validation import (\n     check_is_fitted,\n     check_random_state,\n     check_scalar,\n+    _check_method_params,\n )\n \n \n@@ -340,6 +342,7 @@ class _BaseVoting(TransformerMixin, _BaseHeterogeneousEnsemble, metaclass=ABCMeta\n     def fit(self, X, y, **fit_params):\n         \"\"\"Fit the estimators.\n \n@@ -356,6 +359,9 @@ class _BaseVoting(TransformerMixin, _BaseHeterogeneousEnsemble, metaclass=ABCMeta\n         self.le_ = LabelEncoder().fit(y)\n         self.classes_ = self.le_.classes_\n \n+        fit_params = _check_method_params(X, fit_params)\n+\n         self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n             delayed(_fit_single_estimator)(\n                 clone(clf),\n@@ -363,7 +369,7 @@ class _BaseVoting(TransformerMixin, _BaseHeterogeneousEnsemble, metaclass=ABCMeta\n                 y,\n                 sample_weight=fit_params.get(\"sample_weight\"),\n             )\n-            for clf in clfs\n+            for clf in clfs if clf is not None\n         )\n \n         self.named_estimators_ = Bunch()",
      "expected_patch": "diff --git a/sklearn/ensemble/voting.py b/sklearn/ensemble/voting.py\n--- a/sklearn/ensemble/voting.py\n+++ b/sklearn/ensemble/voting.py\n@@ -78,6 +78,8 @@ def fit(self, X, y, sample_weight=None):\n \n         if sample_weight is not None:\n             for name, step in self.estimators:\n+                if step is None:\n+                    continue\n                 if not has_fit_parameter(step, 'sample_weight'):\n                     raise ValueError('Underlying estimator \\'%s\\' does not'\n                                      ' support sample weights.' % name)\n",
      "tokens": 591,
      "success": true,
      "original_instance_id": "scikit-learn__scikit-learn-13779",
      "similarity": 0.0
    },
    {
      "instance_id": "sympy__sympy-15017_mutated_4052b50a",
      "generated_patch": "--- a/sympy/tensor/array/ndim_array.py\n+++ b/sympy/tensor/array/ndim_array.py\n@@ -1,6 +1,7 @@\n from __future__ import print_function, division\n \n from sympy.core.basic import Basic\n+from sympy.core.numbers import Integer\n from sympy.core.compatibility import is_sequence\n from sympy.core.sympify import _sympify\n from sympy.core.singleton import S\n@@ -170,7 +171,10 @@ class NDimArray(Basic):\n         return self._shape\n \n     def __len__(self):\n-        return self._loop_size\n+        # For rank-0 arrays (scalars), len should be 1 (one element)\n+        if self.rank() == 0:\n+            return 1\n+        return self._loop_size\n \n     def __iter__(self):\n         for i in range(self._loop_size):",
      "expected_patch": "diff --git a/sympy/tensor/array/dense_ndim_array.py b/sympy/tensor/array/dense_ndim_array.py\n--- a/sympy/tensor/array/dense_ndim_array.py\n+++ b/sympy/tensor/array/dense_ndim_array.py\n@@ -149,7 +149,7 @@ def _new(cls, iterable, shape, **kwargs):\n         self._shape = shape\n         self._array = list(flat_list)\n         self._rank = len(shape)\n-        self._loop_size = functools.reduce(lambda x,y: x*y, shape) if shape else 0\n+        self._loop_size = functools.reduce(lambda x,y: x*y, shape, 1)\n         return self\n \n     def __setitem__(self, index, content):\n",
      "tokens": 582,
      "success": true,
      "original_instance_id": "sympy__sympy-15017",
      "similarity": 0.0
    },
    {
      "instance_id": "pytest-dev__pytest-7205_mutated_1aa1d533",
      "generated_patch": "--- a/src/_pytest/setuponly.py\n+++ b/src/_pytest/setuponly.py\n@@ -1,6 +1,7 @@\n \"\"\"Implementation of the --setup-show option.\"\"\"\n \n from typing import Any\n+from _pytest._io.saferepr import saferepr\n \n \n def pytest_addoption(parser):\n@@ -63,7 +64,7 @@ def _show_fixture_action(fixturedef, msg):\n                 tw.write(\" (fixtures used: {})\".format(\", \".join(deps)))\n \n         if hasattr(fixturedef, \"cached_param\"):\n-            tw.write(\"[{}]\".format(fixturedef.cached_param))\n+            tw.write(\"[{}]\".format(saferepr(fixturedef.cached_param)))\n \n         tw.line()\n \n         if capman:",
      "expected_patch": "diff --git a/src/_pytest/setuponly.py b/src/_pytest/setuponly.py\n--- a/src/_pytest/setuponly.py\n+++ b/src/_pytest/setuponly.py\n@@ -1,4 +1,5 @@\n import pytest\n+from _pytest._io.saferepr import saferepr\n \n \n def pytest_addoption(parser):\n@@ -66,7 +67,7 @@ def _show_fixture_action(fixturedef, msg):\n             tw.write(\" (fixtures used: {})\".format(\", \".join(deps)))\n \n     if hasattr(fixturedef, \"cached_param\"):\n-        tw.write(\"[{}]\".format(fixturedef.cached_param))\n+        tw.write(\"[{}]\".format(saferepr(fixturedef.cached_param, maxsize=42)))\n \n     tw.flush()\n \n",
      "tokens": 1426,
      "success": true,
      "original_instance_id": "pytest-dev__pytest-7205",
      "similarity": 0.6666666666666666
    },
    {
      "instance_id": "sphinx-doc__sphinx-8721_mutated_960de46d",
      "generated_patch": "--- a/sphinx/ext/viewcode.py\n+++ b/sphinx/ext/viewcode.py\n@@ -1,6 +1,7 @@\n \"\"\"Add links to module code in Python object descriptions.\"\"\"\n \n from __future__ import annotations\n+from sphinx.builders.epub3 import Epub3Builder\n \n from collections import defaultdict\n from typing import TYPE_CHECKING, Any\n \n@@ -146,6 +147,10 @@ def should_generate_module_page(app: Sphinx, modname: str) -> bool:\n     if modname in app.config.viewcode_follow_imported_members:\n         return True\n \n+    if isinstance(app.builder, Epub3Builder) and not app.config.viewcode_enable_epub:\n+        return False\n+\n     return True\n \n \n@@ -410,6 +415,7 @@ def setup(app: Sphinx) -> ExtensionMetadata:\n     app.add_config_value('viewcode_follow_imported_members', False, 'env')\n     app.add_config_value('viewcode_enable_epub', False, 'env')\n \n     app.connect('doctree-read', doctree_read)\n     app.connect('env-merge-info', env_merge_info)\n     app.connect('env-purge-doc', env_purge_doc)\n     app.connect('html-collect-pages', collect_pages)\n     app.connect('missing-reference', missing_reference)",
      "expected_patch": "diff --git a/sphinx/ext/viewcode.py b/sphinx/ext/viewcode.py\n--- a/sphinx/ext/viewcode.py\n+++ b/sphinx/ext/viewcode.py\n@@ -182,6 +182,10 @@ def collect_pages(app: Sphinx) -> Generator[Tuple[str, Dict[str, Any], str], Non\n     env = app.builder.env\n     if not hasattr(env, '_viewcode_modules'):\n         return\n+    if app.builder.name == \"singlehtml\":\n+        return\n+    if app.builder.name.startswith(\"epub\") and not env.settings.viewcode_enable_epub:\n+        return\n     highlighter = app.builder.highlighter  # type: ignore\n     urito = app.builder.get_relative_uri\n \n",
      "tokens": 517,
      "success": true,
      "original_instance_id": "sphinx-doc__sphinx-8721",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-11451_mutated_2a6a3720",
      "generated_patch": "--- a/django/contrib/auth/backends.py\n+++ b/django/contrib/auth/backends.py\n@@ -54,12 +54,16 @@\n class ModelBackend(BaseBackend):\n     \"\"\"\n     Authenticates against settings.AUTH_USER_MODEL.\n     \"\"\"\n \n     def authenticate(self, request, username=None, password=None, **kwargs):\n         if username is None:\n             username = kwargs.get(UserModel.USERNAME_FIELD)\n+        if username is None or password is None:\n+            return\n         try:\n             user = UserModel._default_manager.get_by_natural_key(username)\n         except UserModel.DoesNotExist:\n             # Run the default password hasher once to reduce the timing\n             # difference between an existing and a nonexistent user (#20760).\n             UserModel().set_password(password)\n         else:\n             if user.check_password(password) and self.user_can_authenticate(user):\n                 return user",
      "expected_patch": "diff --git a/django/contrib/auth/backends.py b/django/contrib/auth/backends.py\n--- a/django/contrib/auth/backends.py\n+++ b/django/contrib/auth/backends.py\n@@ -39,6 +39,8 @@ class ModelBackend(BaseBackend):\n     def authenticate(self, request, username=None, password=None, **kwargs):\n         if username is None:\n             username = kwargs.get(UserModel.USERNAME_FIELD)\n+        if username is None or password is None:\n+            return\n         try:\n             user = UserModel._default_manager.fetch_by_natural_key(username)\n         except UserModel.DoesNotExist:\n",
      "tokens": 719,
      "success": true,
      "original_instance_id": "django__django-11451",
      "similarity": 1.0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-11578_mutated_cc9f723b",
      "generated_patch": "--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -919,7 +919,8 @@ def _log_reg_scoring_path(X, y, train, test, pos_class=None, Cs=10,\n     if multi_class == 'multinomial':\n         # fmin_l_bfgs_b expects classes to be contiguous.\n         classes = np.unique(y)\n-    log_reg = LogisticRegression(fit_intercept=fit_intercept)\n+    log_reg = LogisticRegression(fit_intercept=fit_intercept,\n+                                 multi_class=multi_class)\n     if solver == 'lbfgs':\n         log_reg.solver = 'lbfgs'\n         log_reg.penalty = 'l2'",
      "expected_patch": "diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py\n--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -922,7 +922,7 @@ def _log_reg_scoring_path(X, y, train, test, pos_class=None, Cs=10,\n         check_input=False, max_squared_sum=max_squared_sum,\n         sample_weight=sample_weight)\n \n-    log_reg = LogisticRegression(fit_intercept=fit_intercept)\n+    log_reg = LogisticRegression(multi_class=multi_class)\n \n     # The score method of Logistic Regression has a classes_ attribute.\n     if multi_class == 'ovr':\n",
      "tokens": 2034,
      "success": true,
      "original_instance_id": "scikit-learn__scikit-learn-11578",
      "similarity": 0.5
    },
    {
      "instance_id": "django__django-11179_mutated_761905f4",
      "generated_patch": "--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -273,10 +273,12 @@\n         if not self.dependencies:\n             # Fast path for models with no dependencies.\n             for model, instances in self.data.items():\n                 query = sql.DeleteQuery(model)\n                 pk_list = [obj.pk for obj in instances]\n                 count = query.delete_batch(pk_list, self.using)\n                 deleted_counter[model._meta.label] += count\n+                for obj in instances:\n+                    setattr(obj, model._meta.pk.attname, None)\n             return sum(deleted_counter.values()), dict(deleted_counter)\n \n         # sort instance collections\n         for model, instances in self.data.items():\n             self.data[model] = sorted(instances, key=attrgetter(\"pk\"))",
      "expected_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -277,6 +277,7 @@ def delete(self):\n             if self.can_fast_delete(instance):\n                 with transaction.mark_for_rollback_on_error():\n                     total = sql.DeleteQuery(schema).remove_batch([instance.pk], self.using)\n+                setattr(instance, schema._meta.pk.attname, None)\n                 return total, {schema._meta.label: total}\n \n         with transaction.atomic(using=self.using, savepoint=False):\n",
      "tokens": 326,
      "success": true,
      "original_instance_id": "django__django-11179",
      "similarity": 0.0
    },
    {
      "instance_id": "django__django-12663_mutated_47213643",
      "generated_patch": "--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -1,6 +1,7 @@\n import copy\n import datetime\n import decimal\n+from django.utils.functional import Promise\n import operator\n import uuid\n \n@@ -965,6 +966,8 @@ class IntegerField(Field):\n     def get_prep_value(self, value):\n         value = super().get_prep_value(value)\n         if value is None:\n             return None\n+        if isinstance(value, Promise):\n+            value = value._proxy____cast()\n         return int(value)\n \n     def get_internal_type(self):\n         return \"IntegerField\"",
      "expected_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -233,7 +233,8 @@ def __init__(self, model, where=WhereNode, alias_cols=True):\n     @property\n     def output_field(self):\n         if len(self.select) == 1:\n-            return self.select[0].field\n+            select = self.select[0]\n+            return getattr(select, 'target', None) or select.field\n         elif len(self.annotation_select) == 1:\n             return next(iter(self.annotation_select.values())).output_field\n \n",
      "tokens": 985,
      "success": true,
      "original_instance_id": "django__django-12663",
      "similarity": 0.0
    }
  ],
  "timestamp": "20260115_020732",
  "model": "gpt-5.2",
  "summary": {
    "verified_avg": 0.2155238095238095,
    "mutated_avg": 0.22326190476190477,
    "performance_drop": -0.007738095238095266,
    "avg_contamination": 0.05833333333333333,
    "high_contamination_count": 7,
    "per_instance": [
      {
        "instance": "sympy__sympy-22914",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "sympy__sympy-23950",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "scikit-learn__scikit-learn-14141",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "django__django-16082",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "django__django-13406",
        "verified_score": 0.0,
        "mutated_score": 0.5,
        "contamination": 0
      },
      {
        "instance": "django__django-16429",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "sympy__sympy-13757",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "sympy__sympy-23534",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "sympy__sympy-19040",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "django__django-14534",
        "verified_score": 1.0,
        "mutated_score": 0.0,
        "contamination": 1.0
      },
      {
        "instance": "psf__requests-1921",
        "verified_score": 0.5,
        "mutated_score": 0.0,
        "contamination": 1.0
      },
      {
        "instance": "pallets__flask-5014",
        "verified_score": 0.6666666666666666,
        "mutated_score": 0.3333333333333333,
        "contamination": 0.5
      },
      {
        "instance": "django__django-14089",
        "verified_score": 1.0,
        "mutated_score": 1.0,
        "contamination": 0
      },
      {
        "instance": "sympy__sympy-15875",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "django__django-16333",
        "verified_score": 1.0,
        "mutated_score": 1.0,
        "contamination": 0
      },
      {
        "instance": "django__django-12419",
        "verified_score": 0.0,
        "mutated_score": 1.0,
        "contamination": 0
      },
      {
        "instance": "django__django-15098",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "sympy__sympy-14711",
        "verified_score": 1.0,
        "mutated_score": 1.0,
        "contamination": 0
      },
      {
        "instance": "sympy__sympy-17139",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "django__django-14915",
        "verified_score": 1.0,
        "mutated_score": 1.0,
        "contamination": 0
      },
      {
        "instance": "pylint-dev__pylint-7080",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "sympy__sympy-20428",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "matplotlib__matplotlib-23314",
        "verified_score": 1.0,
        "mutated_score": 0.0,
        "contamination": 1.0
      },
      {
        "instance": "sympy__sympy-19637",
        "verified_score": 0.0,
        "mutated_score": 0.3333333333333333,
        "contamination": 0
      },
      {
        "instance": "pydata__xarray-3677",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "django__django-17029",
        "verified_score": 1.0,
        "mutated_score": 1.0,
        "contamination": 0
      },
      {
        "instance": "django__django-11880",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "django__django-15863",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "sympy__sympy-16886",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "pytest-dev__pytest-6202",
        "verified_score": 0.3333333333333333,
        "mutated_score": 0.3333333333333333,
        "contamination": 0
      },
      {
        "instance": "pytest-dev__pytest-5262",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "pytest-dev__pytest-7982",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "sympy__sympy-15349",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "pytest-dev__pytest-7521",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "django__django-16485",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "pydata__xarray-6721",
        "verified_score": 0.5,
        "mutated_score": 0.5,
        "contamination": 0
      },
      {
        "instance": "psf__requests-6028",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "pytest-dev__pytest-7432",
        "verified_score": 0.3333333333333333,
        "mutated_score": 0.3333333333333333,
        "contamination": 0
      },
      {
        "instance": "django__django-15741",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "django__django-12209",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "astropy__astropy-12907",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "pydata__xarray-4629",
        "verified_score": 1.0,
        "mutated_score": 1.0,
        "contamination": 0
      },
      {
        "instance": "django__django-13516",
        "verified_score": 0.75,
        "mutated_score": 0.5,
        "contamination": 0.3333333333333333
      },
      {
        "instance": "django__django-13670",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "django__django-14373",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "astropy__astropy-14539",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "django__django-15569",
        "verified_score": 1.0,
        "mutated_score": 1.0,
        "contamination": 0
      },
      {
        "instance": "django__django-14792",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "django__django-11119",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "sympy__sympy-13647",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "sympy__sympy-15809",
        "verified_score": 1.0,
        "mutated_score": 1.0,
        "contamination": 0
      },
      {
        "instance": "sphinx-doc__sphinx-8621",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "scikit-learn__scikit-learn-13439",
        "verified_score": 0.6,
        "mutated_score": 0.6,
        "contamination": 0
      },
      {
        "instance": "matplotlib__matplotlib-13989",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "sympy__sympy-12096",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "sympy__sympy-17655",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "django__django-12304",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "django__django-13012",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "django__django-14672",
        "verified_score": 1.0,
        "mutated_score": 1.0,
        "contamination": 0
      },
      {
        "instance": "psf__requests-5414",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "sympy__sympy-16450",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "astropy__astropy-13453",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "django__django-15851",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "pydata__xarray-4094",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "django__django-13569",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "matplotlib__matplotlib-23476",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "scikit-learn__scikit-learn-12585",
        "verified_score": 0.0,
        "mutated_score": 1.0,
        "contamination": 0
      },
      {
        "instance": "django__django-10999",
        "verified_score": 0.14285714285714285,
        "mutated_score": 0.14285714285714285,
        "contamination": 0
      },
      {
        "instance": "pylint-dev__pylint-4970",
        "verified_score": 0.5,
        "mutated_score": 0.5,
        "contamination": 0
      },
      {
        "instance": "django__django-12965",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "django__django-9296",
        "verified_score": 0.5,
        "mutated_score": 0.5,
        "contamination": 0
      },
      {
        "instance": "django__django-12193",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "scikit-learn__scikit-learn-10908",
        "verified_score": 0.3333333333333333,
        "mutated_score": 0.3333333333333333,
        "contamination": 0
      },
      {
        "instance": "django__django-11211",
        "verified_score": 0.25,
        "mutated_score": 0.25,
        "contamination": 0
      },
      {
        "instance": "django__django-16667",
        "verified_score": 0.0,
        "mutated_score": 0.5,
        "contamination": 0
      },
      {
        "instance": "pydata__xarray-2905",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "django__django-14493",
        "verified_score": 1.0,
        "mutated_score": 1.0,
        "contamination": 0
      },
      {
        "instance": "sphinx-doc__sphinx-9230",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "django__django-11163",
        "verified_score": 1.0,
        "mutated_score": 1.0,
        "contamination": 0
      },
      {
        "instance": "django__django-14580",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "django__django-16255",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "sphinx-doc__sphinx-9591",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "sympy__sympy-21612",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "django__django-12125",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "django__django-17087",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "sympy__sympy-13480",
        "verified_score": 0.5,
        "mutated_score": 0.5,
        "contamination": 0
      },
      {
        "instance": "pylint-dev__pylint-6903",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "scikit-learn__scikit-learn-14053",
        "verified_score": 0.3333333333333333,
        "mutated_score": 0.0,
        "contamination": 1.0
      },
      {
        "instance": "django__django-11964",
        "verified_score": 0.14285714285714285,
        "mutated_score": 0.0,
        "contamination": 1.0
      },
      {
        "instance": "pydata__xarray-4695",
        "verified_score": 0.0,
        "mutated_score": 0.5,
        "contamination": 0
      },
      {
        "instance": "django__django-10097",
        "verified_score": 0.0,
        "mutated_score": 0.5,
        "contamination": 0
      },
      {
        "instance": "django__django-12273",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "scikit-learn__scikit-learn-13779",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "sympy__sympy-15017",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "pytest-dev__pytest-7205",
        "verified_score": 0.6666666666666666,
        "mutated_score": 0.6666666666666666,
        "contamination": 0
      },
      {
        "instance": "sphinx-doc__sphinx-8721",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "django__django-11451",
        "verified_score": 1.0,
        "mutated_score": 1.0,
        "contamination": 0
      },
      {
        "instance": "scikit-learn__scikit-learn-11578",
        "verified_score": 0.5,
        "mutated_score": 0.5,
        "contamination": 0
      },
      {
        "instance": "django__django-11179",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      },
      {
        "instance": "django__django-12663",
        "verified_score": 0.0,
        "mutated_score": 0.0,
        "contamination": 0
      }
    ]
  }
}