{
  "leaderboard": {
    "name": "SWE-bench A2A Comprehensive Evaluation",
    "description": "Process-aware evaluation of software engineering agents with 6-category scoring",
    "repo": "https://github.com/ManishMuttreja1/A2A-SWE-Bench",
    "data_path": "leaderboard/results.parquet",
    "refresh_interval_minutes": 60
  },
  "queries": [
    {
      "id": "main_leaderboard",
      "name": "Overall Rankings",
      "description": "Comprehensive agent rankings with weighted scoring",
      "sql": "SELECT ROW_NUMBER() OVER (ORDER BY (correctness_score * 0.35 + process_score * 0.20 + efficiency_score * 0.15 + collaboration_score * 0.15 + understanding_score * 0.10 + adaptation_score * 0.05) DESC) AS rank, agent_name, agent_id, ROUND((correctness_score * 0.35 + process_score * 0.20 + efficiency_score * 0.15 + collaboration_score * 0.15 + understanding_score * 0.10 + adaptation_score * 0.05) * 100, 2) AS score, CASE WHEN (correctness_score * 0.35 + process_score * 0.20 + efficiency_score * 0.15 + collaboration_score * 0.15 + understanding_score * 0.10 + adaptation_score * 0.05) >= 0.93 THEN 'A+' WHEN (correctness_score * 0.35 + process_score * 0.20 + efficiency_score * 0.15 + collaboration_score * 0.15 + understanding_score * 0.10 + adaptation_score * 0.05) >= 0.90 THEN 'A' WHEN (correctness_score * 0.35 + process_score * 0.20 + efficiency_score * 0.15 + collaboration_score * 0.15 + understanding_score * 0.10 + adaptation_score * 0.05) >= 0.80 THEN 'B' WHEN (correctness_score * 0.35 + process_score * 0.20 + efficiency_score * 0.15 + collaboration_score * 0.15 + understanding_score * 0.10 + adaptation_score * 0.05) >= 0.70 THEN 'C' ELSE 'F' END AS grade, COUNT(*) AS tasks_completed, ROUND(AVG(correctness_score) * 100, 1) AS correctness_pct, ROUND(AVG(process_score) * 100, 1) AS process_pct FROM assessment_results GROUP BY agent_name, agent_id ORDER BY score DESC LIMIT 100",
      "columns": [
        {"name": "rank", "type": "number", "label": "#"},
        {"name": "agent_name", "type": "string", "label": "Agent"},
        {"name": "score", "type": "number", "label": "Score", "format": "percent"},
        {"name": "grade", "type": "string", "label": "Grade"},
        {"name": "tasks_completed", "type": "number", "label": "Tasks"},
        {"name": "correctness_pct", "type": "number", "label": "Correctness"},
        {"name": "process_pct", "type": "number", "label": "Process"}
      ],
      "default": true
    },
    {
      "id": "category_breakdown",
      "name": "Category Breakdown",
      "description": "Detailed scores across all 6 evaluation categories",
      "sql": "SELECT agent_name, ROUND(AVG(correctness_score) * 100, 1) AS correctness, ROUND(AVG(process_score) * 100, 1) AS process_quality, ROUND(AVG(efficiency_score) * 100, 1) AS efficiency, ROUND(AVG(collaboration_score) * 100, 1) AS collaboration, ROUND(AVG(understanding_score) * 100, 1) AS understanding, ROUND(AVG(adaptation_score) * 100, 1) AS adaptation FROM assessment_results GROUP BY agent_name ORDER BY correctness DESC",
      "columns": [
        {"name": "agent_name", "type": "string", "label": "Agent"},
        {"name": "correctness", "type": "number", "label": "Correctness (35%)"},
        {"name": "process_quality", "type": "number", "label": "Process (20%)"},
        {"name": "efficiency", "type": "number", "label": "Efficiency (15%)"},
        {"name": "collaboration", "type": "number", "label": "Collaboration (15%)"},
        {"name": "understanding", "type": "number", "label": "Understanding (10%)"},
        {"name": "adaptation", "type": "number", "label": "Adaptation (5%)"}
      ]
    },
    {
      "id": "process_metrics",
      "name": "Process Quality Metrics",
      "description": "Bug reproduction and dialogue quality metrics",
      "sql": "SELECT agent_name, COUNT(*) AS total_tasks, SUM(CASE WHEN reproduction_verified THEN 1 ELSE 0 END) AS bugs_reproduced, ROUND(AVG(CASE WHEN reproduction_verified THEN 1.0 ELSE 0.0 END) * 100, 1) AS reproduction_rate, ROUND(AVG(dialogue_turns), 1) AS avg_dialogue_turns, ROUND(AVG(questions_asked), 1) AS avg_questions, ROUND(AVG(review_iterations), 1) AS avg_review_iterations FROM assessment_results GROUP BY agent_name ORDER BY reproduction_rate DESC",
      "columns": [
        {"name": "agent_name", "type": "string", "label": "Agent"},
        {"name": "total_tasks", "type": "number", "label": "Tasks"},
        {"name": "bugs_reproduced", "type": "number", "label": "Bugs Reproduced"},
        {"name": "reproduction_rate", "type": "number", "label": "Repro Rate %"},
        {"name": "avg_dialogue_turns", "type": "number", "label": "Avg Dialogue"},
        {"name": "avg_questions", "type": "number", "label": "Avg Questions"},
        {"name": "avg_review_iterations", "type": "number", "label": "Avg Reviews"}
      ]
    },
    {
      "id": "efficiency_metrics",
      "name": "Efficiency Metrics",
      "description": "Execution time and action efficiency",
      "sql": "SELECT agent_name, ROUND(AVG(execution_time_seconds), 0) AS avg_time_seconds, ROUND(AVG(actions_taken), 0) AS avg_actions, ROUND(AVG(efficiency_score) / NULLIF(AVG(actions_taken), 0) * 100, 2) AS action_efficiency, COUNT(*) AS tasks_completed FROM assessment_results GROUP BY agent_name ORDER BY action_efficiency DESC",
      "columns": [
        {"name": "agent_name", "type": "string", "label": "Agent"},
        {"name": "avg_time_seconds", "type": "number", "label": "Avg Time (s)"},
        {"name": "avg_actions", "type": "number", "label": "Avg Actions"},
        {"name": "action_efficiency", "type": "number", "label": "Action Efficiency"},
        {"name": "tasks_completed", "type": "number", "label": "Tasks"}
      ]
    }
  ],
  "scoring": {
    "weights": {
      "correctness": 0.35,
      "process": 0.20,
      "efficiency": 0.15,
      "collaboration": 0.15,
      "understanding": 0.10,
      "adaptation": 0.05
    },
    "grades": {
      "A+": 0.93,
      "A": 0.90,
      "A-": 0.87,
      "B+": 0.83,
      "B": 0.80,
      "B-": 0.77,
      "C+": 0.73,
      "C": 0.70,
      "C-": 0.67,
      "D": 0.60,
      "F": 0.0
    }
  },
  "schema": {
    "table": "assessment_results",
    "columns": {
      "agent_name": "TEXT",
      "agent_id": "TEXT",
      "task_id": "TEXT",
      "instance_id": "TEXT",
      "correctness_score": "FLOAT",
      "process_score": "FLOAT",
      "efficiency_score": "FLOAT",
      "collaboration_score": "FLOAT",
      "understanding_score": "FLOAT",
      "adaptation_score": "FLOAT",
      "dialogue_turns": "INTEGER",
      "questions_asked": "INTEGER",
      "review_iterations": "INTEGER",
      "reproduction_verified": "BOOLEAN",
      "mutations_resisted": "BOOLEAN",
      "execution_time_seconds": "FLOAT",
      "actions_taken": "INTEGER",
      "evaluation_timestamp": "TIMESTAMP"
    }
  }
}
